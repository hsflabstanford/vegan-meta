---
title: "Vegan meta-analysis pre-analysis plan"
author: "Seth Green"
date: "2023-11-15"
output: html_document
editor_options: 
  chunk_output_type: console
---

# general principles for data collection 

Before mock analyses, here are some general principles we followed when coding studies.

* We take the outcome that most clearly maps to changes in actual consumption behavior. 

* We take the latest possible outcome to test for the presence of enduring effects/. 

* N of treatment and N of control are from the latest possible post-test as well.

* We use Glass's $\Delta$ rather than Cohen's *d*, meaning we standardize by the SD of the control group at baseline whenever possible. This is to avoid any additional assumptions about equivlance of variance between treatment and control groups. When studies don't provide enough information to estimate the control group's SD, we use combined sample estiamtes of population variance or statistical tests that implicitly reflect this information.

* For cluster-assigned treatments, our Ns are the # of clusters rather than participants. This includes studies that cluster by day (e.g. everyone who comes to a restaurant on some day gets treated).

* when authors don't tell us enough to calculate Glass's $\Delta$ but they do tell us that the results were null, we call the effect type "unspecified null" and record it as $\Delta$ = 0.01.

# data analysis on a simulated dataset

Our data analysis will basically look like this at the outset, except with real data. This simulated dataset has basically the same variables as our real dataset. There will be a few differences, e.g. we'll probably do something more complicated to isolate the leaflet studies (or else modify the dataset). But in general, these are the main points.

Anything else we do is exploratory based on trends we observe in the data once we actually start the analysis.

**libraries, functions, options, and simulated data**

```{r setup, message=F}
#' libraries
library(metafor, quietly = T)
library(dplyr, warn.conflicts = F)
library(ggforestplot) # https://nightingalehealth.github.io/ggforestplot
library(ggplot2, warn.conflicts = F)
library(knitr)
library(purrr)
library(sessioninfo)

#' functions
source('./functions/d_calc.R')
source('./functions/map_robust.R')
source('./functions/sum_lm.R')
source('./functions/var_d_calc.R')
#' options and reproducibility
options(scipen = 99)
set.seed(11111988)

```

make a dataset
```{r make_dataset}
dat <- data.frame(study_name = c('a study', 'b study', 'c study', 'd study', 
                                 'e study', 'f study', 'g study', 'h study', 
                                 'i study', 'j study', 'k study', 'l study',
                                 'm study', 'n study', 'o study', 'p study'),
                  u_s_d  = abs(rnorm(16, 1, 1)),
                  ctrl_sd = abs(rnorm(16,4,1)),
                  eff_type = rep("d_i_m", 16),
                  n_t_post = sample(1:100, 16, replace = T),
                  n_c_post = sample(1:100, 16, replace = T),
                  cluster_var = rbinom(16, 1, 0.4),
                  theory = as.factor(sample(
                    c("animal welfare", "environment","health", "psychology"), 
                    16, replace = T)),
                  self_report = rbinom(16, 1, 0.25),
                  leaflet = rbinom(16, 1, 0.25),
                  doi_or_url = rbinom(16, 1, 0.25),
                  delay = sample(1:30, 16, replace = T),
                  unique_study_id = 1:16,
                  pos_neg_neutral = sample(-1:1, 16, replace = T))

#' add d, var_d, and se_d
  dat <- dat |>
    mutate(
      d = mapply(
        FUN = d_calc,
        stat_type = eff_type,
        stat =  u_s_d,
        sample_sd = ctrl_sd,
        n_t = n_t_post,
        n_c = n_c_post),
      var_d = mapply(
        FUN = var_d_calc,
        d = d,
        n_c = n_c_post,
        n_t = n_t_post),
      se_d = sqrt(var_d))
```

What is the overall average meta-analytics effect?

```{r avg_eff}
dat |> map_robust()
```

Fig 1: forest plot

```{r forest_plot}
dat |> arrange(var_d) |>  ggforestplot::forestplot(study_name, 
                         estimate = d, se = se_d, 
                         colour = theory, 
                         xlab = expression(paste("Glass's", " ", Delta)), 
                         ylab = "Study",
                         title = "Forest Plot") +
    geom_vline(xintercept = (dat |> map_robust())$beta, 
                            lty = 'dashed') +  # color = '#00BFC4'
  theme(plot.title = element_text(hjust = 0.5))
```

Sign test (how many studies were positive, negative, or neutral in their authors' own words)

```{r sign_test}
sign_table <- table(dat$pos_neg_neutral)
binom.test(sign_table[[3]], sum(sign_table[1:3]))

```

publication bias
```{r pub_bias}
dat |> sum_lm()

dat |> ggplot(aes(d, se_d)) + geom_point(aes(color = theory)) + 
  stat_smooth(method = 'lm', se = F, color = 'black') + theme_minimal() +
  ggtitle('relationship between effect size and standard erors')

#' split by published/unpublished (DOI = published)

dat |> split(~doi_or_url) |> map(sum_lm) 
dat |> split(~doi_or_url) |> imap(~map_robust(.x) |> kable('markdown')) 
```

differences by clustering, theory and self-report? 

```{r cluster}

dat |> split(~cluster_var) |> imap(~map_robust(.x) |> kable('markdown'))
dat |> split(~theory) |> imap(~map_robust(.x) |> kable('markdown'))
dat |> split(~self_report) |> imap(~map_robust(.x) |> kable('markdown'))
```

do leaflet studies work? 

```{r leaflet}
dat |> filter(leaflet == 1) |> map_robust() |> kable('markdown')
```

Any relationship with delay and outcome?
```{r delay}
dat |> sum_lm(d, delay)
dat |> ggplot(aes(d, delay)) + geom_point() + 
  stat_smooth(method = 'lm', se = F) + theme_minimal()
```

record computational environment
```{r reproducibility}
sessioninfo::session_info()
```