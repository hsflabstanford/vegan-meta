---
title: "Nudges, norms, and persuasion approaches to reducing consumption of meat and animal products: a meta-analysis and theoretical review"
shorttitle: "vegan-meta"
author:
  - name: "Seth A. Green"
    affiliation: "1"
    address: "Kahneman-Treisman Center, Princeton University"
    email: "sag2212@columbia.edu"
    role:
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
      - "Writing - Review & Editing"
  - name: "Maya Mathur"
    affiliation: "2"
    role:
      - "Writing - Review & Editing"
      - "Supervision"
  - name: "Benny Smith"
    affiliation: "3"
    role:

affiliation:
  - id: "1"
    institution: "Kahneman-Treisman Center, Princeton University"
  - id: "2"
    institution: "Stanford University"
  - id: "3"
    institution: "Allied Scholars for Animal Protection "
abstract: |
  This paper meta-analyzes interventions intended to reduce consumption of meat and animal products (MAP), focusing on the most rigorous, policy-ready studies. Extant efforts generally embody one of three theoretical perspectives: appeals to social norms, nudges to make MAP less salient, and information-based approaches that attempt to change attitudes towards MAP itself on health, environmental, and animal welfare grounds. We find that direct appeals to the environment and personal health, along with some norm messages in cafeterias. Appeals to animal welfare, online studies, video treatments, and leafletting studies have no apparent overall effect. However, even the very best studies in this literature typically have concerning measurement limitations arising from self-reported outcomes and a lack of post-intervention follow-up. These limitations raise concerns about social desirability bias and `regression to the meat:' the possibility that someone who is nudged into eating less MAP at one meal will compensate by eating more at the next. We address these concerns with a variety of statistical corrections as well as highlighting the studies whose designs and measurement strategies convincingly address both issues. We conclude with concrete, shovel-ready suggestions for researchers and policymakers. 
  
authornote: |
 This work was generously supported by the Food System Research Fund and NIH award 1R01LM013866-01. Thanks to Alex Berke, Alix Winter, Anson Berns, Hari Dandapani, Adin Richards, and Matt Lerner for comments on an early draft. Thanks to Jacob Peacock, Andrew Jalil, Gregg Sparkman, Joshua Tasoff, Lucius Caviola, and Emma Garnett for helping assemble the database and providing guidance on their studies. Thanks to Jeff Shrader, Andrey Fradkin, Sofia Verduzco, and Daniel Waldinger for helpful suggestions.

keywords: "meta-analysis, meta-science, meat-and-animal-products, evaluation"
wordcount: "7439"
bibliography: "./manuscript/vegan-refs.bib"
floatsintext: no
linenumbers: no
draft: no
mask: no
figurelist: no
tablelist: no
footnotelist: no
output: 
  papaja::apa6_pdf:
    keep_tex: no
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
---

```{r redownload_data_if_missing, echo=F, include=F, eval=F}
library(googledrive)

# drive_auth() # only if needed
drive_download(as_id('1mPCt7HuK7URvuWcsMQokQCOGnSold-TS0NyC1EZniJk'), 
               path = './data/vegan-meta.csv',
               overwrite= TRUE)
```

```{r setup, include=FALSE}
library(dplyr, warn.conflicts = F)
knitr::opts_chunk$set(fig.path = "results/figures/")
source("./functions/sum_tab.R")

dat <- read.csv('./data/vegan-meta.csv')  |>
  group_by(title) |>
  mutate(unique_paper_id = cur_group_id())  |> 
  ungroup() |> 
  group_by(unique_paper_id, intervention_condition) |> 
  mutate(unique_study_id = cur_group_id()) |>
  ungroup() |>
  mutate(decade = as.factor(case_when(year >= 2000 & year <= 2009 ~ "2000s",
                                      year >= 2010 & year <= 2019  ~ "2010s",
                                      year >= 2020 ~ "2020s")
                            ),
         total_sample = n_c_post + n_c_post) |>
  select(author, year, title, unique_paper_id, unique_study_id, everything())
  
num_papers <- as.numeric(max(dat$unique_paper_id))
num_studies <- as.numeric(max(dat$unique_study_id))
```


## 1. Introduction: the three leading perspectives on changing dietary behavior

Reducing consumption of meat and animal products (MAP) would advance numerous policy goals. Animal agriculture is a major driver of climate change [@scarborough2023; @koneswaran2008; @goodland2009] as well as more localized environmental and public health harms [@horrigan2002; @slingenbergh2004; @graham2008; @greger2010]. Excess MAP consumption is a leading cause of premature deaths [@willett2019; @landry2023]; finally, the conditions in which farmed animals live and die are increasingly recognized as a policy matter in its own right [@yeates2011; @webster2001; @kuruc2023].

Policymakers have many tools availabe for reducing MAP consumption. They can can ban certain foods [@caro2009] or practices [@bursey2018] deemed especially cruel; campaign for vegetarianism [@trewern2022]; raise taxes on MAP with high externalities [@springmann2018]; or change eating environments to make MAP alternatives more salient or appealing [@guthrie2015; @bianchi2018restructuring]. However, any lever which focuses on reducing supply rather than demand risks backsliding through political correction [@michielsen2022]. It is essential, therefore, to assess which theoretical approaches most effectively and durably reduce demand for MAP. This paper approaches that question with a theoretically comprehensive review and methodologically focused meta-analysis.

A previous review called on future MAP research to feature more “direct behavioral outcomes” and “long-term follow-up" [@mathur2021meta, p. 1]. Building on this, our paper restricts its quantitative synthesis to the most rigorous, policy-ready research: randomized controlled trials with at least 25 subjects in treatment and control (or at least 10 clusters in cluster-assigned studies) that measure actual MAP consumption at least a single day after treatment begins. We identified `r num_studies` such interventions published in `r num_papers` papers or technical reports.

Scholars have approached MAP reduction from many disciplines, including social psychology [@rosenfeld2018; @dhont2019], economics [@lusk2009], choice architecture [@bianchi2018restructuring; @mertens2022]; and environmental studies [@costello2016]. Among the studies that meet our inclusion criteria, three approaches prevail: **norms-based approaches** that make MAP seem socially undesirable, **nudges** that make MAP alternatives more salient, and **persuasion-based approaches** that attempt to change ideas about the desirability of MAP itself. Which approach is most effective at changing real world behavior has broad implications for both this particular issue and policy in general.

Our main quantitative finding is that appeals to personal health and the environment are the most effective MAP reduction strategies. We also see some evidence of change resulting from a handful of salience- and norms-based changes to some university dining halls. We find overall null results for appeals to animal welfare, studies conducted online, video treatments, and leafletting studies.

However, we place low confidence in the generalizability of these findings because of two potential soruces of measurement error: social desirability bias arising from self-reported outcomes [@mathur2021effectiveness]: and, for interventions that alter a particular eating environment, a general lack of engagement with the possibility of compensatory/backlash effects down the line. We think of this as the "regression to the meat" problem: that someone who is nudged into eating less MAP at one meal may perceive a moral license [@merritt2010; @blanken2015] to eat more MAP later. If we limit our analysis to studies with deal convincingly with both threats to inference, we still conclude that appeals to the environment and health, as well as a handful of nudges and norms messages, reduce reduce MAP consumption, but in the highly specialized context of dining halls at elite American universities. For this literature to truly become shovel-ready for policymakers, it urgently needs extension and replication, along with careful attention to measurement validity.

Our paper builds on two literatures. The first is systematic reviews of attempts to reduce MAP consumption, of which there have been 22 by our count, with two others that we know of forthcoming. (See appendix A for a complete overview). Our paper makes four contributions on top of this already rich set. First, our database is current as of December 2023, which has significance in an emerging literature whose most credible estimates and best designs tend to be in recent publications. Second, our review is quantitative, while most previous reviews are narrative or systematic reviews but do not offer meta-analysis. Third, among papers with a meta-analytic component, ours is (so far) unique for being theoretically comprehensive rather than focusing on the effects of a single conceptual approach. Fourth, ours is the only review to our knowledge to set strict inclusion criteria that attempt to identify the most rigorous, policy-ready research.[^1]

[^1]: We'd also note that some of these reviews err strongly on the side of inclusion, and thus meta-analyze studies with serious threats to internal validity. For example, prior reviews included studies that use differential screening procedures for treatment and control [@rees2018] or that alter the treatment after assignment based on subjects' prior diets [@morren2021]; these procedures violate the 'all else equal in expectation' condition of a randomized controlled trial. As @simonsohn2022 put it, combining "studies that lack internal validity or external validity, which are obtained using incorrect statistical techniques, or studies where results seem to arise from methodological artefacts" with high-quality studies creates averages that are "virtually guaranteed to lack a meaningful interpretation" (p. 551).

Second, our paper contributes to a growing literature of meta-analyses, reviews, and "megastudies" [@doell2023; @milkman2021; @milkman2021megastudy] that attempt to compare the efficacy of different approaches to solving social problems. In social psychology, @paluck2021 and @porat2024 apply meta-analytic methods to testing the efficacy of different theories at reducing prejudice and sexual violence, respectively, while @vlasceanu2024 test 11 theoretically diverse interventions aimed at four "climate mitigation outcomes" (p. 1). In a related vein, @bergquist2023 provide a meta-analysis of meta-analyses for climate mitigation behaviors, and find that social comparison and financial incentives were generally effective, while information and feedback generally were not. We also build on prior reviews that that holistically assess the efficacy of choice architecture approaches versus, e.g., taxes [@list2023] or subsidies [@campos2021]. Finally, a paper from @bergman2024 compares information-based approaches to "short-term financial assistance, customized assistance during the housing search process, and connections to landlords" (p. XXX) to encourage families to move to high-opportunity areas. Our paper's approach is similar to all of these but distinct, to the best of our knowledge, for the stringency and policy focus of our meta-analytic inclusion criteria.

The remainder of the paper proceeds as follows. Section 2 details and motivatess the inclusion criteria and search process by which we assembled our meta-analytic database. Section 3 describes the database. We provide some descriptive statistics about the database, and then present its major theoretical approaches \textemdash environmental, health, and animal welfare appeals to MAP reduction comprising information-based strategies, norms manipulations, and nudges \textemdash and representative literature from each. For each subset, we also highlight some frequent design or measurement limitations that led us to exclude otherwise promising results. Section 4 provides an overview of our meta-analytic methods and procedures.

Section 5 presents our quantitative results. We provide a mixture of pooled averages, tests for publication biases, and comparisons of different approaches. We also offer some attempts to estimate the magnitude of different biases in this literature drawn from related literatures, and to use those estimates to offer effect size corrections. These analyses are tentative, and offer readers a broad range of possibilities intended to match different priors about the severity and importance of the measurement issues we enumerate Section 6 concludes with some concrete suggestions for future MAP reduction researchers based on the results of our analyses.

## 2 Assembling the meta-analytic database

### 2.1 Selecting inclusion criteria

Meta-analysis is a powerful, flexible procedure for pooling results from many studies into a singular estimate, or cluster of estimates, denoting the relationship between a treatment and an outcome across contexts. For this to be an unbiased estimate of the true causal relationship between the two requires several additional assumptions. First, the pooled studies must each furnish an unbiased causal estimate. Second, the set of studies must be a random sample of the universe of possible studies, and not, for instance, truncated by publication bias [@thornton2000]. Third, the assembled outcomes must have a persistent, known relationship with the true outcome of interest.

Each of these propositions is, in theory, testable and amenable to statistical correction (see @mathur2022 and @green2024 for suggestions and strategies). However, the most fundamental challenge to meta-analysis is whether the underlying data are coherently integrable. A recent paper by @slough2023 makes this point forcefully. In their view, for studies to have "target equivalence" \textemdash the property of identifying "the same estimand" (p. 1) \textemdash they must first achieve harmonized contrasts and measurements, meaning that the "substantive comparison across studies is the same" and "the outcome of interest is the same and it is measured in the same way" (p.2). These properties are necessary for meta-analytic results to be "meaningful and interpretable" (p.2). Crucially, they cannot be achieved "solely with statistical techniques" and are instead a product of tailored "design or inclusion criteria" (p.2).

We build on that paper via the following inclusion criteria.

First, we only look at randomized controlled trials for well-understood reasons [@cook2002; see @simonsohn2022 for discussion specific to meta-analysis]. This meant both that treatment was randomized and that there was a true, no-treatment control group for comparison.

Second, studies needed to measure MAP consumption directly, whether indirectly or through self-report. Although this self-report is a potential source of bias [@hebert1995social; @hebert1997gender; @cerri2019], it is a well-understood, widely studied problem, which means that we have reasonable priors about its magnitude, and therefore can account for it in our sensitivity analyses. However, we consider studies aimed at reducing consumption of particular meat products, typically red and/or processed meat, to be looking at a separate estimand, and thus we analyzed them separately as a point of comparison.[^2].

[^2]: If subjects reduce their red and/or processed meat consumption by switching to chicken or fish, this might be an improvement on environmental or health grounds but a step backwards for animal welfare [@mathur2022ethical]; both @klockner2017 and @lohmann2022 both explicitly recommended that subjects switch from red meat to other meat products.

Third, studies needed to measure MAP consumption at least a single day after treatment. For information-based studies, this was straightforward: essentially every treatment took under an hour to administer, and we looked only at studies where there was a delay of at least 24 hours before outcomes were collected. For place-based interventions, measuring this was a little trickier. Most studies in this category measured outcomes while treatment was being actively administered, e.g. a dining hall with a dynamic norms message on display counting the amount of meat sold while the sign was up. For an individual subject of such a study, there was no delay between treatment and outcome. We decided to count studies that took place for more than one day and measured outcomes continuously (e.g. if they displayed the dynamic norms message at many lunches consecutively). Arguably these studies' results will capture any adaptation to treatment, and an enduring effect over many days therefore represents an enduring effect. However, we remain concern about what happens to treated subjects once the treatment ends, and we return to this point in our quantitative results.

Finally, we required that studies have at least 25 subjects in both treatment and control, or, for cluster-assigned studies, at least 10 clusters in total. @paluck2021 found that studies with fewer than 25 subjects per arm, which constituted the smallest quintile of studies in the prejudice reduction literature, showed systematically larger effects than their larger peers. That paper also argued that fewer than 10 clusters would be too few to calculate meaningful standard errors. In practice, we excluded very few studies for having fewer than 25 subjects, but quite a few for having fewer than 10 clusters; many studies describing themselves as experiments had just one unit assigned to treatment and one to control (thogh theyrecorded results at the level of individuals). We categorize these studies as quasi-experiments.

We also required that the full papers be available on the internet, rather than just a summary or abstract, and written in English.

### 2.2 Our search process

Our cutoff date for papers was December 2023.

```{r where_do_studies_come_from, echo=F, include=F}
paper_sources <- dat |> group_by(unique_paper_id) |> slice(1) |> 
  sum_tab(source)
paper_sources

prior_knowledge <- paper_sources["prior knowledge"]
initial_review_papers <- as.numeric(paper_sources["Bianchi (2018a)"]) + 
  as.numeric(paper_sources["Mathur (2021)"])

second_review_papers <- as.numeric(paper_sources["Chang (2023)"]) + 
  as.numeric(paper_sources["Harguess (2019)"]) +  as.numeric(paper_sources["Wynes (2018)"])

cv_papers <- as.numeric(paper_sources["CV (Sparkman)"]) + 
  as.numeric(paper_sources["CV (Jalil)"])

snowball_papers <- paper_sources["snowball search"]

systematic_search_papers <- paper_sources["systematic search"]
```

First, we read all qualifying studies that authors 1 and 3 knew of at the outset, which yielded `r prior_knowledge` papers.

Second, we located and read XX previous systematic reviews, starting with @mathur2021effectiveness as well as @bianchi2018restructuring and @bianchi2018conscious. Those three reviews yielded `r initial_review_papers` additional papers. We then read and categorized papers from XX additional reviews (assisted greatly by @grundy2022, a review of reviews); From @harguess2020, @chang2023 and @wynes2018, we learned of `r second_review_papers` additional papers.

Third, We checked the CVs of prominent researchers in the field, which yielded `r cv_papers` additional papers.

Fourth, we conducted a snowball search where we read papers our assembled papers had cited, papers suggested to us by article homepages, and papers that cited articles already in our database. This yielded `r snowball_papers` papers.

Finally, we conducted a systematic search of Google Scholar for the terms [OUR SEARCH TERMS ONCE WE ARE DONE]. This yielded `r systematic_search_papers` more papers, bringing our total sample size to `r num_papers` papers and `r num_studies` interventions.[^3]

[^3]: In three cases, we condensed multiple interventions into one statistical result based on how they were reported in the paper: @abrahamse2007, @lacroix2020 and @peacock2017. These studies all present substantively null results and, in their results sections, group multiple treatment arms into singular statistical results, which we recorded.

## 3 The meta-analytic database

We first offer some descriptive statistics of our database and then provide a theoretical review.

### 3.1 Descriptive overview of meta-analytic database

```{r descriptive_stats, echo = F, include=F}
library(stringr)
library(purrr)
source('./functions/sum_tab.R')

# Data preparation and basic statistics
paper_dat <- dat |> 
  group_by(unique_paper_id) |> 
  slice(1) |>
  mutate(pub_status = case_when(
    str_detect(venue, "dissertation|thesis") ~ "thesis",
    str_detect(venue, "advocacy") ~ "advocacy org publication",
    str_detect(doi_or_url, "osf\\.io") ~ "preprint",
    str_detect(doi_or_url, "10\\.") ~ "publication"),
    decade = as.character(cut(year, breaks = c(1999, 2009, 2019, 2029), labels = c("2000s", "2010s", "2020s")))) |>
  ungroup()

# Decade Analysis
decade_tab <- paper_dat |> count(decade)
first_decade_papers <- as.numeric(decade_tab$`n`[decade_tab$decade == "2000s"])
second_decade_papers <- as.numeric(decade_tab$`n`[decade_tab$decade == "2010s"])
third_decade_papers <- as.numeric(decade_tab$`n`[decade_tab$decade == "2020s"])

# Publication Type Analysis
doi_tab <- paper_dat |> count(pub_status)
published_papers <- as.numeric(doi_tab$`n`[doi_tab$pub_status == "publication"])
preprint_papers <- as.numeric(doi_tab$`n`[doi_tab$pub_status == "preprint"])
other_papers <- as.numeric(doi_tab$`n`[doi_tab$pub_status == "dissertation_or_tech_report"])

# Non-DOI Paper Analysis
non_doi_paper_stats <- paper_dat |> filter(pub_status != "publication") |> count(venue)
dissertation_papers <- as.numeric(non_doi_paper_stats$`n`[non_doi_paper_stats$venue == "dissertation"])
advocacy_papers <- as.numeric(non_doi_paper_stats$`n`[non_doi_paper_stats$venue == "advocacy org publication"])

# Venue Analysis
venue_counts <- sort(table(paper_dat$venue), decreasing = T)
num_venues <- length(venue_counts)
most_common_venue <- noquote(names(sort(venue_counts, decreasing = TRUE)[1]))
most_common_venue_count <- max(venue_counts)

# Correcting Journal Article Counts
journal_article_counts <- paper_dat |> 
  filter(pub_status == "publication") |> 
  count(venue) |> 
  arrange(desc(n))

# Cluster Assigned Analysis
cluster_sample_stats <- dat |> 
  filter(cluster_assigned == "Y") |> 
  summarise(n = n(),
            median = median(total_sample, na.rm = TRUE), 
            min = min(total_sample, na.rm = TRUE), 
            max = max(total_sample, na.rm = TRUE))

# Non-Clustered Sample Size Statistics
non_cluster_sample_stats <- dat |> 
  filter(cluster_assigned == "N") |> 
  summarise(n = n(),
            median = median(total_sample, na.rm = TRUE), 
            min = min(total_sample, na.rm = TRUE), 
            max = max(total_sample, na.rm = TRUE))

# Intervention Types Count
intervention_types_counts <- dat |> 
  summarise(cafeteria_or_restaurant = sum(cafeteria_or_restaurant_based == "Y", na.rm = TRUE),
            multi_component = sum(multi_component == "Y", na.rm = TRUE),
            leaflet_count = sum(leaflet == "Y", na.rm = TRUE),
            video_count = sum(video == "Y", na.rm = TRUE),
            internet_based = sum(internet == "Y", na.rm = TRUE))

# Emotional Activation
emotional_activation_stats <- dat |> 
  summarise(emotional_activated = sum(emotional_activation == "Y", na.rm = TRUE), 
            emotional_not_activated = sum(emotional_activation == "N", na.rm = TRUE))

# Pre-Analysis Plan Stats
pre_analysis_plan_stats <- dat |> 
  summarise(pre_analysis_yes = sum(public_pre_analysis_plan != "N", na.rm = TRUE),
            pre_analysis_no = sum(public_pre_analysis_plan == "N", na.rm = TRUE))

# Open Data Stats
open_data_stats <- dat |> 
  summarise(open_data_yes = sum(open_data != "N", na.rm = TRUE),
            open_data_no = sum(open_data == "N", na.rm = TRUE))

# where do studies take place and with whom?
country_dat <- dat |> sum_tab(country)
pop_dat <- dat |> sum_tab(population)
# delay 
median_delay <- median(dat$delay)
range_delay <- range(dat$delay)
```

The earliest paper in our sample is @allen2002, and the latest is @jalil2023. Remarkably, a majority of these papers have been published since 2020: `r first_decade_papers` in the 2000s, `r second_decade_papers` in the 2010s, and `r third_decade_papers` in the 2020s.

Out of `r num_papers` total papers, `r published_papers` were published in peer-reviewed journals. `r dissertation_papers` are dissertations, one is a preprint, and four were published by advocacy organizations. Among journal articles, `r num_venues` different journals are represented. The most common venue is *`r most_common_venue`,* with `r most_common_venue_count` papers, followed by three in *Journal of Environmental Psychology*, and two apiece in *American Journal of Public Health*, *Frontiers in Psychology*, and *Sustainability*. The remainder were published in field journals for food and nutrition, psychology, and public health.

This database of studies uses methodologically diverse approaches. `r intervention_types_counts$cafeteria_or_restaurant` studies were conducted in a cafeteria or restaurant, `r intervention_types_counts$leaflet_count` studies employed leaflets, `r intervention_types_counts$video_count` used videos, and `r intervention_types_counts$internet_based` were administered online. `r intervention_types_counts$multi_component` used multi-component strategies, meaning that their treatments comprised multiple active elements intended to change behaviors.

`r cluster_sample_stats$n` studies were assigned to clusters. This subset had a median of `r cluster_sample_stats$median` clusters in total, ranging from `r cluster_sample_stats$min` to `r cluster_sample_stats$max`. There were `r non_cluster_sample_stats$n` studies with assignment at the level of the individual, with a median sample size of `r non_cluster_sample_stats$median`, and a range from `r non_cluster_sample_stats$min` to `r non_cluster_sample_stats$max`.

`r emotional_activation_stats$emotional_activated` had interventions with clearly emotionally activating content, e.g. video footage of industrial farming.

`r open_data_stats$open_data_yes` studies made their data openly available, and `r pre_analysis_plan_stats$pre_analysis_yes` papers had publicly available pre-analysis plans.

A majority (`r country_dat["United States"]` of `r num_studies`) of studies take place exclusively in the United States. with a further `r country_dat["Germany"]` in Germany and `r country_dat["United Kingdom"]` in the United Kingdom. Australia, Canada, Denmark, the Netherlands, and Sweden had one each, and one internet-based study had participants in the United States, United Kingdom, Canada, Australia, and "other" [@cooney2016].

Most studies in this database were administered to university students: `r pop_dat["university students"]` of `r num_studies`. A further `r pop_dat["adults"]` were administered to adults, while `r pop_dat["young women"]` was delivered to young women (ages 13-25) and `r pop_dat["all ages"]` to people of all ages: one at a restaurant [@coker2022] and one online survey with an age range of 18 to 82 [@bochmann2017].

The average delay between the start of treatment and outcome measurement is `r median_delay` days, with a range of `r range_delay[1]` to `r range_delay[2]` days.

### 3.1.1 a diversity of dependent variables

```{r self_report_tab, echo=F, include=F}
self_report_count <- dat |> sum_tab(self_report)

self_report_outcomes <- dat |> filter(self_report == "Y") |> 
  select(author, year, title, outcome, outcome_category) 

self_report_outcome_table <- self_report_outcomes |> sum_tab(outcome_category)

servings_portions_meals_count <- sum(str_detect(self_report_outcomes$outcome_category, "servings|portions|meals"))

days_count <- sum(str_detect(self_report_outcomes$outcome_category, "days"))
weight_loss_count <- sum(str_detect(self_report_outcomes$outcome_category, "weight"))
```
Self-reported outcomes are the norm: `r self_report_count['Y']`of`r `num_studies` studies. `r servings_portions_meals_count` of these studies measured MAP consumption in terms of servings, portions, or meals with MAP, while `r days_count` measured number of days with  `r weight_loss_count` measured MAP consumption by weight. `r sum(self_report_outcomes$outcome_category == "self_reported_more_less_outcome")` studies asked subjects to report whether they ate more or less MAP after receiving treatment than before. One paper [@norris2014] grouped subjects' responses into a Likert-type scale from 1-5 depending on how many portions of animal products they consumed. The majority of self-reported outcomes asked just about meat rather than MAP as a whole [DOUBLE-CHECK AND MAYBE CODE THIS]

```{r objective_report_tab, echo=F, include=F}
objective_report_studies <- dat |> filter(self_report == "N") |> 
  select(author, year, title, outcome, outcome_category)

objective_report_studies |> sum_tab(outcome_category)

MAP_vs_meat <- dat |> group_by(str_detect(outcome_category, "MAP")) |> count()
```

By contrast the `r nrow(objective_report_studies)` studies that did not rely on self-report had more homogeneous outcomes:  `r sum(str_detect(objective_report_studies$outcome_category, "porportion"))` of these studies measured the proportion of meals at a dining hall or restaurant were vegetarian or vegan, while `r sum(str_detect(objective_report_studies$outcome_category, "percent"))` -- @jalil2023 and @haile2021 -- measured percentage reductions in MAP consumption on an individual basis.

`r MAP_vs_meat$n[1]` studies looked at reducing meat consumption, while `r MAP_vs_meat$n[2]` looked at other categories of animal product, including eggs and dairy.

### 3.2 The leading theoretical approaches to reducing MAP consumption

```{r theory_tab, echo=F, include=F}
library(stringr)
source('./functions/study_count.R')

theory_tab <- dat |> sum_tab(theory)
secondary_theory_tab <- dat |> sum_tab(secondary_theory)

norms <- dat |>   filter(str_detect(theory, "norms"))

norms |> select(author, year, title, theory, secondary_theory)

norms_paper_count <- norms |> study_count('unique_paper_id')

hybrid_norm_approaches <- norms |> 
  filter(str_detect(theory, "&"))

norm_nudge_approaches <- norms |> 
  filter(str_detect(theory, "nudge"))
```

Three approaches characterize the policy-relevant MAP reduction research: norms, nudges and persuasion. Persuasion approaches comprise three sub-categories: health, environmental, and animal welfare appeals.

Many interventions explicitly combine multiple theoretical approaches, for example providing information about the environmental case for MAP reduction and also a norm-based message about the increasing popularity of vegetarian options [@piester2020]. Our counts of interventions by category equal to more than the total number of interventions in the database.

#### 3.2.1 Norms

Norms-based approaches inform `r nrow(norms)` of `r num_studies` interventions in our database and `r`norms_paper_count\` papers. These interventions typically try to normalize vegetarianism and veganism by creating a perception that eating plant-based meals is consistent with social norms. To do this, researchers might put up signs that say “[More and more [retail store name] customers are choosing our veggie options" [@coker2022, p. 2] or "In a taste test we did at the [name of cafe], 95% of people said that the veggie burger tasted good or very good!" [@piester2020, p. 5]. One study told participants that people who eat meat are more likely to endorse social hierarchy and embrace human dominance over nature [@allen2002], thus making them out to be a counter-normative outgroup.

Two theoretical splits characterize this literature. The first is between *descriptive* and *injunctive* norms: while "descriptive norms pertain to the behavior of a majority of people (e.g. “most people eat vegetarian at least twice a week”), injunctive norms describe what behavior most others approve or disapprove of (e.g. “most people approve of eating vegetarian at least twice a week” [@alblas2023, p. 993]). For example, that study's injunctive norm intervention told Dutch households with unusually high meat consumption rates that they were negative outliers, along with a frowning face symbol. The other theoretical divide is between *dynamic* and *static* norms. Dynamic norms emphasize how behavior is changing over time, while static norms emphasize the current state of affairs. For example, @sparkman2017 presented people waiting in line at a Stanford cafeteria the opportunity to participate in a 'survey' in exchange for a meal coupon, where the survey presented one of two norms-based messages: a 'static' message about how "30% of Americans make an effort to limit their meat consumption," or a dynamic message emphasizing how behavior is changing over time and that vegetarianism is taking off among participants' peers.

Dynamic norm messages are predominant in this subset of the literature. However, many studies in this literature combine multiple approaches into one intervention. @aldoh2023, for example, employ a 2x2 design where either a static norm or dynamic norm intervention conveying information about meat-eating habits in the United Kingdom is either combined with a visual cue (a graph showing the percentage of British people who took efforts to reduce their meat consumption either holding steady or going up over time) or not, These approaches are theoretically congruent, while other studies deliberately combine multiple approaches. In two cases, authors combined norms-appeals with explicit reasons to reduce MAP consumption. @hennessy2016 provided participants with one of two leaflets; the "why vegetarian" leaflet contained both "pictures of vegetarian celebrities in the why-focused leaflet to demonstrate a social norm" along with health, environmental, and animal welfare reasons to adopt a vegetarian diet. @lacroix2020 combine a descriptive social norm ("45% of Canadians are al- ready making efforts to reduce their consumption of meat") with environmental and health reasons to reduce consumption of red and processed meat.

Finally, `r nrow(norm_nudge_approaches)` deploy what we consider to be norms-based nudges in unobtrusive ways in dining halls. Two of four interventions in @piester2020 posted signs at a university canteen that said "In a taste test we did at the [name of cafe], 95% of people said that the veggie burger tasted good or very good!" [@piester2020, p. 5]; one of those intervention arms also included an environmental message: "Many people don’ know how much our food choices impact the environment. Eating sustainable foods is a good way we can fight climate change!" [@piester2020, p. 5]. @coker2022 placed a dynamic norm message about the growing popularity of veggie burgers in a chain of restaurants.

Whether these interventions are nudges is debatable. On the one hand, they seek to exploit a widespread heuristic of following group norms, and they do so by raising the salience of certain items in an unobtrusive way. On the other, They are plainly attempts to change underlying preferences by providing factual information. However, in these hybrid cases, the suggested change is implicit and can easily be ignored, which suggests a "libertarian paternalistic" perspective on behavior change [@thaler2003]. A further relevant distinction comes from @brachem2019, who argue that unlike descriptive norms, injunctive norms "work at least partly...through the implication of social sanctions" (p.9), which amount to incentives. Therefore, we coded norm-based interventions that that were cheap, unobtrusive, and descriptive as a nudge as well. This excludes, for instance, a survey with a norm message taken on the line to a dining hall because the delivery method is intrusive.

### 3.2.2 Nudges

```{r nudge_theory, include=F, echo=F}
nudge_studies <- dat |> filter(str_detect(theory, "nudge"))

hybrid_nudge_approach_number <- sum(str_detect(nudge_studies$theory, "&"))

norms_nudge_approaches <- nudge_studies |> filter(str_detect(theory, "norms"))

nudge_studies |> select(author, year, theory, secondary_theory)

pure_nudge_count <- sum(!str_detect(nudge_studies$theory, "&"))
```

As discussed above, the precise boundaries around the idea of 'nudge' can be blurry. We refer to the original definition in @thaler2009, p. 6:

> A nudge...is any aspect of the choice architecture that alters people’s behavior in a predictable way without forbidding any options or significantly changing their economic incentives. To count as a mere nudge, the intervention must be easy and cheap to avoid. Nudges are not mandates.

We also follow guidance from @hansen2016, who argues that a nudge should refer to "features that influence behaviour in ways not in accordance with that of economic rationality" (p.162) by making use of cognitive biases. By this definition,"rational persuasion or argument" [\@ @hansen2016, p. 169] is not a nudge because it works on the conscious, deliberative mind rather than on automatic, prone-to-bias processes.

By these standards, `r nrow(nudge_studies)` intervention in our database are nudges printed in `r length(unique(nudge_studies$doi_or_url))` papers. `r hybrid_nudge_approach_number` of these studies are combine nudges with social norm messages, as previously discussed. Further, two interventions in @piester2020 placed a message about the environmental benefits of reducing MAP consumption in a university canteen with no social norm message, thus combining nudge and persuasion approaches.

`r pure_nudge_count` study is a pure nudge. @andersson2021 randomly altered whether the vegetarian or meat option appeared at the top of a large menu display at a university cafeteria in Sweden, along with "the amount of carbon dioxide equivalents" associated with each option" (p. 4).

#### Whither the choice architecture approaches?

This relative dearth of nudge studies might surprise researchers familiar with the sprawling literature on nudges and diet. We attribute this mainly to our strict focus on MAP consumption as a dependent variable. This entailed excluding all studies that measured only hypothetical outcomes, which were startlingly common. For instance, @campbell2014 intercepted college students on their way to a dining hall, asked them to complete a survey, and then led them to another room where students were with different hypothetical menus comprised of options from the dining hall. Students told researchers which food they preferred and then left to go eat their meal, which the researchers did not track. As the authors put it, this design might “be critiqued for not providing actual food choices and thus lacking any real consequences” (p. 16). Along the same lines, @bacon2018 asked MTurk participants to “imagine a scenario in which they were catching up with a friend for dinner in a nice restaurant one evening during the week…they were also presented with an image of a cozy table in a restaurant” (p. 17). The main outcome was probability of selecting a vegetarian option from a hypothetical menu.

We also excluded some interesting studies that assigned treatment at the level of a restaurant or dining hall and included too few units for meaningful analysis. @mcclain2013 and @reinders2017, for instance, test plausible theories of change in a college cafeteria and a chain of restaurants, respectively, but had just 2 and 3 units in their respective treatment arms. Along similar lines, some strong studies in dining halls with compelling theories of change and objective outcome measurements did not feature truly random assignment [@gravert2021; @garnett2020].

Finally, we note that prior systematic reviews of the the nudge and diet literature include studies with disqualifying threats to internal validity, such as differential screening procedures for treatment and control [@rees2018] or changes to treatment after assignment based on subjects' prior diets [@morren2021]. As @simonsohn2022 put it, combining "studies that lack internal validity or external validity, which are obtained using incorrect statistical techniques, or studies where results seem to arise from methodological artefacts" with high-quality studies creates averages that are "virtually guaranteed to lack a meaningful interpretation" (p. 551).

### Persuasion

```{r persuasion_count, echo=F, include=F}
persuasion_studies <- dat |> filter(str_detect(theory, "persuasion"))
```

We now turn to direct efforts to persuade people to reduce their MAP consumption, which comprise `r nrow(persuasion_studies)` of `r num_studies` in our database, These studies generally provide direct arguments and relevant, factual arguments for dietary change. These arguments come in three varieties: appeals toanimal welfare, the environment, and personal health.

### Appeals to animal welfare

```{r animal_welfare_studies, echo=F, include=F}
animal_studies <- dat |> filter(str_detect(secondary_theory, "animal welfare"))

animal_leaflet_studies <- animal_studies |> filter(leaflet == "Y")

animal_leaflet_college_studies <- animal_leaflet_studies |> filter(population == "university students")
strict_animal_studies <- animal_studies |> filter(secondary_theory == "animal welfare")
non_strict_animal_studies <- animal_studies |> filter(secondary_theory != "animal welfare")

animal_video_studies <- animal_studies |> filter(video == "Y")

animal_outcome_types <- table(animal_studies$self_report)

online_animal_studies <- table(animal_studies$internet)
```

Direct appeals to eat less meat for the sake of animals’ wellbeing inform `r nrow(animal_studies)` of `r num_studies` studies in our database. Many of these interventions are conducted by advocacy organizations such as Faunalytics, The Humane League, and Mercy for Animals. [PUT A NUMBER ON IT?]

`r nrow(animal_leaflet_studies)` interventions involve leaflets, and `r nrow(animal_leaflet_college_studies)` of these are administered to university students. Leafletting studies typically contain facts, details, and sometimes graphic pictures about industrial farming (see @haile2021, @norris2014 and @peacock2017 for representative examples; see \href{https://veganoutreach.org/wp-content/uploads/PPR-2015-EI.pdf} for a representative leaflet).

`r nrow(animal_video_studies)` interventions involve videos. For example, @cooney2016 used facebook ads to draw young women (ages 13-25) to a landing page with a video of farmed animal cruelty, and then asked them about their meat consumption a month later. Some videos, like that in @feltz2022, combined animal welfare appeals with information about the environmental and health impacts of industrial farming.

Among animal welfare interventions overall, `r nrow(strict_animal_studies)` of these focus exclusively about animal welfare, while `r nrow(non_strict_animal_studies)` combine animal welfare appeals with other theoretical approaches.

`r animal_outcome_types["Y"]` of these studies use self-reported outcomes. The lone exception is @haile2021, which tracked food purchases at a university dining hall. Approximately half of all animal appeal studies (`r online_animal_studies["Y"]` of `r nrow(animal_studies)`) were administered online.

#### Appeals to the environment

```{r environmental_studies, echo=F, include=F}
environmental_studies <- dat |> 
  filter(str_detect(secondary_theory, "environment"))

solely_environment <- environmental_studies |> 
  filter(secondary_theory == "environment")

hybrid_environment <- environmental_studies |> 
  filter(secondary_theory != "environment")

```

These studies focus on the environmental harms of consuming animal products and/or promote plant-based alternatives as more sustainable. This framing informs `r nrow(environmental_studies)` of `r num_studies` interventions in our database. The typical argument in these pieces is that MAP production and consumption leads to global warming through carbon emissions.

As with appeals to animal welfare, these interventions comprise leaflets [@hennessy2016; @bianchi2022], signs in college cafeterias [@piester2020], and videos [@bochmann2017]. One study compared the effects of reading two op-eds with "reduce" and "eliminate" messages respectively [@sparkman2021], each providing both environmental and health rationales.

The landmark study in this branch of the literature is @jalil2023, who randomly assigned undergraduate classes to hear a “50 min talk about the role of meat consumption in global warming, along with information about the health benefits of reduced meat consumption” (p. 218) and then measured their subsequent food choices at the college’s dining facilities. Overall, they find that students in the treatment group “reduced their meat consumption by 5.6 percentage points with no signs of reversal over 3 years” (p. 218). Among students who said they had tried to reduce their meat consumption, 64% said they were motivated by global warming, and 33% by health; 26% said both.

No other study in any strand of the literature shows positive effects lasting this long.

#### Appeals to health

```{r health_studies, echo=F, include=F}
health_studies <- dat |> filter(str_detect(secondary_theory, "health"))
just_health_studies <- health_studies |> filter(!str_detect(secondary_theory, "&") & 
                                                !str_detect(theory, "&")) 
```

Health concerns motivate \$`r nrow(health_studies)` of `r num_studies` interventions in our database. These appeals typically stress benefits like cardiovascular gains, weight loss, or cancer prevention.

For example, @fehrenbach2015 tested the “effectiveness of two video messages designed to encourage Americans to reduce their meat consumption.” The study had two treatment arms and a control. Both treatment videos sought to induce a feeling of “high threat” by informing viewers of the “the negative health effects of high meat consumption;” one video also sought to induce feelings of “high efficacy” by suggesting “easy ways to reduce their meat consumption,” while the “low efficacy” group’s video “only included a very minor efficacy component in the conclusion.” The videos were 7 and 4 minutes long, respectively. Before the study, on the day of the study, and again a week later, participants were asked about their attitudes and intentions towards eating meat, as well as how much meat they’d eaten in the past 7 days.

Interventions with a health component typically combine it with other arguments, such as appeals to the environment [@jalil2023; @sparkman2021; @hennessy2016] or animal welfare [@feltz2022; @norris2014]. One noteworthy combination of intervention components comes from @bianchi2022, who provided participants with "free meat substitutes for the household for 4 weeks," "information leaflets about the health and environmental benefits of eating less meat," "recipes," and "success stories in the form of vignettes of people who reduced their meat intake" (p. 1358).

### 3.3 Red and processed meat consumption reduction efforts

```{r red_and_processed_meat_studies, echo=F, include=F}
RPMC <- read.csv("./data/RPMC-data.csv") |>
  group_by(title) |>
  mutate(unique_paper_id = cur_group_id())  |> 
  ungroup() |> 
  group_by(unique_paper_id, intervention_condition) |> 
  mutate(unique_study_id = cur_group_id()) |>
  ungroup() |>
  mutate(decade = as.factor(case_when(year >= 2000 & year <= 2009 ~ "2000s",
                                      year >= 2010 & year <= 2019  ~ "2010s",
                                      year >= 2020 ~ "2020s")),
         total_sample = n_c_post + n_c_post) |>
  select(author, year, title, unique_paper_id, unique_study_id, everything()) 

first_decade_RPMC_studies <- RPMC |> filter(year == 2005)

carfora_studies <- RPMC |> filter(str_detect(author, "Carfora"))
```

A subset of appeals to health focus on reducing red and/or processed meat consumption (RPMC) specifically. These studies typically provide information about health risks such as cancer, heart disease, and diabetes; highlight the environmental costs of raising and slaughtering cattle; or emphasize the sustainability of other choices, including fish and poultry.

We counted `r nrow(RPMC)` studies that meet our other criteria and look specifically at reducing RPMC. We consider these studies to be aiming at a related but fundamentally distinct estimand from those in our main database, and so we analyze them separately. We describe them here to provide a sense of their content, and in our meta-analysis, we analyze the RPMC separately as a point of comparison.

`r nrow(first_decade_RPMC_studies)` studies, all published in 2005 by researchers at the Dana-Farber Institute, advocate for reducing red meat as one of many behavioral strategies for reducing cancer risk. @emmons2005cancer randomized "ten community health centers...in low-income, multiethnic neighborhoods" to either usual care or "Healthy Directions–Health Centers" (p.1200) which used "n activities and materials" (p. 1201), e.g. motivational interviews, to persuade people to increase their fruit and vegetable consumption, activity, and multivitamin intake, while reducing red meat consumption. Self-reports indicated that "twelve percent of the intervention participants reduced red meat consumption to 3 or fewer servings per week" (p. 1203), compared to no change in the control group. @sorensen2005 tested "Healthy Directions-Small Business" a companion intervention, among "working-class, multiethnic populations employed in small manufacturing businesses" (p. 1389) and found small, statistically insignificant reductions in red meat consumption. Finally @emmons2005project targeted the same behaviors as the other two studies, along with alcohol consumption and smoking, among patients who were found to be at elevated risk of colon cancer in a health screening, and found significant decreases in red meat consumption, but no overall effect on fruit and vegetable consumption.

`r nrow(carfora_studies)` studies, published in `r length(unique(carfora_studies$unique_paper_id))` papers and all with Valentina Carfora as first author, test the effects of text-based reminders to reduce consumption or red or processed meat on Italian undergraduates [@carfora2017correlational; @carfora2017randomised; @carfora2019]. All three led to significant reductions in self-reported RPMC.

@klockner2017 and @dijkstra2022 tested different combinations of anti-meat messaging in online settings for Norwegians and Italians, respectively, and found a combination of null and backlash results.

Finally, one study from @piester2020 ranked items in a university cafeteria by their sustainability with a leaf-based diagram, where more leaves corresponded to more sustainable choices. For example meals with lobster or pork were given three leaves; meals with chicken were given either three or four leaves, depending on the dish, as was macaroni and cheese; while pad thai with tofu was given five leaves. The study found a moderate, statistically nonsigificant effect of being exposed to this rating system. (We did not include this study in our main analysis because it was possible to substitute from pork or lobster to chicken and show an improvement in the dependent variable).

## 5 Meta-analysis

We report all results as Glass's ∆, which standardizes by variance of the control group rather than of the entire population (we use variance of the entire sample when individual variances were not presented). We employ random effects meta-analysis. 

Further comments on our methods can be found in our appendix.

```{r main_results, echo=F, include=F}
library(dplyr)
library(metafor, quietly = T)
library(knitr)
library(purrr)
library(sessioninfo)
library(stringr)

source('./functions/d_calc.R')
source('./functions/var_d_calc.R')
source('./functions/study_count.R')
source('./functions/map_robust.R')

#' count_and_robust helper function;
#' necessary b/c `filter |> split |> imap()` didn't work for some reason

count_and_robust <- function(data) {
      bind_cols(study_count(data), map_robust(data))
  }
dat <- dat |>
  mutate(d = mapply(
        FUN = d_calc,
        stat_type = eff_type,
        stat =  u_s_d,
        sample_sd = ctrl_sd,
        n_t = n_t_post,
        n_c = n_c_post),
      var_d = mapply(
        FUN = var_d_calc,
        d = d,
        n_c = n_c_post,
        n_t = n_t_post),
      se_d = sqrt(var_d)) |> 
  select(-X) |>   
  select(author, year, title, unique_paper_id, unique_study_id, everything())

main_result <- dat |> count_and_robust()
sign_table <- table(dat$neg_null_pos)
null_proportion <- sign_table[[2]] / sum(sign_table)

# robustness checks: pre-analysis plan
pap_split <- dat |> mutate(has_pap = if_else(public_pre_analysis_plan == 'N', 0, 1)) |> 
  split(~has_pap) |>  
  map(count_and_robust)
pap_split[[1]]$Delta
```
 
### An overall null effect
Our meta-analysis of `r num_studies` policy-relevant interventions yields an overall meta-analytic effect of `r`main_result$Delta` (se = `rmain_result$se`), p =`r main_result$pval`. This is not a clinically or statistically significant effect.

A vote counting procedure [@bushman1994] demonstates the same point more starkly. In our sample, `r sign_table[[2]]` of `r num_studies` had, in the words of the relevant paper, no statistically significant effects (`r null_proportion` percent of all studies).`r sign_table[[1]]` studies had a statistically significant positive effect, while`r sign_table[[3]]` had a significant backlash effect.

This null finding stands in marked contrast to previous reviews, which found more positive results [@mathur2021meta; @mertens2022; @bianchi2018restructuring; @chang2023]. This disparity seems to be mostly explained by our focus measuring MAP consumption, as the largest results in prior reviews tended to be for intentions, attitudes, and hypothetical choices. This was the most common reason for our excluding otherwise eligible studies from our analysis. 

Figure 1 below shows the distribution of effect sizes in our sample. The dashed line in the figure below represents the overall meta-analytic effect, and the black points represent individual studies. The color of the points corresponds to the theoretical approach of the intervention.

```{r fig, echo=F}
library(ggplot2)
library(ggtext)
library(rlang)

bold_labels <- function(x) {
  ifelse(x == "RE Estimate", "<b>RE Estimate</b>", x)
}

model <- dat |> map_robust()

plot_dat <- dat |> 
  mutate(theory_category = if_else(str_detect(theory, "&"), "hybrid", theory),
         lower_bound = d - (1.96 * se_d),
         upper_bound = d + (1.96 * se_d)) |>
  select(author, year, d, se_d, lower_bound, upper_bound, theory_category) |> 
  add_row(author = "RE Estimate", year = NA, d = model$Delta, 
          lower_bound = model$Delta - (1.96 * model$se),
          upper_bound = model$Delta + (1.96 * model$se), 
          theory_category = NA) |>
  mutate(study_name = if_else(author == "RE Estimate", 
                              "RE Estimate", paste0(author, " ", year))) |>
  select(study_name, d, se_d, lower_bound, upper_bound, theory_category)

# Get unique study names excluding "RE Estimate"
unique_studies <- unique(plot_dat$study_name[plot_dat$study_name != "RE Estimate"])

# Append "RE Estimate" to the end of the list
ordered_levels <- c(unique_studies, "RE Estimate")

# Set this order to study_name
plot_dat$study_name <- reorder(factor(plot_dat$study_name, levels = ordered_levels), desc(plot_dat$se_d))

plot_dat |> ggplot(aes(x = d, y = study_name)) +
  geom_point(data = subset(plot_dat, study_name == "RE Estimate"), 
             size = 5, shape = 18) + # shape = 5 for a transparent diamond 
  geom_point(data = subset(plot_dat, study_name != "RE Estimate"), 
             aes(color = theory_category), size = 3, shape = 18) +
  geom_errorbarh(data = subset(plot_dat, study_name != "RE Estimate"), 
                 aes(xmin = lower_bound, xmax = upper_bound, color = theory_category),
                 height = .1) +
  geom_vline(xintercept = 0, color = "black", alpha = .5) +
  geom_vline(xintercept = model$Delta, 
             color = 'black', lty = 'dashed') +
  theme_minimal() +
  theme(axis.text.y = element_markdown()) +  # Apply HTML formatting to y-axis text
  scale_y_discrete(labels = bold_labels) +    # Use custom function for y-axis labels
  scale_x_continuous(name = expression(paste("Glass's", " ", Delta))) +
  labs(color = "Theory category") +
  ylab("Study") +
  ggtitle("Vegan meta forest plot") +
  theme(plot.title = element_text(hjust = 0.5,
                                  face = "bold"),
        legend.title = element_text(size = 15),
        legend.text = element_text(size = 12),
        axis.line = element_line(colour = "black")) 
```

```{r RPMC_supplementary_analysis, echo=F, include=F}
RPMC <- RPMC |>  mutate(d = mapply(
        FUN = d_calc,
        stat_type = eff_type,
        stat =  u_s_d,
        sample_sd = ctrl_sd,
        n_t = n_t_post,
        n_c = n_c_post),
      var_d = mapply(
        FUN = var_d_calc,
        d = d,
        n_c = n_c_post,
        n_t = n_t_post),
      se_d = sqrt(var_d)) |> 
  select(-X)

RPMC_model <- RPMC |> count_and_robust()
# vs...
dat |> count_and_robust()


```

### Red meat studies produce larger effects
By contrast, the `r nrow(RPMC)` studies looking to reduce consumption of red and/or processed meat produced an average effect of `r RPMC_model$Delta` (se = `r RPMC_model$se`), p = `r RPMC_model$pval`. We discuss this disparity further below.

### Some evidence of publication bias

```{r publication_bias, echo=F, include=F}
source('./functions/sum_lm.R')
eff_size_d_relationship <- dat |> sum_lm(d, se_d)

publication_type_eff_size <- dat |> mutate(pub_status = case_when(
    str_detect(venue, "dissertation|thesis") ~ "thesis",
    str_detect(venue, "advocacy") ~ "advocacy org publication",
    str_detect(doi_or_url, "osf\\.io") ~ "preprint",
    str_detect(doi_or_url, "10\\.") ~ "publication")) |> 
      split(~pub_status) |> imap(~count_and_robust(.x)); publication_type_eff_size
```

We observe a moderate, though statistically insignificant relationship between effect size and standard error (b = `r eff_size_d_relationship[2,1]`), p = `r eff_size_d_relationship[2,4]`,  meaning that larger effect sizes are more likely to be imprecise estimates in our sample Figure 2 displays this relationship, color coded by publication type.

```{r publication_bias_plot, echo=F, include=F}
dat |>  
  mutate(pub_status = case_when(
    str_detect(venue, "dissertation|thesis") ~ "thesis",
    str_detect(venue, "advocacy") ~ "advocacy org publication",
    str_detect(doi_or_url, "osf\\.io") ~ "preprint",
    str_detect(doi_or_url, "10\\.") ~ "publication")) |>
  ggplot(aes( x = se_d, y = d)) +
  geom_point(aes(color = pub_status), size = 2) +
  geom_smooth(method = "lm", color = "black", lty = "dotted", se = F) +
  theme_minimal() +
  labs(x = "Standard error", y = "Glass's \u0394", color = "Publication type") +
  ggtitle("Relationship between standard errors and effect sizes") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5,
                                  face = "bold")) 
```

As this graph suggests, we observe that dissertations and technical reports (mostly published by animal advocacy organizations) 

This suggests that publication bias is not a major concern in our sample. We also observe that `r publication_type_eff_size$preprint$N_unique` of `r num_studies` studies are preprints, while `r publication_type_eff_size$publication$N_unique` are published papers.

We also not that a null finding on MAP consumption is equivalent to a null result overall, because papers typically present multiple dependent variables and/or subgroup analyses. @allen2002, for example, report that "red and white meat consumption for both treatment and control groups remained constant" (p. 124), but write in their abstract that "most participants" in the treatment group reported less favorable impressions of meat, less "object identification" with meat, and greater self-reported consumption of fruits and vegetables three weeks later (p. 118). Likewise, @piester2020, over three studies, find two null effects and one significantly positive effect on MAP consumption overall, but find that women typically responded to treatment while men did not, and present gender-based results in their abstract.

### Translating standardized effect sizes to real world changes
The specific dependent variables in this literature, as well as the different variances between populations, make it challenging to generate a "rule of thumb" for translating standardized effect sizes to real-world changes. However, we can say that the average effect size in our sample is small, and that the largest effect sizes in the literature are also small. For example, @jalil2023 found that students in the treatment group reduced their meat consumption by 5.6 percentage points with no signs of reversal over 3 years. This corresponds to Glass's ∆ of 0.118. The largest effect size in the literature comes from @bianchi2022, who found a decline in meat consumed of 12 grams per day for the control group and 49 grams per day for the treatment, for a difference in difference of 37 grams per day. Relative to a standard deviation of 70 grams for the control group, this represents a Glass's ∆ of 0.52.

As an example of a backlash result, study one in @feltz2022

### Comparing theoretical approaches
```{r theoretical_approaches, echo=F, include=F}
norms_results <- dat |> filter(str_detect(theory, "norms")) |> count_and_robust(); norms_results

nudge_results <- dat |> filter(str_detect(theory, "nudge")) |> count_and_robust(); nudge_results

health_results <- dat |> filter(str_detect(secondary_theory, "health")) |> count_and_robust(); health_results

environment_results <- dat |> filter(str_detect(secondary_theory, "environment")) |> count_and_robust(); environment_results

animal_welfare_results <- dat |> filter(str_detect(secondary_theory, "animal welfare")) |> count_and_robust(); animal_welfare_results

# for general comparison
persuasion_results <- dat |> filter(str_detect(theory, "persuasion")) |> count_and_robust(); persuasion_results

```

Table XXX presents the results of our meta-analysis by theoretical approach. Note that because many studies present overlapping approaches, the numbers in this table do not sum to the total number of studies in our sample.

Nudges are generally the most effective approach in our subset, producing statistically significant results that correspond to a small effect size by convention. However, they are also the smallest set of studies (`r nudge_results$N_unique` of `r num_studies` studies). Health and environmental appeals, though substantively small effect sizes, produce statistically significant changes as well. Animal welfare appeals and norms-based approaches do not produce statistically or substantively significant changes in MAP consumption.

| Approach         | N (studies)                 | ∆ (se)                           |
|------------------|-----------------------------|----------------------------------|
| Norms            | `r norms_results$N_unique`  | `r norms_results$Delta` (`r norms_results$se`)`r ifelse(norms_results$pval < 0.001, "***", ifelse(norms_results$pval < 0.01, "**", ifelse(norms_results$pval < 0.05, "*", "")))` |
| Nudge            | `r nudge_results$N_unique`  | `r nudge_results$Delta` (`r nudge_results$se`)`r ifelse(nudge_results$pval < 0.001, "***", ifelse(nudge_results$pval < 0.01, "**", ifelse(nudge_results$pval < 0.05, "*", "")))` |
| Health           | `r health_results$N_unique` | `r health_results$Delta` (`r health_results$se`)`r ifelse(health_results$pval < 0.001, "***", ifelse(health_results$pval < 0.01, "**", ifelse(health_results$pval < 0.05, "*", "")))` |
| Environment      | `r environment_results$N_unique` | `r environment_results$Delta` (`r environment_results$se`)`r ifelse(environment_results$pval < 0.001, "***", ifelse(environment_results$pval < 0.01, "**", ifelse(environment_results$pval < 0.05, "*", "")))` |
| Animal Welfare   | `r animal_welfare_results$N_unique` | `r animal_welfare_results$Delta` (`r animal_welfare_results$se`)`r ifelse(animal_welfare_results$pval < 0.001, "***", ifelse(animal_welfare_results$pval < 0.01, "**", ifelse(animal_welfare_results$pval < 0.05, "*", "")))` |


```{r norms_in_more_detail, echo=F, include=F}
dynamic_norms_results <- dat |> filter(str_detect(brief_description, "dynamic")) |> count_and_robust(); dynamic_norms_results

static_norms_results <- dat |> filter(str_detect(brief_description, "static")) |> count_and_robust(); static_norms_results

```

Dynamic norms interventions appear to be more effective than static norms interventions: `r dynamic_norms_results$Delta` (se = `r dynamic_norms_results$se`), p = `r dynamic_norms_results$pval` versus `r static_norms_results$Delta` (se = `r static_norms_results$se`), p =`r static_norms_results$pval`.

### Internet, video, and pamphlet studies are ineffective

```{r delivery_methods, echo=F, include=F}

internet_results <- dat |> filter(str_detect(internet, "Y")) |> count_and_robust(); internet_results

pamphlet_results <- dat |> filter(str_detect(leaflet, "Y")) |> count_and_robust(); pamphlet_results

video_results <- dat |> filter(str_detect(video, "Y")) |> count_and_robust(); video_results

place_based_results <- dat |> filter(dat$cafeteria_or_restaurant_based == "Y") |> count_and_robust(); place_based_results

```

We now turn to the question of method of delivery. Table XXX reports our results.

| Method of Delivery           | N (studies)                          | ∆ (se)                              |
|------------------------------|--------------------------------------|-------------------------------------|
| Internet                     | `r internet_results$N_unique`        | `r internet_results$Delta` (`r internet_results$se`)`r ifelse(internet_results$pval < 0.001, "***", ifelse(internet_results$pval < 0.01, "**", ifelse(internet_results$pval < 0.05, "*", "")))` |
| Pamphlet                     | `r pamphlet_results$N_unique`        | `r pamphlet_results$Delta` (`r pamphlet_results$se`)`r ifelse(pamphlet_results$pval < 0.001, "***", ifelse(pamphlet_results$pval < 0.01, "**", ifelse(pamphlet_results$pval < 0.05, "*", "")))` |
| Video                        | `r video_results$N_unique`           | `r video_results$Delta` (`r video_results$se`)`r ifelse(video_results$pval < 0.001, "***", ifelse(video_results$pval < 0.01, "**", ifelse(video_results$pval < 0.05, "*", "")))` |
| Place-based (Cafeteria/Restaurant) | `r place_based_results$N_unique` | `r place_based_results$Delta` (`r place_based_results$se`)`r ifelse(place_based_results$pval < 0.001, "***", ifelse(place_based_results$pval < 0.01, "**", ifelse(place_based_results$pval < 0.05, "*", "")))` |

Here we see that internet-based and video interventions are not effective. Pamphlet/leaflet studies produce an overall backlash effect, though this is not statistically significant. 

Place-based interventions, such as those in cafeterias or restaurants, are comparatively more effective, though still not statistically significant overall.

### self-report measures are not systematically different

Based on past research, we expected to see evidence of self-report bias
### delay?

### country? 

### meat vs MAP

### Robustness to markers of study quality

### effect size over time

### Addressing other sources of potential bias


###  MetaUtility::prop_stronger

## Discussion

### The central unanswerewd question of interMAP substitution
Given our disappointing central findings -- a general lack of efficacy on reducing overall MAP consumption -- the most important outstanding question in our meta-analysis is how much of the gap between general effects and RPMC effects is driven by substitution to other MAP products. Evidence from the literature on this question are mixed, in part because the available dependent variables are not very fine grained. For instance, @emmons2005project, @emmons2005cancer, and @sorensen2005 measure changes in red meat as well as changes in fruit and vegetable intake, but do not measure consumption of other categories of MAP or of grains and legumes. @carfora2017correlational, @carfora2017randomised and @carfora2019 all measure just consumption of either red or processed meat. Interestingly, @jalil2023, though not targeting RPMC specifically, records changes in beef, poultry, fish, and vegetarian meals, and finds larger reductions in poultry and fish than it does for red meat.^[to fill in: some other studies answer related questions, e.g.https://www.sciencedirect.com/science/article/abs/pii/S2212267222010711]

A few papers explicitly advocate that people substitute:
  -   [Klockner and Ostad (2017)](http://dx.doi.org/10.1016/j.jenvp.2017.01.006) advocate that people reduce RMC by three strategies: "reduce portion size for beef, substitute beef with other meats or fish, and increase the number of vegetarian meals)." But they don't measure anything besides RMC.
  - [Lohman et al. (2022](https://doi.org/10.1016/j.jeem.2022.102693)) find reductions in red meat, increases in some fish dishes, decreases in others, and an uptick in vegan/vegetarian meals (they don't have enough clusters to meet our sample size standards). [Larner et al. (2021)](https://kobra.uni-kassel.de/themes/Mirage2/scripts/mozilla-pdf.js/web/viewer.html?file=/bitstream/handle/123456789/12593/fofjVol9No1Art5.pdf?sequence=1&isAllowed=y#pagemode=thumbs') encourage substitution to poultry and eggs by labeling them low-impact, but again, don't report their outcomes in a way that would allow us to distinguish.

How much a policymaker should worry about this gap in our understanding depends on their goals For those focused on health, any reduction in red meat is good news, particularly the relatively large effects in [one emmons and one other ], which are aimed at people at elevated risk of cancer. From an environmental perspective, red and processed meats are also the highest-priority target, though we note that none of the reductions we see in the literature, even if they were scaled up perfectly without loss of efficacy, would make much of a dent on GHG emissions. Last, from an animal welfare perspective, the gap between regular effects and RPMC effects is potentially disastrous if it means people are substituting from red meat to other kinds of MAP that create more harms per meal.

Even interpreting the RPMC results in the most optimistic light, however -- assuming that all of the effect sizes are driven by reductions in red meat consumption -- the overall effect sizes are still quite small. Anyone envisioning a radical change in how we produce and consume food will have trouble finding satisfying answers in this literature. Even @jalil2023, arguably the strongest study in the literature in terms of long-term, objective measurement, is still a test of a few hundred students at one elite liberal arts college. There are grounds for doubting its broad applicability (though we encourage decision-makers at comparable schools to heed its lessons).

### Are our small results surprising? 

That depends what literature you're reading. If you read the food literature, you might be shocked to see we don't find anything. If we had to guess, we'd say this is probably driven _most_ by our looking only at actual MAP consumption, which we have prior reason to think does not line up very well with intentions and attitudes [@mathur2021effectiveness]. On the other hand, the broader literature on behavior change, finds
* self-reported intentions don't predict behavior [@kormos2014; @hassan2016],
* neither do attitudes [@porat2024];
* the best RCTs don't scale [@dellavigna2022];
* and the kinds of structural interventions that actually change deep-seated habits are hard to evaluate in an RCT. As @stevenson2023 so aptly puts it: "When it comes to the type of limited-scope interventions that lend themselves to high-quality evaluation, social change is hard to engineer."


### Where should researchers go from here?
  -   Let's start by filling in some obvious gaps.
  -   Do a RPMC reduction study and assess effects on other MAP products too 😃
  -   these studies are remarkably geographically concentrated. We lack rigorous evaluations of MAP reduction efforts in Latin America, Asia, and Africa.
  -  price interventions! constraints vs. preferences, focus on constraints! (Tabarrok piece on crime)
  -  @piester2020 find that food sustainability labels had a significant impact on women but very little impact on men. Should anti-MAP strategies generally be gender-tailored? (See [Veul 2018](https://theses.ubn.ru.nl/items/fcd6b5e7-7981-4086-aca0-4da7d28d42b2) for further discussion.)
  - How much is animal welfare advocacy activating [disgust](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3189352/) [avoidance](https://www.nature.com/articles/s41598-021-91712-3) vs. empathy for animals? e.g. If videos of farmed animal lives show especially squalid or pathogenic living conditions, or if pamphlets about dairy cows talk about the [allowable level](https://genv.org/pus-in-milk/)of [blood and pus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7649072/) in milk products, which theoretical perspective are these interventions embodying, or could empathy and disgust be compared to one another?
  -   Do changes to menus or restaurant layouts have effects on treated consumers a week or two later, rather than just the day of? Most studies with these designs only measure outcomes while treatment is being administered or during the control period, but we also care about lasting changes in habits.REGRESSION TO THE MEAT
  -   one study ([Sparkman et al. 2020](https://www.mdpi.com/2071-1050/12/6/2453)) partnered with a grocery/restaurant delivery or meal prep service (which “abruptly closed” in the middle of their experiment). We think this is a promising strategy for deploying large-scale interventions and measuring real-world behavior. Perhaps someone at the [economics team at Instacart](https://tech.instacart.com/the-economics-team-at-instacart-94c48db951e8) is interested in pursuing this?

For policymakers, what we think works and doesn't overall:       
  magine that we magically were able to scale these interventions up to the entire western world
.2 Policy lessons?
 - don't run a leaflet study and expect it to work. We need new leaflets or new approaches.
 - Ditto with online
 - If you're a college administrator at an elite west coast college, the Jalil et al stuff is a great start,but awaiting replication. 10 classrooms is not very much.
 - no handle whatsoever on what gets people to change outside of a dining hall

### Bibliography
