---
classoptions: 
  - sn-nature      
  - referee         # Optional: Use double line spacing 
  # - lineno        # Optional: Add line numbers
  # - iicol         # Optional: Double column layout
title: "Meaningfully reducing consumption of meat and animal products is an unsolved problem: results from a meta-analysis"
titlerunning: MAP-reduction-meta
authors: 
  - firstname: Seth Ariel
    lastname: Green
    email: setgree@stanford.edu
    affiliation: 1
    corresponding: TRUE
  - firstname: Maya B.
    lastname: Mathur
    affiliation: 1
  - firstname: Benny
    lastname: Smith 
    affiliation: 2
affiliations:
  - number: 1
    info:
      orgdiv: Humane and Sustainable Food Lab
      orgname: Stanford University
  - number: 2
    info:
      orgname: Allied Scholars for Animal Protection 
keywords:
  - meta-analysis
  - meat
  - plant-based
  - randomized controlled trial
  
abstract: |
  Which theoretical approach leads to the broadest and most enduring reductions in consumptions of meat and animal products (MAP)? We address these questions with a theoretical review and meta-analysis of rigorous randomized controlled trials with consumption outcomes. We meta-analyze 36 papers comprising 42 studies, 114 interventions, and approximately 88,000 subjects. We find that these papers employ four major strategies to changing behavior: choice architecture, persuasion, psychology, and a combination of persuasion and psychology. The pooled effect of all 114 interventions on MAP consumption is SMD = 0.065, indicating an unsolved problem. Reducing consumption of red and processed meat is an easier target: SMD = 0.249, but because of missing data on potential substitution to other MAP, we can’t say anything definitive about the consequences of these interventions on animal welfare. We further explore effect size heterogeneity by approach, population, and study features. We conclude that while no theoretical approach provides a proven remedy to MAP consumption, designs and measurement strategies have generally been improving over time, and many promising interventions await rigorous evaluation.
date: "`r Sys.Date()`"
output: 
  rticles::springer_article:
    keep_tex: true
    keep_md: true

bibliography: "./vegan-refs.bib"
editor_options: 
  chunk_output_type: console
header-includes:
  - \usepackage{comment}
  - \usepackage{anyfontsize}
  - \usepackage{caption}
  - \usepackage{float}      # For precise float placement
  - \usepackage{placeins}   # Provides \FloatBarrier command
---

```{r setup, include=FALSE}

# directory modifications so we can put the manuscript stuff in its own folder
library(knitr)
library(rprojroot)
opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
setwd(find_rstudio_root_file())

# so that knitr labels figures
knitr::opts_chunk$set(fig.path = "./figures/",
                      echo = FALSE,
                      out.extra = "")
options(tinytex.clean = TRUE) # switch to FALSE to get the bbl file for overleaf
# libraries
source('./scripts/libraries.R')

# functions and data
source('./scripts/functions.R')
source('./scripts/load-data.R')
```

# Introduction {#sec1}

Reducing global consumption of meat and animal products (MAP) is vital to reducing chronic disease and the risk of zoonotic pandemics [@willett2019; @landry2023; @hafez2020], abating environmental degradation and climate change [@poore2018; @koneswaran2008; @greger2010], and improving animal welfare [@kuruc2023; @scherer2019].
However, MAP is widely regarded as normal, necessary, and a dietary staple [@piazza2022; @milford2019].
Global MAP consumption is increasing annually [@godfray2018] and expected to continue doing so [@whitton2021].

There is a vast and diverse literature investigating potential means to reverse this trend.
Example approaches include providing free access to meat substitutes [@katare2023], changing the price [@horgen2002] or perceptions [@kunst2016] of meat, or attempting to persuade people to change their diets [@bianchi2018conscious].
A large portion of this literature seeks to alter the contexts in which MAP is selected [@bianchi2018restructuring], for instance by changing menu layouts [@bacon2018; @gravert2021] or placing vegetarian items more prominently in dining halls [@ginn2024].
Some interventions are associated with large impacts [@hansen2021; @boronowsky2022; @reinders2017], and prior reviews have concluded that some frequently studied approaches, such as using persuasive messaging that appeals to animal welfare [@mathur2021meta] or making vegetarian meals the default [@meier2022] may be consistently effective.
Governments, universities, and other institutions are increasingly implementing these ideas in such settings as dining halls [@pollicino2024] and hospital cafeterias [@morgenstern2024].

However, much of this literature is beset by design and measurement limitations.
Many interventions are either not randomized [@garnett2020] or underpowered [@delichatsios2001].
Others record outcomes that are imperfect proxies MAP consumption, such as attitudes and intentions [@mathur2021effectiveness], yet behaviors often do not track with these psychological processes [@porat2024].
Further, many studies measure only immediate impacts [@hansen2021; @griesoph2021] rather than longer-term effects, or focus on hypothetical choices [@raghoebar2020; @vermeer2010].
Last, numerous studies that aim to reduce consumption of red and processed meat (RPM) may induce people to switch to other forms of MAP, such as chicken or fish [@grummon2023].
While RPM is of special concern for health and greenhouse gas emissions [@abete2014; @auclair2024], increasing chicken or fish consumption may lead to substantially worse outcomes for animal welfare [@mathur2022ethical], and fails to reduce the risk of zoonotic outbreaks from factory farms [@hafez2020] or land and water pollution [@grvzinic2023].

In the past few years, a new wave of MAP reduction research has made commendable methodological advances in design, outcome measurement validity, and statistical power.
Historically, in some scientific fields, strong effects detected in early studies with methodological limitations were ultimately overturned by more rigorous follow-ups [@wykes2008; @paluck2019; @scheel2021].
Does this phenomenon hold in the MAP reduction literature as well?

```{r models_and_constants, include=F}
# Models
## Overall
model <-robumeta::robu(formula = d ~ 1, data = dat, studynum = unique_study_id, 
                       var.eff.size = var_d, modelweights = 'CORR', small = TRUE)


## Extract and format key results for each model
overall_results <- extract_model_results()
rpmc_results <- RPMC |> extract_model_results()

# constants
num_papers <- as.numeric(max(dat$unique_paper_id))
num_studies <- as.numeric(max(dat$unique_study_id))
num_interventions <- as.numeric(nrow(dat))

n_total <- noquote(format(round_to(x = sum(dat$n_c_total_pop) + sum(dat$n_t_total_pop), 
                                  accuracy = 1000, direction = "down"),
                         big.mark = ",", scientific = FALSE))

decade_tab <- dat |> group_by(unique_paper_id) |>  slice(1) |>  ungroup() |> count(decade)

RPMC_papers <- as.numeric(max(RPMC$unique_paper_id))
```

We answer this question with a meta-analysis of rigorously designed RCTs aimed at creating lasting reductions in MAP consumption [@andersson2021; @kanchanachitra2020; @abrahamse2007; @acharya2004; @banerjee2019; @bianchi2022; @bochmann2017; @bschaden2020; @carfora2023; @cooney2014; @cooney2016; @feltz2022; @haile2021; @hatami2018; @hennessy2016; @jalil2023; @mathur2021effectiveness; @merrill2009; @norris2014; @peacock2017; @polanco2022; @sparkman2021; @weingarten2022; @piester2020; @aldoh2023; @allen2002; @camp2019; @coker2022; @sparkman2020; @berndsen2005; @bertolaso2015; @fehrenbach2015; @mattson2020; @shreedhar2021].
These RCTs all measured consumption outcomes at least a single day after treatment was first administered, and all had at least 25 subjects in both treatment and control, or, in the case of cluster-assigned studies, at least ten clusters in total.
Additionally, we coded a separate dataset of `r RPMC_papers` papers that otherwise met our inclusion criteria but instead measured changes in consumption of RPM [@anderson2017; @carfora2017correlational; @carfora2017randomised; @carfora2019; @carfora2019informational; @delichatsios2001talking; @dijkstra2022; @emmons2005cancer; @emmons2005project; @jaacks2014; @james2015; @lee2018; @lindstrom2015; @perino2022; @schatzkin2000; @sorensen2005; @wolstenholme2020].

Studies in our meta-analytic database pursued one of four theoretical approaches: choice architecture (the manipulation of how MAP is presented to diners), psychological appeals (typically manipulations of perceived norms around eating meat), explicit persuasion (centered around animal welfare, the environment, and/or health), or a combination of psychological and persuasion messages.
Interventions varied in delivery method, for example, documentary films [@mathur2021effectiveness], leaflets [@peacock2017], university lectures [@jalil2023], op-eds [@haile2021], and changes to menus in cafeterias [@andersson2021] and restaurants [@coker2022; @sparkman2021].

We estimated overall effect sizes as well as effect sizes associated with different theoretical approaches and delivery mechanisms.
Although we find some heterogeneity across theories and mechanisms, we find consistently smaller effects on MAP consumption than previous reviews have suggested [@bianchi2018restructuring; @byerly2018; @chang2023; @harguess2020; @kwasny2022; @mathur2021meta; @meier2022; @pandey2023], with some intriguing exceptions.
Thus, contradicting previous reviews that analyzed a wider array of designs and outcomes, we conclude that meaningfully reducing MAP consumption is an unsolved problem.
However, many promising approaches still await rigorous evaluation.

# Results {#sec2}

## Descriptive overview {#sec2.1}

Our meta-analysis included `r num_papers` papers comprising `r num_studies` studies, and `r num_interventions` separate point estimates, each corresponding to a distinct intervention.
The total sample size was `r n_total` subjects (caveat that this is a broad approximation: many interventions were administered at the level of day or cafeteria and did not record how many individuals were assigned to treatment).

```{r mean_subjects, include=F}
total_pops <- dat |> filter(cluster_assigned == 'N') |> mutate(total_pop = as.numeric(n_c_post + n_t_post)) |> pull(total_pop)

median_total_pop <- round(median(total_pops, na.rm = TRUE))
percentile_25 <- round(quantile(total_pops, 0.25, na.rm = TRUE))
percentile_75 <- round(quantile(total_pops, 0.75, na.rm = TRUE))
```

The earliest paper was published in 2002 [@allen2002], and a majority (`r  decade_tab |> filter(decade == "2020s") |> pull(n)` of `r num_papers` papers) were published since 2020.
Among studies where treatment was assigned to individuals rather than by clusters, the median analyzed sample size per study was `r median_total_pop` subjects (25th percentile: `r percentile_25`; 75th percentile: `r percentile_75`).

## Constituent Theories {#sec2.2}

**Choice Architecture** studies [@andersson2021; @kanchanachitra2020] manipulate aspects of physical environments to reduce MAP consumption, such as placing the vegetarian option at eye level on a cafeteria menu [@andersson2021].

**Persuasion** studies [@kanchanachitra2020; @abrahamse2007; @acharya2004; @banerjee2019; @bianchi2022; @bochmann2017; @bschaden2020; @carfora2023; @hennessy2016; @piester2020; @cooney2014; @cooney2016; @feltz2022; @haile2021; @hatami2018; @jalil2023; @mathur2021effectiveness; @merrill2009; @norris2014; @peacock2017; @polanco2022; @sparkman2021; @weingarten2022] Such messages are often delivered through printed materials, such as leaflets [@haile2021; @polanco2022], booklets [@bianchi2022] articles and op-eds [@sparkman2021; @feltz2022], and videos [@sparkman2021; @cooney2016; @mathur2021effectiveness].
Less common delivery methods included in-person dietary consultations [@merrill2009], emails [@banerjee2019], and text messages [@carfora2023].
Arguments focus on health, the environment (usually climate change), and animal welfare.

\begin{comment}
Some are designed to be emotionally activating, e.g. presenting upsetting footage of factory farms [@polanco2022], while others present information more factually, for instance about the relationship between diet and cancer [@hatami2018].
Many persuasion studies combine arguments, such as a lecture on the health and environmental consequences of eating meat
These studies formed the majority of our database.
\end{comment}

**Psychology** studies [@aldoh2023; @allen2002; @camp2019; @coker2022; @piester2020; @sparkman2020] manipulate the interpersonal,cognitive, or affective factors associated with eating meat.
The most common psychological intervention is centered on social norms seeking to alter the perceived popularity of non-MAP dishes [@sparkman2020].
In one study, a restaurant put up signs stating that "[m]ore and more [retail store name] customers are choosing our veggie options" [@coker2022].
In another, a university cafeteria put up signs stating that "[i]n a taste test we did at the [name of cafe], 95% of people said that the veggie burger tasted good or very good! Consider giving the garden fresh veggie burger a try today!” [@piester2020]. One study told participants that people who ate meat are more likely to endorse social hierarchy and embrace human dominance over nature, making meat-eaters out to be a counter-normative outgroup [@allen2002]. Other psychological interventions include response inhibition training, where subjects are trained to avoid responding impulsively to stimuli such as unhealthy food [@camp2019].

\begin{comment}
Norms might be descriptive, stating how many people engaged in the desired behavior [@aldoh2023], or dynamic, telling subjects that the number of people reducing their MAP consumption is increasing over time [@aldoh2023; @coker2022; @sparkman2020].
Another study looked at response inhibition training, where subjects are trained to associate meat with an inhibiting response [@camp2019].
The first psychology study meeting our inclusion criteria was published in 2017.
\end{comment}

Finally, a group of interventions combines **persuasion** approaches with **psychological** appeals to reduce MAP consumption [@berndsen2005; @bertolaso2015; @carfora2023; @fehrenbach2015; @hennessy2016; @mathur2021effectiveness; @mattson2020; @piester2020; @shreedhar2021].
These studies typically combine a persuasive message with a norms-based appeal [@piester2020; @mattson2020] or an opportunity to pledge to reduce one's meat consumption [@mathur2021effectiveness; @shreedhar2021].

## Meta-analytic results {#sec2.3}

```{r needed_vars, include=F}
low_prop_test <- prop_stronger( q = 0.1, M = overall_results$Delta,
                                t2 = overall_results$tau^2,
                                se.M = overall_results$SE, tail = "above",
                                estimate.method = "calibrated",
                                ci.method = "calibrated", dat = dat,
                                yi.name = "d", vi.name = "var_d",
                              bootstrap = "ifneeded", R = 200) |> 
   mutate(across(1:6, \(x) round(x, 3)))
low_prop_test
high_prop_test <- prop_stronger( q = 0.2,  M = overall_results$Delta,
                                t2 = overall_results$tau^2,
                                se.M = overall_results$SE, tail = "above",
                                estimate.method = "calibrated",
                                ci.method = "calibrated", dat = dat,
                                yi.name = "d", vi.name = "var_d",
                              bootstrap = "ifneeded", R = 200) |> 
     mutate(across(1:6, \(x) round(x, 3)))
high_prop_test
```

In our dataset, the pooled effect of all interventions is SMD = `r overall_results$Delta` (95% CI: `r overall_results$CI`), p = `r overall_results$p_val`, $\tau$ (standard deviation of population effects) = `r overall_results$tau`.
We estimate that `r round(low_prop_test$est * 100, 2)`% of true effects are above SMD = 0.1, and just `r round(high_prop_test$est * 100,2)`% are above SMD = 0.2.

Table 1 compares the overall meta-analytic estimate to the subgroup estimates associated with the four major theoretical approaches, as well as the three categories of persuasion.

\begin{center}
[Table 2 about here]
\end{center}
\begin{center}
[Figure 1 about here]
\end{center}

```{r rpmc_and_merged_stats, include=F}

red_high_prop_test <- prop_stronger( q = 0.2, M = rpmc_results$Delta,
                                     t2 = rpmc_results$tau^2,
                                se.M = rpmc_results$SE, tail = "above",
                                estimate.method = "calibrated",
                                ci.method = "calibrated", dat = RPMC,
                                yi.name = "d", vi.name = "var_d",
                              bootstrap = "ifneeded", R = 200) |> 
     mutate(across(1:6, \(x) round(x, 3)))

merged_model <- merged_dat |> robu(formula = d ~ 1, studynum = unique_study_id, 
                 var.eff.size = var_d, modelweights = 'CORR', small = TRUE)
merged_results <- merged_dat |> extract_model_results()

```

By contrast, studies that only attempted to reduce consumption of RPM had larger estimates: across these 17 studies and 25 estimates, we detect a pooled effect of SMD = `r merged_results$Delta` (95% CI: `r merged_results$CI`), p = `r rpmc_results$p_val`, $\tau$ = `r merged_results$tau`.
We estimate that `r round(red_high_prop_test$est * 100, 2)`% of true effects are above SMD = 0.2.

Meta-analyzing the MAP and RPM studies combined yields an overall estimate of SMD = `r round(merged_model$reg_table$b.r, 3)` (95% CI: `r merged_results$CI`), p = `r merged_results$p_val`, $\tau$ = `r merged_results$tau`.

## Meta-regression on study characteristics analysis {#sec2.4}

Table 2 displays average differences in effect size by study population, region, era of publication, and delivery method.

\begin{center}
[Table 2 about here]
\end{center}

## Sensitivity Analyses {#sec2.5}

Table 3 presents average differences by publication status, data collection strategy, and open science practices.

\begin{center}
[Table 3 about here]
\end{center}

```{r publication_bias, include=F, message=F}
pub_bias_corrected_estimate <- pubbias_meta(yi = dat$d, vi = dat$var_d, cluster = dat$unique_study_id, model_type = 'robust', favor_positive = TRUE, alpha_select = .05, small = TRUE, selection_ratio = 2)

pub_bias_estimate <- round(pub_bias_corrected_estimate$stats$estimate, 3)
pub_ci_lower <- round(pub_bias_corrected_estimate$stats$ci_lower, 2)
pub_ci_upper <- round(pub_bias_corrected_estimate$stats$ci_upper, 2)
pub_ci_p_val <- round(pub_bias_corrected_estimate$stats$p_value, 3)

nulls <- dat |> filter(neg_null_pos == 0| neg_null_pos == -1)
worst_case <- extract_model_results(data = nulls)

```

\begin{comment}
The meta-analytic mean corrected for publication bias [@hedges1992], which assumes that significant, positive results are twice as likely to be published as anything else, is SMD = r pub_bias_estimate (95% CI: [r paste0(pub_ci_lower, ", ", pub_ci_upper)]), p = r pub_ci_p_val.
\end{comment}

As assessment of worst-case publication bias that analyzes only null and negative results [@mathur2024] yields an estimate of SMD = `r worst_case$Delta` (95% CI: `r worst_case$CI`), p = `r worst_case$p_val`.
Figure 2 is a significance funnel plot [@mathur2020] that relates studies’ point estimates to their standard errors and compares the pooled estimate within all studies (black diamond) to the worst-case estimate (grey diamond).

\begin{center}
[Fig 2 about here]
\end{center}
\begin{comment}
should this be a supplementary fig?
\end{comment}

# Methods {#sec3}

```{r methods_nums, include=F}
reviews_count <- nrow(read.csv('./data/review-of-reviews.csv'))
excluded_count <- nrow(read.csv('./data/excluded-studies.csv'))

robustness_count <- read.csv("./data/robustness-data.csv") |>
  group_by(title) |>
  mutate(unique_paper_id = cur_group_id()) |>
  ungroup() |>
  group_by(inclusion_exclusion) |>
  summarise(cnt = n_distinct(unique_paper_id)) |>
  mutate(inclusion_exclusion = as.character(inclusion_exclusion))

# Add the sum row after the main pipe
robustness_count <- robustness_count |>
  bind_rows(tibble(inclusion_exclusion = "sum", cnt = sum(robustness_count$cnt)))

```

## Study selection {#sec3.1}

As previously detailed, our meta-analytic sample comprises randomized controlled trial evaluations of interventions intended to reduce MAP consumption that had at least 25 subjects in treatment and control (or at least 10 clusters for studies that were cluster-assigned) and that measured MAP consumption at least a single day after treatment begins.
We required that studies have a pure control group receiving no treatment.
We further restricted our search to studies that were publicly circulated in English by December 2023.

We also made two consequential post-hoc decisions regarding study inclusion: to count reductions in red and processed meat as a separate estimand and to analyze them separately, and to exclude studies that sought to induce substitution from one kind of MAP to another, e.g. swapping red meat with fish.

Given our interdisciplinary research question and previous work indicating a large grey literature [@mathur2021meta], we designed and carried out a customized search process We 1) reviewed `r reviews_count` prior reviews, nine of which yielded included articles [@mathur2021meta; @bianchi2018conscious; @bianchi2018restructuring; @ammann2023; @chang2023; @DiGennaro2024; @harguess2020; @ronto2022; @wynes2018]; 2) conducted backwards and forward citation search; 3) reviewed published articles by authors with papers in the meta-analysis; 4) contacted leading researchers in the field to check our in-progress search; 5) searched Google Scholar for terms that had come up in studies repeatedly; 6) used an AI search tool to search for gray literature (\url{https://undermind.ai/}); and 7) checked a database emerging from an ongoing nonprofit project that seeks to identify all papers on meat-reducing interventions (see supplement for details).

All three authors contributed to the search.
Inclusion/exclusion decisions were primarily made by the first author, with all authors contributing to discussions about borderline cases.

See supplement for PRISMA diagram.
See code and data repository for details on the `r reviews_count` prior reviews we consulted and approximately `r excluded_count` papers we excluded.

## Data extraction {#sec3.3}

The first author extracted all data.
We extracted an effect size for one outcome per intervention: the latest possible measure of net MAP or RPM consumption.
Sample sizes corresponded to the same time point.
Additional variables coded included information about publication, details of the interventions, length of delay, intervention theories, and additional details about interventions' methods, contexts, and open science practices (see supplement).

When in doubt about calculating effect sizes, we consulted available datasets and/or contacted authors.

To assess risk of bias, we collected data on whether outcomes were self-reported or objectively measured, publication status, and presence of a pre-analysis plan and/or open data (see table 3).

All effect size conversions were conducted by the first author using methods and R code initially developed for previous papers [@paluck2019; @paluck2021; @porat2024] using standard techniques from [@cooper2019], with the exception of a difference in proportion estimator that treats discrete events as draws from a Bernoulli distribution (see appendix to [@paluck2021] for details).

## Statistical analysis methods {#sec3.4}

Results were synthesized using robust variance estimation (RVE) methods [@hedges2010] as implemented by the robumeta package [@fisher2015] in R [@Rlang].
Many studies in our sample featured multiple treatment groups compared to a single control group.
Therefore, we used the RVE method to allow for the resulting dependence between observations, as well as a standard small-sample correction.
Data analyses were largely conducted with custom functions building on tidyverse [@wickham2019] and publication bias was assessed using PublicationBias [@mathur2024; @mathur2020].
[SAY MORE ABOUT THESE METHODS]

We used `Rmarkdown` [@xie2018] and a containerized [@moreau2023] online platform [@clyburne2019] to ensure computational reproducibility [@polanin2020].

# Discussion

Our overall effect of SMD = `r overall_results$Delta`, as well as our upper confidence bound of SMD = `r round(model$reg_table$CI.U, 2)`, lead us to conclude that reducing MAP consumption is an unsolved problem.
Although some individual studies found comparatively larger effects (SMD \> 0.5: [@carfora2023; @merrill2009; @kanchanachitra2020; @bianchi2022; @piester2020]), each of these studies employed its own methods and theory of change.
Therefore, we conclude that no theoretical approach, delivery mechanism, or intended persuasive message should be considered a well-validated method of reducing MAP consumption.

Though this may surprise readers of previous reviews [@mathur2021meta; @meier2022; @mertens2022], we attribute our findings to our stricter inclusion criteria.
For instance, of the ten largest effect sizes recorded in [@mathur2021effectiveness], nine measured attitudes and/or intentions, and the tenth came from a non-randomized design.
Prior research has found that intentions do not predict behavior [@mathur2021effectiveness], and reviews in other fields have found systematic differences in impacts between randomized and non-randomized evaluations [@porat2024; @stevenson2023].
It stands to reason that a review focused on rigorous evaluations of consumption outcomes would not accord with the findings of reviews aimed at broader targets.

Likewise, as our analyses show, studies aimed at reducing RPM consumption are associated with an effect about four times larger (SMD = 0.25) than those aimed at reducing all categories of MAP consumption.
Sharply curtailing RPM consumption is a core component of current leading dietary guidelines, such as the heart-healthy diet [\@diab2023], but many of these same diets actively encourage moderate intake of poultry and fish.
Further, reducing RPM consumption is frequently mentions as something consumers can and should do to personally fight climate change [@auclair2024].
By contrast, vegetarianism is still a minority diet worldwide [@tilman2014] that consumers consider to be diffuclt, unsatisfying, and expensive [@bryant2019].
We speculate that cutting back on RPM is perceived as easier and more socially rewarded than cutting back on MAP generally, and that this explains the observed difference in effect sizes.

```{r confounding_check, include=F}
confound_table <- dat |> filter(self_report == 'N') |> group_by(str_detect(population, 'university')) |> summarise(count = n()) |> as_tibble()

```

We caution that our analyses are limited by our small sample size.
Our moderation analysis, for example, tests differences between studies that are highly confounded — `r confound_table$count[[2]]` of `r confound_table$count[[2]] + confound_table$count[[1]]` interventions with objectively reported outcomes are also studies of university populations, limiting our ability to detect the independent association of these variables with effect size.
Further, our meta-analytic database is a non-random sample of the literature writ large, and our estimates of publication bias should not be taken as estimates for the entire literature.
Most importantly, our results are sensitive to choices about included dependent variables, which some might argue means they lack robustness.
However, this critique is a double-edged sword.
Our paper suggests that prior reviews' findings are also more sensitive to inclusion rules than was previously known.

Overall, we are encouraged by positive trends in the literature.
First, as noted, a majority of studies in our meta-analysis have been published since 2020, indicating the field's growing dedication to questions of credible design and measurement.
Second, we observe many fruitful collaborations between researchers and advocacy organizations, as shown by the plethora of nonprofit white papers in our sample.
Third, many promising designs and interventions yet await rigorous evaluation.
For instance, no study in our meta-analysis evaluated extended contact with farm animals, manipulations to the price of meat, activating moral and/or physical disgust, and many categories of choice architecture intervention.
Each of these is a potentially promising research project.

In sum, though we view meaningfully reducing MAP consumption as an unsolved problem, there is no reason to think it is unsolvable.

\bmhead{Acknowledgments}

*Thanks to Alex Berke, Alix Winter, Anson Berns, Hari Dandapani, Adin Richards, Martin Gould, and Matt Lerner for comments on an early draft. Thanks to Jacob Peacock, Andrew Jalil, Gregg Sparkman, Joshua Tasoff, Lucius Caviola, Natalia Lawrence, and Emma Garnett for help with assembling the database and providing guidance on their studies. We gratefully acknowledge funding from the NIH (grant XXX) and Open Philanthropy (YYY).*

# Declarations {.unnumbered}

\newpage

## Tables

```{r meta_table, echo=FALSE, message=FALSE, results='asis'}
source('./scripts/meta-table.R')
meta_table
```

```{r moderator_table, echo=F, message=F}
source('./scripts/moderator-table.R')
moderator_table
```

```{r sensitivity_table,echo=F, message=F}
source('./scripts/sensitivity-table.R')
sensitivity_table
```

\FloatBarrier 
\newpage

## Figures

```{r forest_plot, fig.cap="Forest plot for MAP reduction studies. Each point corresponds to a fixed effects meta-analysis for each paper. Papers employing multiple theoretical approaches are represented once per theory. Dot size is inversely proportional to variance. Points are sorted within theory by effect size (Glass's $\\Delta$). A random effects meta-analysis for the entire dataset is plotted at the bottom. The black line demarcates an effect size of zero, and the dotted line is the observed overall effect.", echo=FALSE, message=F, fig.align='center', fig.pos='H', fig.height=9, fig.width=6}
source('./scripts/forest-plot.R')
forest_plot 
```

```{r funnel_plot, echo=F, fig.cap='very good caption '}
funnel_plot <- significance_funnel(yi = dat$d, vi = dat$var_d, favor_positive = TRUE, , alpha_select = 0.05, plot_pooled = TRUE)
funnel_plot
```

```{r robust_data, include=F}

# source('./scripts/robustness-check.R')
```

\newpage

# Supplementary Materials {#Sec5}

## Supplementary Methods {#Sec5.1}

### Effect size details

When standard deviations for the control group were available, outcomes were converted to Glass's $\Delta = \frac{\mu_T - \mu_C}{\sigma_C}$, and were otherwise converted to Cohen's $d$.
...

### Full list of statistical packages

...

### Codebook for data

...

### PRISMA diagram

...

## Supplementary Discussion

### Four deviations from pre-analysis plan

Our coding and analyses were pre-registered on the Open Science Framework (\url{https://osf.io/3sth2}).
As discussed in the main text, we made two post-hoc changes to our study inclusion criteria: excluding studies that sought to induce substitution from one kind of MAP to another, and counting reduction in consumption of RPM as a separate estimand.
Here we discuss two further deviations.

```{r alt_model, include=F}
alt_model <- metafor::robust(x = rma.uni(yi = d, vi = var_d, data = dat), cluster = dat$unique_study_id)
```

First, our initial analyses used the random effects model from `metafor` to calculate pooled effect sizes.
However, as we assembled our dataset, we noticed that many papers had, across interventions, non-independent observations, typically in the form of multiple treatments compared to a single control group.
Upon discussion, the team's statistician (MBM) suggested that the `CORR` model from the `robumeta` package would be a better fit.

Using our original model from `metafor`, we detect a pooled effect size of `r alt_model$beta` (95% CI: [`r paste0(alt_model$ci.lb, " ", alt_model$ci.ub)`]), p = `r alt_model$pval`.
In relative terms, this is substantially smaller, but in absolute terms, both this model and our main model produce very small estimates.

Second, we added many moderators to our dataset that we did not plan on, such as a broad category for delivery method, whether a study was intended to be emotionally activating, or whether a program had multiple components.
We did not end up focusing on these in our main paper but include them in our dataset for completeness.

### Some promising interventions that did not meet our inclusion criteria

[to write]

### The limits of systematic search for MAP reduction papers {#sec5.4.1}

This literature has remarkable methodological, disciplinary, and theoretical diversity.
However, it also has few if any agreed upon terms to describe itself.
For instance,the term "MAP" is nonstandard; other papers discuss animal-based proteins, animal products, meat, edible animal products, plant-based foods, plant-based protein, and so on.
This diversity of language poses a particular challenge for anyone seeking to systematically review this literature.
Whether one has identified the correct terms that each relevant study uses to describe itself is, for all practical purposes, unknowable.

This informed our search process.
Rather than starting with a list of search terms, we began by reading prior reviews, and then reading the studies cited by those reviews, to get a sense of the language that studies used to describe themselves.
We then pursued the multi-pronged, iterative search process described in the main text.
Ultimately, we used systematic search techniques to fill in the the blanks when we had an intuition that we were missing studies employing a particular approach.

The following are the Google Scholar search terms we used:

-   "random" "nudge" "meat"
-   "meat" "purchases" "information" "nudge"
-   "nudge" "theory" "meat" "purchasing"
-   "meat" "alternatives" "default" "nudge"
-   "dynamic" "norms" "meat"
-   "norms" "animal" "products"
-   "university" "meat" "default" "reduction"

For each of these terms, we looked through ten pages of results.

### Edge cases for study inclusion {#sec5.4.2}

Arguably the hardest decision in meta-analysis is what studies to include or exclude.
By far the most common reason for exclusion was category of dependent variable (e.g. measuring attitudinal or intentional outcomes).
However, many cases were harder and required some deliberation.

Some studies limit dietary portions or switch what people are served (e.g. children being served more vegetables at lunchtime).
We did not include these studies because they were essentially guaranteed to have effects that were either positive or at least bounded at zero.
However, we did include studies that provided free access to meat alternatives [@acharya2004; @bianchi2022] and measured outcomes after the intervention had concluded.
(There were not enough of these studies in our main dataset to analyze this approach separately, but their effect sizes are `r round(dat |> filter(author == 'Acharya') |> pull(d),3)` and `r round(dat |> filter(author == 'Bianchi') |> pull(d),3)` respectively.)

Other studies induce a form of treatment in their control groups, for instance asking all subjects to take a pledge to go vegetarian.
Our main database only includes studies with a pure control group or an unrelated placebo.
However, we include a selection of studies in our supplementary robustness check.

Another common design feature we encountered was treatment assigned at the level of alternating weeks at a cafeteria.
Generally these studies did not have enough weeks to meet our sample size requirements.
We also note that simply alternating weeks is not equivalent to random assignment.

Last, we encountered many studies that measured fruit and or/vegetable consumption but not MAP consumption.
In some cases, it might have been possible to add assumptions about substitution and estimate effect sizes, e.g. if menus were fixed, but we exclusively meta-analyzed studies that reported MAP consumption directly.

### Defining the the theoretical boundaries between studies requires judgment calls {#sec5.4.4}

We noted a surprising paucity of qualifying interventions employing choice architecture, which has been frequently cited by experimenters [@boronowsky2022], reviewers [@meier2022], and advocacy groups [@zhang2022] as a proven method of changing consumer behavior.
By contrast, our review revealed that very few papers in this literature both employed randomized designs and measured lasting effects on MAP consumption.
We encourage future choice architecture research to measure delayed outcomes whenever possible, such as by intervening on participants at lunch and then measuring MAP consumption at dinner as well [@vocski2024].

However, our choice architecture count would have been larger if we had included all studies self-identifying as 'nudge' studies in the choice architecture category [@thaler2009].
Such studies dd not necessarily alter anything about the architecture of a choice, and were not obviously seeking to operate on 'unconscious' processes [@garnett2020].
For instance, a text message reminder of reasons to eat less meat is cheap and easy to ignore, and is arguably designed to correct for time-inconsistent preferences, a kind of cognitive bias.
On the other hand, such a text message also provides relevant information about the choice set, and if every intervention that attempted this was a nudge, most studies in our database would be nudges.

We decided to separate interventions that altered the literal architecture of a choice, and therefore were plausibly working on unconscious processes, from interventions that tried to alter how people think or feel about what they're eating.

Likewise, categorizing interventions employing social norms messages was at times challenging.
[@mols2015] identify "unthinking conformity" as an example of a "human failing" that nudges take as their "starting point" (p. 4), and if social norms activate an unthinking desire to conform, then arguably a message about how many people are going vegetarian in one's community is a nudge.
Our view is that a social norm prompt might engender a rich array of possible reactions, both cognitive and affective, and we do not assume that "unthinking conformity" is the dominant or exclusive response.
Therefore, we do not classify the norms interventions in our database as nudges.

A future project might investigate exactly what reactions are occurring by asking subjects how well they recall a norms message and what it made them think about.
A high prevalence of subjects who are unable to recall the message's specifics but nevertheless cut back on MAP consumption would be evidence that norms are acting through automatic rather than reflective processes.'

Reasonable people might have defined the theoretical boundary conditions differently.
For instance, rather than grouping psychology approaches together, one might separate interpersonal processes (norms) from purely personal processes, e.g. pledges, implementation intentions, or response inhibition training.
For this reason, we included in our dataset both `theory` and `secondary_theory` columns, and in the latter we include more specific information about papers' approaches to behavior change.
We invite readers to explore different categories and their respective pooled effect sizes by building on the code and data we provide.

### The limits of immediate outcome measurement in choice architecture studies

Most choice architecture study we reviewed manipulated some aspect of a dining environment and then observed what people chose or ate under those conditions.
Mapping such outcomes to net reductions in MAP consumption requires some additional assumptions.
Speaking broadly, we might tell four possible stories about what a diner who is nudged into eating a vegan meal at breakfast might do at lunch:

1.  If the meal was palatable, the diner might wish to eat more vegan meals at the future, which would result in a net reduction in MAP consumption.
2.  If the meal was unpalatable, the diner might develop an aversion to plant-based foods, which would result in a net *increase* in MAP consumption.
3.  If each meal is more or less chosen in isolation, the diner's net MAP consumption might be reduced by the amount of MAP avoided in that one meal.
4.  If the diner has in her mind a daily or weekly "MAP budget" — an amount of animal products she is "allowed to eat" in a given time period — then she might compensate by having that much MAP at the next meal, which would lead to a net change of zero.

Which of these stories best maps to consumer behavior might be elicited by

### Notes on prior reviews {#sec5.4.5}

It was striking to us there have been more systematic reviews of MAP reduction research than there have been studies meeting our criteria.
We encourage scholars to pursue more randomized controlled trials with consumption outcomes.

We turn now to a selective overview of prior reviews of dietary research that were highly relevant to this one.

Among the reviews that found MAP reduction interventions to be effective, several focused exclusively on choice architecture.
[@arno2016] found that nudges led to an average increase of healthy dietary choices of 15.3%, while [@byerly2018] found that committing to reduce meat intake and making menus vegetarian by default were more effective than educational interventions.
However, the vast majority of vegetarian-default studies we analyzed for this paper did not qualify for our analysis because they lacked delayed outcomes, and their net effect on MAP consumption is unknown.

[@bianchi2018restructuring] found that reducing meat portions, making alternatives available, moving meat products to be less conspicuous, and changing meat's sensory properties can all reduce meat demand.
[@pandey2023] found that changing the presentation and availability of sustainable products was effective in increasing demand for them, as was providing information about them.

In a meta-review, [@grundy2022] found environmental education to be most promising, with substantial evidence also supporting health information, emphasizing social norms, and decreasing meat portions.

Some reviews have focused on particular settings for MAP reduction interventions.
[@hartmannboyce2018] found that grocery store interventions, such as price changes, suggested swaps, and changes to item availability, were effective at changing purchasing choices.
However, that review covered a wide variety of health interventions, such as reducing consumption of dietary fat and increasing fruit and vegetable purchases.
It is unclear how directly such findings translate to MAP reduction efforts.

[@chang2023] focused on university meat-reduction interventions and found more promising results than did reviews that looked at the wider public.
This suggests that students and young people may be particularly receptive to MAP reduction interventions.
[@harguess2020] reviewed 22 studies on meat consumption and found promising results for educational interventions focused on the environment, health, and animal welfare.
That paper recommends using animal imagery to cause an emotional response and utilizing choice architecture interventions.
Our review, by contrast, found no relationship between animal welfare appeals and MAP consumption.

Taking a different angle, [@adleberg2018] reviewed the literature on protests in a variety of movements and found mixed evidence of efficacy.
The authors recommend that animal advocacy protests have a specific target (e.g. a particular institution) and "ask."

Other studies provide insights on who is most easily influenced by interventions to reduce MAP consumption.
For example, [@blackford2021] found that nudges focused on "system 1" thinking were more effective at encouraging sustainable choices than those focused on "system 2," and that interventions had greater effects on females than males.
Our review also featured studies showing differences between men and women.

[@rosenfeld2018] reports that meat avoidance is associated with liberal political views, feminine gender, and higher openness, agreeableness and neuroticism.
That review also identifies challenges and barriers to vegetarianism, such as recidivism and hostility from friends and family.
Future research could tailor interventions to address these barriers.

Several reviews have had mixed or inconclusive results.
For instance, [@bianchi2018conscious] found that health and environmental appeals appear to change dietary intentions in virtual environments, but did not find evidence of actual consumption changes.
In the same vein, [@kwasny2022] notes that most existing research focuses on attitudes and intentions and lacks measures of actual meat consumption over an extended period of time.
[@taufik2019] reviewed many studies aimed at increasing fruit and vegetable intake, but found far fewer that looked at reducing MAP consumption.
[@benningstad2020] found that dissociation of meat from its source plays a role in meat consumption, but no extant research that included behavioral outcomes.

A few reviews have found evidence that seems to recommend against particular interventions.
[@greig2017] reviewed the literature on leafleting for vegan/animal advocacy outreach, and observed biases towards overestimating impact.
That paper concluded that leafleting does not seem cost-effective, though with significant uncertainty.
This accords with our findings on advocacy organization materials' limited impacts.

[@nisa2019] meta-analyzed interventions to improve household sustainability, of which reducing MAP consumption was one of several.
Although they found small effect sizes for most interventions, they concluded that nudges were comparatively effective.
Many such nudge studies looked at meat consumption.
Similarly, [@rau2022] reviewed the literature on environmentally friendly behavior changes, including but not limited to diet change, and found small or nonexistent effects in most cases.
Only fifteen interventions in that paper were described as “very successful,” and none of these related to food.

We draw two lessons from these papers.
The first is that the marginal value of a new rigorous evaluation is much higher than that of a new systematic review.
The second is that the category of dependent variable matters for estimating impact.
We encourage researchers who care about reducing MAP consumption to measure it directly whenever possible.

\begin{comment}
First I feel a little strange saying that the marginal value of a review is low (then whay are we writing this paper?) Second, maybe there's a space for discussion about what counts as  meaningful? mention that ease of implementation matters in terms of what’s meaningful. The costs of fully exposing one person is the relevant denominator. The costs of recruitment are part of the cost. Maybe some people are more amenable to nudges after hearing an argument for
\end{comment}

\newpage

# References
