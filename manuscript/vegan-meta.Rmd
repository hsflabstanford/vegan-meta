---
title: "information and place-based approaches to reducing consumption of meat and animal products: findings, biases, and limitations"
shorttitle: "vegan-meta"
author:
  - name: "Seth A. Green"
    affiliation: "1"
    address: "Kahneman-Treisman Center, Princeton University"
    email: "sag2212@columbia.edu"
    role:
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name: "Benny Smith"
    affiliation: "2"
    role:
      - "Writing - Review & Editing"
  - name: "Maya Mathur"
    affiliation: "3"
    role:
      - "Writing - Review & Editing"
      - "Supervision"
affiliation:
  - id: "1"
    institution: "Kahneman-Treisman Center, Princeton University"
  - id: "2"
    institution: "Allied Scholars for Animal Protection "
  - id: "3"
    institution: "Stanford University"
abstract: |
  This paper meta-analyzes interventions intended to reduce consumption of meat and animal products (MAP), focusing on the most rigorous, policy-ready studies. Extant efforts generally embody one of two theoretical perspectives: information-based approaches that attempt to change attitudes towards MAP consumption, and place-based interventions that make MAP less salient, appealing, or affordable in a particular context. We find that direct appeals to the environment and personal health, along with some changes to layouts and messages in university cafeterias, can reduce MAP consumption, while appeals to animal welfare, online studies, and leafletting studies have no apparent overall effect.  However, even the very best studies in this literature typically have concerning measurement limitations: for information-based approaches, the predominance of self-reported outcomes, and for place-based approaches, a lack of post-intervention follow-up. In other words, information-based approaches are at risk of social desirability bias, and place-based approaches are at risk of "regression to the meat:" the possibility that someone who is nudged into eating less MAP at one meal will compensate by eating more at the next. Our meta-analysis paper proffers some statistical approaches to addressing these biases, producing a wide range of point estimates. We also highlight the findings of the studies whose designs and measurement strategies convincingly address both issues. We conclude with concrete, shovel-ready suggestions for future researchers that take the lessons of this analysis into account. 

authornote: |
 This work was generously supported by the Food System Research Fund and the NIH (grant 5R01LM013866-03). Thanks to Alex Berke, Alix Winter, Andrey Fradkin, Anson Berns, Hari Dandapani, Martin Gould, Martin Rowe, Matt Lerner, Adin Richards, and Daniel Waldinger for suggestions and comments on an early draft. Thanks to Lucius Caviola, Emma Garnett, Andrew Jalil, Jacob Peacock, Gregg Sparkman, and Joshua Tasoff for helping us assemble the database and providing guidance on their studies.
keywords: "meta-analysis, meta-science, meat-and-animal-products, evaluation"
wordcount: "2483"
bibliography: "vegan-refs.bib"
floatsintext: no
linenumbers: no
draft: no
mask: no
figurelist: no
tablelist: no
footnotelist: no
output: papaja::apa6_pdf
editor_options: 
  chunk_output_type: console
---

## 1. Introduction: a multitude of perspectives on changing dietary behavior

Reducing consumption of meat and animal products (MAP) is vital to many policy goals. Animal agriculture is a major driver of climate change [@scarborough2023; @koneswaran2008; @goodland2009] as well as more localized environmental and public health harms [@horrigan2002; @slingenbergh2004; @graham2008; @greger2010]. Excess MAP consumption is a leading cause of premature deaths [@willett2019; @landry2023]; finally, the conditions in which farmed animals live and die are increasingly recognized as a policy matter in their own right [@yeates2011; @webster2001; @kuruc2023].

Policymakers have a broad array of tools at their disposal for attempting to change eating behavior. For example, they can ban certain kinds of food [@caro2009] or practices [@bursey2018] perceived to be unusually cruel; campaign for vegetarianism [@trewern2022]; or change eating environments to make non-meat options more salient or appealing [@guthrie2015; @bianchi2018restructuring]. However, any policy lever which focuses on supply rather than reducing consumer demand risks backsliding through political correction [@michielsen2022]. It is essential, therefore, to assess which theoretical approaches most effectively and durably alter consumer eating behavior. This paper approaches that question with a theoretically comprehensive review and methodologically focused meta-analysis.

A previous review called on future MAP research to feature more “direct behavioral outcomes” and “long-term follow-up" [@mathur2021meta, p. 1]. Our paper shares those commitments, and thus restricts its meta-analysis to the very most rigorous, policy-ready research: randomized controlled trials with at least 25 subjects in treatment and control (or at least 10 clusters in cluster-assigned studies) that measure actual MAP consumption at least a single day after treatment begins. We identified 44 such interventions published in 29 papers or technical reports.

Scholars have approached the problem of MAP reduction from a myriad of academic disciplines, including social psychology [@rosenfeld2018; @dhont2019], economics [@lusk2009], choice architecture [@bianchi2018restructuring; @mertens2022]; and environmental studies [@costello2016]. The central theoretical divide we observe among policy-ready studies is between **information-based approaches** that attempt to change ideas about MAP consumption and **place-based interventions** that make MAP consumption more difficult, expensive, or apparently counter-normative in a restaurant or university dining hall. Which of these two approaches is more effective at changing real world behavior has broad implications for behavioral scientists and policymakers.

Our main quantitative finding is that appeals to personal health and the environment are the most broadly effective MAP reduction strategies. We also see some evidence of change resulting from price- and salience-based changes to some university dining halls, and text-based reminders of prior intentions to reduce MAP consumption. We find overall null results for appeals to animal welfare, studies conducted online, and leafletting studies.

However, we place low confidence in the generalizability of these results due to two concerns about measurement. The first is social desirability bias arising from self-reported outcomes [@mathur2021effectiveness], which are predominant in the information-based literature. The second is the place-based literature's general lack of engagement with the possibility of compensatory/backlash effects: that someone who is nudged into eating less MAP at one meal may perceive a moral license [@merritt2010; @blanken2015] to eat more MAP later. If we limit our analysis to studies with deal convincingly with both threats to inference, we still conclude that appeals to the environment and health, as well as a handful of nudges and norms messages, reduce reduce MAP consumption, but in the highly specialized context of dining halls at elite American universities. For this literature to truly become shovel-ready for policymakers, it urgently needs extension and replication, along with careful attention to measurement validity.

Our paper builds on two literatures. The first is systematic reviews of attempts to reduce MAP consumption, of which there have been 22 by our count, with two others that we know of forthcoming. (See appendix A for a complete overview). Our paper makes four contributions on top of this already rich set. First, our database is current as of December 2023, which has significance in an emerging literature whose most credible estimates and best designs tend to be in recent publications. Second, our review is quantitative, while most previous reviews are narrative or systematic reviews but do not offer meta-analysis. Third, among papers with a meta-analytic component, ours is (so far) unique for being theoretically comprehensive rather than focusing on the effects of a single conceptual approach. Fourth, ours is the only review to our knowledge to set strict inclusion criteria that attempt to identify the most rigorous, policy-ready research.

Second, our paper contributes to a growing literature of meta-analyses, reviews, and "megastudies" [@doell2023; @milkman2021] that attempt to compare the efficacy of different approaches to solving social problems. In social psychology, @paluck2021 and @porat2024 apply meta-analytic methods to testing the efficacy of different theories at reducing prejudice and sexual violence, respectively, while @vlasceanu2024 test 11 theoretically diverse interventions aimed at four "climate mitigation outcomes" (p. 1).[^1] In a related vein, @bergquist2023 provide a meta-analysis of meta-analyses for climate mitigation behaviors, and find that social comparison and financial incentives were generally effective, while information and feedback generally were not. We also build on prior reviews that that holistically assess the efficacy of choice architecture approaches versus, e.g., taxes [@list2023] or subsidies [@campos2021]. Finally, a paper from @bergman2024 compares information-based approaches to "short-term financial assistance, customized assistance during the housing search process, and connections to landlords" (p. XXX) to encourage families to move to high-opportunity areas. Our paper's approach is similar to all of these but distinct, to the best of our knowledge, for the stringency and policy focus of our meta-analytic inclusion criteria.

[^1]: This is distinct from the "Metaketa" initiatives from Evidence on Governance and Politics, which run many field experiments simultaneously to test the effect of one theoretical approach on a common outcome [@slough2021; @blair2021]. Metaketas are concerned primarily with external validity, and thus keep the independent variable approximately constant, while megastudies are aimed at comparative efficacy, and so test many distinct treatments.

The remainder of the paper proceeds as follows. Section 2 details (and motivates) the inclusion criteria and search process by which we assembled our meta-analytic database. Section 3 describes the database. We provide some descriptive statistics about the database, and then present its six major theoretical approaches \textemdash environmental, health, and animal welfare appeals to MAP reduction comprising information-based strategies, and norms manipulations, choice architecture, and incentive approaches comprising place-based strategies \textemdash and representative literature from each. For each subset, we also highlight some frequent design or measurement limitations that led us to exclude otherwise promising results. Section 4 provides an overview of our meta-analytic methods and procedures.

Section 5 presents our quantitative results. We provide a mixture of pooled averages, tests for publication biases, and comparisons of different approaches. We also offer some attempts to estimate the magnitude of different biases in this literature drawn from related literatures, and to use those estimates to offer effect size corrections. These analyses are tentative, and offer readers a broad range of possibilities intended to match different priors about the severity and importance of the measurement issues we enumerate Section 6 concludes with some concrete suggestsion for future MAP reduction researchers based on the results of our analyses.

## 2 Assembling the meta-analytic database

### 2.1 Selecting inclusion criteria

Meta-analysis is a powerful, flexible procedure for pooling results from many studies into a singular estimate, or cluster of estimates, denoting the relationship between a treatment and an outcome across contexts. For this to be an unbiased estimate of the true causal relationship between the two requires several additional assumptions. First, the pooled studies must each furnish an unbiased causal estimate. Second, the set of studies must be a random sample of the universe of possible studies, and not, for instance, truncated by publication bias [@thornton2000]. Third, the assembled outcomes must have a persistent, known relationship with the true outcome of interest.

Each of these propositions is, in theory, testable and amenable to statistical correction (see @mathur2022 and @green2024 for suggestions and strategies). However, the most fundamental challenge to meta-analysis is whether the underlying data are coherently integrable. A recent paper by @slough2023 makes this point forcefully. In their view, for studies to have "target equivalence" \textemdash the property of identifying "the same estimand" (p. 1) \textemdash they must first achieve harmonized contrasts and measurements, meaning that the "substantive comparison across studies is the same" and "the outcome of interest is the same and it is measured in the same way" (p.2). These properties are necessary for meta-analytic results to be "meaningful and interpretable" (p.2). Crucially, they cannot be achieved "solely with statistical techniques" and are instead a product of tailored "design or inclusion criteria" (p.2).

We share this paper's concerns, and we address them via stringent inclusion criteria.

First, we only look at randomized controlled trials for historically well-understood reasons [@cook2002; see @simonsohn2022 for discussion specific to meta-analysis]. This meant both that treatment was randomized and that there was a true, no-treatment control group for comparison.

Second, studies needed to measure MAP consumption directly. This included self-reported outcomes because, as we discuss later, we have preexisting estimates of the magnitude of any resulting bias. However, a tricky case emerged when we found studies that attempted to reduce red or processed meat consumption rather than MAP consumption as a whole. Some of these studies recommended that people substitute to other MAP, such as chicken or fish, but none to our knowledge measured any outcome besides red and/or processed meat. We decided to include these studies so long as they did not specifically recommend that people substitute to other MAP.

Third, studies needed to measure MAP consumption at least a single day after treatment began. For information-based studies, this was straightforward: essentially every treatment took under an hour to administer, and we looked only at studies where there was a delay of at least 24 hours before outcomes were collected. For place-based interventions, measuring this was a little trickier. Most studies in this category measured outcomes while treatment was being actively administered, e.g. a dining hall with a dynamic norms message on display counting the amount of meat sold while the sign was up. For an individual subject of such a study, there was no delay between treatment and outcome. We decided to count studies that took place for more than one day and measured outcomes continuously (e.g. if they displayed the dynamic norms message at many lunches consecutively). Arguably these studies are designed to successfully capture adaptation to treatment, and an enduring effect over many days suggests a real effect. However, we remain concern about what happens to treated subjects once the treatment ends, and we return to this point at length in our quantitative results.

Finally, we required that studies have at least 25 subjects in treatment and control, or, for cluster-assigned studies, at least 10 clusters. @paluck2021 found that studies with fewer than 25 subjects per arm, which constituted the smallest quintile of studies in the prejudice reduction literature, showed systematically larger effects than their larger peers That paper also argued that fewer than 10 clusters would be too few to calculate meaningful standard errors. In practice, we excluded very few studies for having fewer than 25 subjects, but quite a few for having fewer than 10 clusters; many studies describing themselves as experiments had just one unit assigned to treatment and one to control, but recorded results at the level of individuals, thereby ignoring clustered standard errors. We treat these studies as, effectively, quasi-experiments and did not include them in our database.

We also required that the full papers be available on the internet, rather than just a summary or abstract, and written in English.

### 2.2 Our search process

## 3 The meta-analytic database

## 

Consider [Fehrenbach (2015)](https://www.proquest.com/docview/1712399091?fromopenview=true&pq-origsite=gscholar), a 2015 dissertation that tested the “effectiveness of $$two$$ video messages designed to encourage Americans to reduce their meat consumption.” The study had two treatment arms and a control. Both treatment videos sought to induce a feeling of “high threat” by informing viewers of the “the negative health effects of high meat consumption;” one video also sought to induce feelings of “high efficacy” by suggesting “easy ways to reduce their meat consumption,” while the “low efficacy” group’s video “only included a very minor efficacy component in the conclusion.” The videos were 7 and 4 minutes long, respectively. Before the study, on the day of the study, and again a week later, participants were asked about their attitudes and intentions towards eating meat, as well as how much meat they’d eaten in the past 7 days.

Overall, the high threat/high efficacy group reported that they ate an average of 3.16 fewer meals involving meat in the week following the intervention than the one before it, compared to 2.11 for the high threat/low efficacy group and 1.92 for the control group. As a benchmark, the population ate meat at an average of 13.64 meals per week before the intervention (SD = 4.21).

This study strikes us as having a high risk of social desirability bias for three reasons.

First, the study is designed to make people feel a sense of “high threat” from eating meat, and then asks them a week later about how much meat they ate. There are grounds for doubting how much respondents would accurately recount their eating habits. This problem is typical of this literature.

Second, the study asks participants to recall a week’s worth of meals; previous research has found that [daily food diaries lead to more accurate reports](https://pubmed.ncbi.nlm.nih.gov/7635601/). As [Mathur et al. (2021a)](https://www.sciencedirect.com/science/article/pii/S0195666321001847) put it:

> Many existing studies measure meat consumption in terms of, for example, Likert-type items that categorize the number of weekly meals containing meat (e.g., “none”, “1–5 meals”, etc.) or in terms of reductions from one’s previous consumption. When possible, using finer-grained absolute measures, such as the number of servings of poultry, beef, pork, lamb, fish, etc., would enable effect sizes to be translated into direct measures of societal impact.

Third, the decline in meat-eating among the control group suggests that the intended direction of the experiment might have been crystal clear to everyone, whether they watched the video or not.

In sum, using broad stroke, self-reported outcomes in a context where meat is being presented as bad for you seems like a high-risk environment for [experimenter demand effects](https://www.elgaronline.com/display/edcoll/9781788110556/9781788110556.00031.xml).

## 4

### Bibliography
