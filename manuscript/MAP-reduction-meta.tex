%Version 2.1 April 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[sn-nature,pdflatex]{sn-jnl}

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published
%%%%  by Springer Nature. The guidance has been prepared in partnership with
%%%%  production teams to conform to Springer Nature technical requirements.
%%%%  Editorial and presentation requirements differ among journal portfolios and
%%%%  research disciplines. You may find sections in this template are irrelevant
%%%%  to your work and are empowered to omit any such section if allowed by the
%%%%  journal you intend to submit to. The submission guidelines and policies
%%%%  of the journal take precedence. A detailed User Manual is available in the
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

\usepackage{comment}
\usepackage{anyfontsize}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}


\raggedbottom




% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}





\begin{document}


\title[MAP-reduction-meta]{Meaningfully reducing consumption of meat and
animal products is an unsolved problem: results from a meta-analysis}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate}
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Seth
Ariel} \sur{Green} }\email{\href{mailto:setgree@stanford.edu}{\nolinkurl{setgree@stanford.edu}}}

\author[1]{\fnm{Maya B.} \sur{Mathur} }

\author[2]{\fnm{Benny} \sur{Smith} }



  \affil[1]{\orgdiv{Humane and Sustainable Food Lab}, \orgname{Stanford
University}}
  \affil[2]{\orgname{Allied Scholars for Animal Protection}}

\abstract{Which theoretical approach leads to the broadest and most
enduring reductions in consumptions of meat and animal products (MAP)?
We address these questions with a theoretical review and meta-analysis
of rigorous Randomized Controlled Trials. We meta-analyze 36 papers
comprising 43 studies, 114 interventions, and approximately 88000
subjects. We find that these papers employ choice architecture, norms,
or persuasion approaches to changing behavior. The pooled effect of
these interventions on MAP consumption outcomes is \(\Delta\) = 0.065,
indicating an unsolved problem. Reducing consumption of red and
processed meat is an easier target: \(\Delta\) = 0.258, but because of
missing data on potential substitution to other MAP, we can't say
anything definitive about the consequences of these interventions on
animal welfare. We further explore effect size heterogeneity by
approach, population, and study features. We conclude that while no
theoretical approach provides a proven remedy to MAP consumption,
designs and measurement strategies have generally been improving over
time, and many promising interventions await rigorous evaluation.}

\keywords{meta-analysis, meat, plant-based, randomized controlled trial}



\maketitle

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Introduction}\label{sec1}

Consumption of meat and animal products (MAP) is increasingly recognized
as a major contributor to premature deaths
\citep{willett2019, landry2023}, public health risks
\citep{slingenbergh2004, graham2008}, ecological harms
\citep{greger2010} and climate change
\citep{scarborough2023, koneswaran2008} as well as an ethical crisis in
its own right \citep{kuruc2023, singer2023}.

Supply-side interventions, such as banning or taxing certain practices
or products, risk political backlash if they lack broad public support.
It is of vital importance, therefore, to assess which strategies and
theoretical perspectives lead to consistent reductions in demand for
MAP, under which conditions, and for which populations.

The research on diet and its antecedents and consequences is vast. By
our count, there have been at least 130 previous published dietary
reviews in the past two decades, with at least 37 focused specifically
on MAP reduction. However, comparatively few of these are quantitative,
and most prior reviews investigated particular approaches, for example
choice architecture \citep{bianchi2018restructuring}, rather than
comparing the efficacy of different strategies. Moreover, two prior
investigations revealed three common gaps in the MAP reduction
literature: a dearth of long-term follow-ups, missing consumption
outcomes, and inattention to the gap between intentions and behavior
\citep{mathur2021meta, mathur2021effectiveness}.

Our paper addresses these concerns by meta-analyzing randomized
controlled trials that

\begin{itemize}
\item
  were designed to voluntarily reduce MAP consumption, rather than
  encouraging substitution from red meat to white meat or to fish, or
  removing items from someone's plate
\item
  had least 25 subjects each in treatment and control, or, for
  cluster-randomized trials, at least 10 clusters in total;
\item
  measured MAP consumption, whether self-reported or observed directly,
  rather than (or in addition to) attitudes, intentions, beliefs or
  hypothetical choices;
\item
  featured a pure control group or placebo, rather than comparing
  multiple treatments
\item
  recorded outcomes at least a single day after the start of treatment.
\end{itemize}

Additionally, studies needed to be publicly circulated by December 2023
and published in English.

We coded 36 such papers
\citep{andersson2021, kanchanachitra2020, abrahamse2007, acharya2004, banerjee2019, bianchi2022, bochmann2017, bschaden2020, carfora2023, hennessy2016, piester2020, cooney2014, cooney2016, feltz2022, haile2021, hatami2018, jalil2023, mathur2021effectiveness, merrill2009, norris2014, peacock2017, polanco2022, sparkman2021, weingarten2022, aldoh2023, allen2002, camp2019, coker2022, griesoph2021, sparkman2017, sparkman2020, berndsen2005, bertolaso2015, fehrenbach2015, mattson2020, shreedhar2021}
comprising 42 separate studies, 114 interventions, and approximately
88000 subjects. (This is an approximation because some interventions
were administered at the level of day or cafeteria and did not record a
precise number of human subjects.) The earliest paper was published in
2002 \citep{allen2002}, and a majority (19 of 36) have been published
since 2020.

We also coded four supplementary datasets. First is a collection of 17
papers
\citep{anderson2017, carfora2017correlational, carfora2017randomised, carfora2019, carfora2019informational, delichatsios2001talking, dijkstra2022, emmons2005cancer, emmons2005project, jaacks2014, james2015, lee2018, perino2022, schatzkin2000, sorensen2005, wolstenholme2020}
aimed at reducing, and measuring, consumption of red and/or processed
meat (RPM), comprising 17 studies, 25 interventions, and approximately
60000 subjects.

Second is a dataset of 14 studies that we disqualified for
methodological reasons but that we include in a supplementary robustness
check
\citep{alblas2023, beresford2006, dannenberg2023, delichatsios2001eatsmart, epperson2021, frie2022, garnett2020, hansen2021, kaiser2020, lentz2020, lindstrom2015, loy2016, piazza2022, reinders2017, vlaeminck2014}.

Third, we coded a dataset of 897 studies that we excluded along with
their reasons for exclusion.

Fourth is a dataset of 134 review papers that we reviewed while
searching for papers.

All datasets are provided in our supplementary materials.

Studies in our primary database pursued three theories of change: choice
architecture, psychology, and persuasion, or a combination of persuasion
and psychology.

\textbf{Choice Architecture} studies
\citep{andersson2021, kanchanachitra2020} manipulate aspects of physical
environments to make non-MAP options more salient, such as placing a
vegetarian meal at eye level on a billboard menu \citep{andersson2021}
or making it more laborious for people to serve themselves fish sauce
\citep{kanchanachitra2020}.

\begin{comment}
Do we put in something here about the line between choice architecture and nudge? I currently have it in the results section?
(See our results section forA handful of other studies [NAME THEM] identify their interventions as nudges, but do not alter the actual architecture of a choice, instead doing [WHAT THEY DO]. Our quantitative results are presented both with and without these studies included with the choice architecture studies.)
\end{comment}

\textbf{Persuasion} studies
\citep{kanchanachitra2020, abrahamse2007, acharya2004, banerjee2019, bianchi2022, bochmann2017, bschaden2020, carfora2023, hennessy2016, piester2020, cooney2014, cooney2016, feltz2022, haile2021, hatami2018, jalil2023, mathur2021effectiveness, merrill2009, norris2014, peacock2017, polanco2022, sparkman2021, weingarten2022}
appeal directly to people to eat less MAP. These studies formed the
majority of our database. Arguments focus on health, the environment
(usually climate change), and animal welfare. Some are designed to be
emotionally activating, e.g.~presenting upsetting footage of factory
farms \citep{polanco2022}, while others present facts about, e.g., the
relationship between diet and cancer \citep{hatami2018}. Many persuasion
studies combine arguments, such as a lecture on the health and
environmental consequences of eating meat \citep{jalil2023}.

\textbf{Psychology} studies
\citep{aldoh2023, allen2002, camp2019, coker2022, griesoph2021, piester2020, sparkman2017, sparkman2020}
typically manipulate the interpersonal,cognitive, or affective factors
associated with eating meat. The most common psychological intervention
is centered on social norms. These studies seek to alter the perceived
popularity of desired outcomes, e.g.~plant-based dishes
\citep{sparkman2017}. Norms might be descriptive, stating how many
people engaged in the desired behavior, \citep{aldoh2023},or
dynamic,teling subjects that the number of people engaging in desired
behavior is increasing
\citep{aldoh2023, coker2022, sparkman2017, sparkman2020}. Another study
looked at response inhibition training, where subjects are trained to
avoid responding impulsively to meat \citep{camp2019}. The first
psychology study meeting our criteria was published in 2017.

Finally, a group of interventions combines \textbf{persuasion}
approaches with \textbf{psychological} appeals to reduce MAP consumption
\citep{berndsen2005, bertolaso2015, carfora2023, fehrenbach2015, hennessy2016, mattson2020, piester2020, shreedhar2021}.

These interventions typically suggest reasons to eat less meat side by
side with information about changing consumer habits in society, i.e
they combine norms and persuasion approaches.

\section{Results}\label{sec2}

\subsection{An overall small effect with some heterogeneity by
approach}\label{sec2.1}

Our overall meta-analytic effect size is \(\Delta\) = 0.063 (SE =
0.022), p = .0092. The aggregate effect is statistically significant,
but does not indicate a meaningful reduction.

Figure 1 displays the distribution of effect sizes, grouped by paper,
with each individual point representing an intervention. The overall
effect size is plotted at the bottom.

\includegraphics[width=1.2\linewidth,]{./figures/forest_plot-1}

Table 1 reports the number of studies, interventions, and subjects
(approximately) per approach, as well as the pooled effect sizes per
approach.

\begin{table}[!h]
\centering
\caption{\label{tab:table_one}Choice architecture, Persuasion, Psychology, and Persuasion + Psychology approaches to MAP reduction}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Approach & N (Studies) & N (Interventions) & N (Subjects) & Glass's $\Delta$ (SE)\\
\midrule
\textbf{Overall} & 42 & 114 & 88800 & 0.0630** (0.0220)\\
Choice Architecture & 2 & 3 & 12200 & 0.2120 (0.0950)\\
Persuasion & 25 & 76 & 21300 & 0.0720* (0.0280)\\
Psychology & 11 & 18 & 53100 & 0.0890 (0.0450)\\
Persuasion + Psychology & 9 & 17 & 2100 & 0.0940 (0.0960)\\
\bottomrule
\multicolumn{5}{l}{\rule{0pt}{1em}* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001.}\\
\end{tabular}
\end{table}

Table 2 displays the numbers and findings of persuasion interventions by
topic.

\begin{table}[!h]
\centering
\caption{\label{tab:table_two}Three approaches to MAP reduction persuasion}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Persauasion Approach & N (studies) & N (interventions) & N (subjects) & Glass's $\Delta$ (SE)\\
\midrule
Health & 18 & 30 & 13900 & 0.0820 (0.0390)\\
Environment & 14 & 24 & 8400 & 0.0820 (0.0540)\\
Animal Welfare & 16 & 65 & 15700 & 0.0260 (0.0190)\\
\bottomrule
\multicolumn{5}{l}{\textsuperscript{} Note: because many studies present more than one category of message, the Ns for studies, \linebreak}\\
\multicolumn{5}{l}{interventions, and subjects will sum to more than the total numbers in the persuasion category.}\\
\end{tabular}
\end{table}

These small effects may surprise readers of previous reviews, which
typically found more positive results
\citep{mathur2021meta, meier2022, mertens2022}. We attribute this
difference to our stricter inclusion criteria. For instance, of the ten
largest effect sizes recorded in \citep{mathur2021effectiveness}, nine
were non-consumption outcomes and the tenth came from a non-randomized
design.

Per the papers' own calculations and data, 98 of 114 interventions had
null effects on net MAP consumption. However, many studies present a
wide variety of outcomes, or include MAP reduction as one of many
components of a broader program of behavior change, and present
significant results as well.

\begin{comment}
Could put this back in: "Using our calculations of effect size and standard error 15 interventions have 95% confidence intervals that do not overlap with zero, 12 of which are positive effects, out of 114 interventions."
\end{comment}

\subsection{Moderate evidence of publication bias}\label{sec2.2}

We conduct four tests for publication bias.

\begin{comment} 
Could put in introductory remarks about how this puts our main results in one light or another? 
\end{comment}

First, in our dataset, effect size and standard error are positively
correlated, though not significantly.

Second, the 10 studies with pre-analysis plans have a marginally smaller
effect: \(\Delta\) = 0.019 (SE = 0.025), p = .4747. This difference is
not statistically significant.

Third, the 13 studies with openly available data also have a marginally
smaller effect: \(\Delta\) = 0.013 (SE = 0.028), p = .6665. This
difference is also not statistically significant.

Fourth, the pooled effect size of interventions published in
peer-reviewed journals is about eight times larger than the pooled
effect size from everything else (advocacy organization publications,
preprints, and student theses).

\begin{table}[!h]
\centering
\caption{\label{tab:table_three}Difference in effect size by publication status}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Publication status & N (Interventions) & N (Studies) & N (subjects) & Glass's $\Delta$ (SE)\\
\midrule
Advocacy, preprints, and theses & 56 & 11 & 6800 & 0.0110 (0.0430)\\
Journal Article & 58 & 31 & 81900 & 0.0830** (0.0270)\\
\bottomrule
\multicolumn{5}{l}{\rule{0pt}{1em}* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001.}\\
\end{tabular}
\end{table}

\subsection{Red and Processed Meat is an easier target}\label{sec2.3}

On average, interventions aimed at reducing consumption of red and
processed meat (RPM) outperform general MAP reduction interventions:
\(\Delta\) = NA \text{(SE = NA)}, p = NA. Each of the RPM reduction
studies employs persuasion, and a majority (19 of 25) appeal to personal
health. However, these studies do not collect data on white meat and/or
fish consumption, and therefore their impact on MAP consumption overall
is unknown. (One study in our primary dataset aimed at reducing RPM
consumption but measures meat consumption overall \citep{shreedhar2021}.
That study found moderate positive effects in the short-run and no
effects in the long run.)

RPM is of special concern for its environmental and health consequences
\citep{grummon2023}, but some categories of meat considered sustainable
are arguably worse for animals on a pound-for-pound basis
\citep{mathur2022ethical}. For some plausible patterns of substitution,
these interventions are net positive for health and the environment and
net negative for animal welfare.

\subsection{Norms work sometimes, but it is not clear why or
when}\label{sec2.4}

The overall effect for intervention with a norms component is \(\Delta\)
= NA (SE = NA), p = NA. Of these 0 interventions, NA are self-reported
nulls. Moreover, the spread of norms results is unusually large. For
example, one standout paper with four included studies, each featuring
real-world settings and objectively measured consumption outcomes, finds
one significant positive result, two nulls, and one significant backlash
\citep{sparkman2020}. We do not see, in this collection of studies, a
clear limiting principle for when norms interventions achieve their
goals.

\begin{comment} say something about dannenberg 2024 or the 2024 meta-analysis that finds vey little?
\end{comment}

\subsection{The evidence for choice architecture on MAP consumption is
promising, but scant}\label{sec2.5}

Although nudges are common in the diet literature writ large
\citep{olafsson2024, cadario2020, szaszi2018}, only three nudge studies
from two papers \citep[@][]{kanchanachitra2020, andersson2021} met our
inclusion criteria. Both had moderate effect sizes on the order of a few
percentage points of MAP reduction.

We restrict our choice architecture analysis to studies that literally
alter the architecture of a choice, but two other studies in our dataset
describe themselves as pursuing nudges. The first encourages
participants to take a pledge to go vegetarian \citep{banerjee2019},
which implicitly corrects for time-inconsistent preferences, whle the
second embeds a statement about the proportion of people who chose a
vegetarian meal in a specified time period at a university canteen
\citep{griesoph2021}, which creates what the authors call a ``social
comparison nudge.'' If we include these studies in our choice
architecture model, we get a pooled effect size of \(\Delta\) = 0.12 (SE
= 0.129), p = .4603 gleaned from 8 interventions with approximately
13500 subjects.

\begin{comment} maybe say something about Had our search extended to 2024, we would have likely included many more studies, many of which find small or null effects [cite]

\subsection{Health studies work better for RPM than for
MAP}\label{sec2.6}

The pooled effect size for persuasion studies with a health component is
\(\Delta\) = 0.082 (SE = 0.039), p = .0634. This is small and not
significant, albeit larger than the overall pooled effect.

Health appeals are a component of 19 of 25 interventions aimed at
reducing RPM consumption, and are generally more effective there:
\(\Delta\) = NA (SE = NA), p = NA. This fits with the broader context
where official nutritional guidelines typically encourage consumers to
reduce RPM and consume moderate amounts of lean meat and fish.

We also judge many health studies to be at elevated risk of
self-reporting bias. For example, one study seeks to induce a sense of
fear in subjects \citep{berndsen2005}, while others target people who
are at risk of cancer \citep{hatami2018} or cancer survivors
\citep{james2015, lee2018} with reasons they should change their diet,
and then ask subjects to self-report what they have eaten recently.

\subsection{Environmental appeals have modest positive
effects}\label{sec2.7}

The pooled effect size for persuasion studies with an environmental
component is \(\Delta\) = 0.082 (SE = 0.054), p = .1600. The strongest
evidence that these appeals produce real-world impacts is
\citep{jalil2023}, which substituted an introductory lecture in a
first-year economics class for a lecture on the environmental and health
consequences of meat, focusing mostly on the environment, and then
tracked student meal choices in dining halls for three years following.
That study found that treatment led to an overall reduction in MAP
consumption of 5.6\% (\(\Delta\) = 0.118 (SE = 0.5717429)). Due to this
study's exceptional commitment to long-term, oblique outcome
measurement, we consider it to be reasonably strong evidence for this
intervention's efficacy among the population from which the sample was
drawn.

\subsection{Animal welfare appeals are almost always
ineffective}\label{sec2.8}

The pooled effect size for persuasion studies with an animal welfare
component is \(\Delta\) = 0.026 (SE = 0.019), p = .1954. A full 60 of 65
interventions in this category are self-described nulls. Slightly more
than half (32 of 65) lead to increases in MAP consumption, though just
one of these effects is statistically significant.

The 11 studies and 53 interventions using materials from advocacy
organizations find an overall effect of -0.006 (SE = 0.02), p = .7794.

\subsection{Mixed evidence of effect delay over time}\label{sec2.9}

A key outcome for our paper is whether MAP reduction interventions are
habit-forming. A large effect observed immediately \citep{hansen2019}
could plausibly dissipate quickly and create no enduring changes. On the
other hand, a small push in the right direction might start a cascade of
changes leading to permanent dietary change.

In our dataset, we observe mixed, inconclusive evidence of effect decay
over time. First, there is a tiny, positive relationship between number
of days separating treatment onset from outcome measurement (\(\beta\) =
0.00007), and a tiny , negative relationship between number of days
separating treatment \emph{conclusion} from measurement (\(\beta\) =
-0.00003). We consider these conflicting results a wash.

Another way to consider effect decay is to look at studies which measure
consumption at multiple time points
\citetext{\citealp[e.g.][]{bianchi202022}; \citealp[@bschaden2020, @carfora2023]{bochmann2022}; \citealp{jalil2023}}.
We note that for the most part, effects seem to decline over time;
\citep{jalil2023}, where effects persist for at least three years, is a
prominent counter-example. However, because most of the studies we
looked at featured attrition over time, we do not place too much stock
in this result.

\begin{comment} There is probably a way to do this quantitatively and if we get asked to do it in review, I'll do it, but it's a fair bit of work and I think we've made the general point 
\end{comment}

\subsection{Persuasion messages are more persuasive in conjunction with
psychological appeals}\label{sec2.10}

The conjunction of persuasion messages with psychological appeals is, in
this dataset, the best supported theory for producing consistent, albeit
small changes in dietary behavior: 0.094 (SE = 0.096), p = .3552. This
is about twice as large as the pooled effect size from persuasion
messages on their own and about one-third larger than psychological
appeals on their own. However, with just
\texttt{r}persuasion\_psychology\_model\$N\_studies` studies from 8 to
go on, we do not consider this an especially robust result, and we note
that the pooled effect size is still substantively small. Nevertheless,
we see this as tentative evidence that theoretical innovation in the
form of synergizing multiple theories is a promising avenue of MAP
reduction research.

\subsection{Heterogeneity by reporting, cluster assignment, delivery
method, and country}\label{sec2.11}

Our sample of studies is comparatively small, and many differences
between studies are confounded. For example, 23 of 24 interventions with
objectively reported outcomes are also studies of university
populations. Nevertheless we offer a few tentative explorations of
potential moderators of effect size.

Contrary to our expectations, self-reported and objectively collected
outcomes were not meaningfully different: 0.074 for objectively reported
vs 0.059 for self-reported. Likewise, the difference in effect sizes for
studies where treatment was assigned to clusters (e.g.~cafeteria or day
of treatment) vs.~individuals is small.

Table 4 displays the effect size associated with the four most common
delivery mechanisms in our dataset, which were also the groups with
enough clusters for meta-analysis to be viable.

\begin{table}[!h]
\centering
\caption{\label{tab:table_four}Difference in effect size by delivery method}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Delivery method & N (Interventions) & N (Studies) & N (subjects) & Glass's $\Delta$ (SE)\\
\midrule
Printed Materials & 57 & 13 & 10900 & 0.0140 (0.0270)\\
In-Cafeteria & 19 & 10 & 68300 & 0.0660 (0.0390)\\
Video & 16 & 10 & 5400 & 0.0120 (0.0170)\\
Online & 8 & 3 & 1800 & 0.0620 (0.0320)\\
\bottomrule
\end{tabular}
\end{table}

Table 5 displays effects associated with different regions.

\begin{table}[!h]
\centering
\caption{\label{tab:table_five}Difference in effect size by study region}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Region & N (Interventions) & N (Studies) & N (Subjects) & Glass's $\Delta$ (SE)\\
\midrule
North America & 71 & 22 & 40700 & 0.0460 (0.0230)\\
Europe & 32 & 15 & 37500 & 0.1190* (0.0540)\\
Asia, Australia, and worldwide & 11 & 5 & 10500 & 0.0010 (0.0730)\\
\bottomrule
\end{tabular}
\end{table}

Interventions with adult subjects are moderately more effective
(\(\Delta\) = 0.093 (SE = 0.039), p = .0325) than those with a
university population ( (\(\Delta\) = 0.056 (SE = 0.036), p = .1468).

\section{Methods}\label{sec3}

\textbf{Search}: We employed a multi-pronged search strategy for
assembling our database. First, we checked the bibliographies of three
recent reviews
\citep{mathur2021meta, bianchi2018conscious, bianchi2018restructuring}
for relevant studies. Second, we checked any possibly relevant study
that either cited or was cited by studies we from our first round of
coding Third, we checked the bibliographies of authors whose studies we
coded. Fourth, we contacted leading researchers in the field with our
in-progress database to see if we had missed any. Fifth, we repeated
steps two and three with new studies we had. Sixth, we searched Google
Scholar for terms that had come up in studies repeatedly (e.g.~``dynamic
norms + meat'', ``MAP reduction'', and ``plant-based diet +
effective'').

\begin{comment} 
does this need more description? This is not entirely reproducible I think but TBH it was not a major source of studies in our database
\end{comment}

Sixth, we checked database emerging from a parallel project being
conducted by Rethink Priorities. Seventh, we identified a further 130+
systematic reviews and checked their bibliographies, and obtained
qualified studies from six of those reviews
\citep{ammann2023, chang2023, DiGennaro2024, harguess2020, ronto2022, wynes2018}.
Eighth, we used an AI search tool (\url{<https://undermind.ai>}) to
check for gray literature. All three authors contributed to the search.

\textbf{Coding:} For quantitative outcomes, we selected the latest
possible outcome that had enouugh subjects to meet our inclusion
criteria. Sample sizes were drawn from the same post-test. All effect
sizes were standardized by the standard deviation of the outcome for the
control group at baseline whenever possible (Glass's \(\Delta\)). All
effect size conversions were conducted by the first author using methods
and R code initially developed for previous papers
\citep{paluck2019, paluck2021, porat2024} using standard techniques from
\citep{cooper2019}, with the exception of a difference in proportion
estimator created for \citep{paluck2021} and explained in our appendix.

\textbf{Meta-analysis:} Our initial set of analyses was pre-registered
on the Open Science Framework in November 2023
(\url{<https://osf.io/j5wbp>}), although the project evolved
substantially over time. We describe four important deviations in our
appendix. Our analyses use functions and models from the
\texttt{robumeta} \citep{fisher2015} and \texttt{tidyverse}
\citep{wickham2019} packages in \texttt{R} \citep{Rlang}. Our analysis
uses robust variance estimation methods \citep{hedges2010}.

\section{Discussion}\label{Sec4}

We offer three lenses through which to view our results.

First, one might focus on the small effect sizes and the moderate
evidence of publication bias and conclude that what meager effects we do
detect are likely overestimates, and therefore conclude that the true
effect being estimated in this dataset is a null.

Second, one might argue that our assembled database of studies \emph{is}
successfully changing consumption behavior, but in ranges too small for
most studies to detect. By this light, future studies should replicate
existing approaches with sufficient power to detect much smaller
effects.

Moreover, a change of a few percentage points might be significant in
some contexts. For example, if a college calculates that meat
consumption accounts for 20\% of its carbon emissions, a 5.4\% reduction
in meat consumption \citep{jalil2023} achieves about a 1\% reduction in
carbon output. Whether this is a cost-effective method of reducing
carbon output depends on the alternatives.

Third, one might look at the largest effect sizes in our dataset, for
instance, the seven interventions with an effect size of
\(\Delta \geq 0.5\)
\citep{bianchi2022, carfora2023, merrill2009, piester2020} and seek to
replicate and/or expand their approaches. However, we'd caution that
these seven interventions are comparatively small, with an average of 84
subjects.

We do not have a clear preference between these interpretations.
However, we are generally encouraged by trends in this literature.

First, as previously noted, a majority of studies that meet our
inclusion criteria have been published in the past few years, suggesting
an overall increase in attention to design and measurement validity.
Second, we applaud researchers in this field for publishing null results
when they find them. Third, we notice that the universe of possible
interventions and settings is much broader than those we analyzed,
suggesting that some promising approaches await rigorous evaluation.
e.g.~direct contact with animals on an animal sanctuary, price
gradations, high-intensity vegan meal planning, door-to-door canvassing,
or studies taking place in diverse settings such as retirement homes.
Fourth, the tentative but promising results from studies that combine
persuasive messages with psychological appeals suggest that
theoretically synergistic approaches are a promising path forward.

\backmatter

\bmhead{Supplementary information}

All code data, and documentation are available on GitHub
(\url{https://github.com/setgree/vegan-meta}) and Code Ocean {[}LINK{]}

\bmhead{Acknowledgments}

\emph{Thanks to Alex Berke, Alix Winter, Anson Berns, Hari Dandapani,
Adin Richards, Martin Gould, and Matt Lerner for comments on an early
draft. Thanks to Jacob Peacock, Andrew Jalil, Gregg Sparkman, Joshua
Tasoff, Lucius Caviola, and Emma Garnett for help with assembling the
database and providing guidance on their studies. We gratefully
acknowledge funding from the NIH (grant XXX) and Open Philanthropy
(YYY).}

\section*{Declarations}\label{declarations}
\addcontentsline{toc}{section}{Declarations}

\newpage

\section{Appendix}\label{appendix}

\subsection{Supplementary Methods}\label{supplementary-methods}

\subsubsection{Search terms}\label{search-terms}

really hard to get a handle on how to systematically search this
literature because of diverse language (no single disciplinary home)

``random'' ``nudge'' ``meat'' meat purchases information nudge nudge
theory meat purchasing meat alternatives default nudge

\subsubsection{Converting difference in proportions to standardized mean
difference}\label{converting-difference-in-proportions-to-standardized-mean-difference}

Conventional methods of converting binary outcomes to estimates of
standardized mean difference have some notable downsides, e.g.~any given
odds ratio is compatible with multiple possible effect sizes depending
on the rate of occurrence of the dependent variable \citep{gomila2021}.
We address this by treating all binary variables as draws from a
Bernoulli distribution with \(p(1 - p)\), where p is the proportion of
some event's occurrence. For example, if 50\% of the treatment group ate
vegetarian meals vs 45\% for the control group, then Glass's
\(\Delta = \frac{0.05}{\sqrt{0.45 * (1-0.45)}} = 0.1\).

\subsubsection{Four deviations from pre-analysis
plan}\label{four-deviations-from-pre-analysis-plan}

Our pre-analysis plan registered some general principles and hypotheses
for our search process, but did not otherwise do much to constrain how
or where we searched. It also included a synthesized dataset and some
mock analyses that resemble our final analyses in general form. However,
as the project evolved over time, we made four substantive changes to
our paper that we did not anticipate at the pre-analysis stage.

First, our initial draft combined RPM and MAP studies, taking the former
as providing face value estaimtes of the latter. However, we later
decided that RPM reduction was fundamentally a separate estimand, and
that without firm data on substitution to other kinds of MAP, we could
not say anything definite about the net effect on demand for MAP.

Second, and related, we initially included studies that were not
necessarily aimed at achieving overall MAP reduction, but rather a
generally healthier diet with some amount of chicken and/or fish, for
instance the Mediterranean diet. Many of these studies had otherwise
qualifying measurement strategies. However, we ultimately concluded that
these were a separate estimand as well, and we did not want to add noise
to the estimate of studies that were aimed more specifically at reducing
MAP consumption rather than causing inter-MAP substitution.

Third, our initial analyses used the random effects model from
\texttt{metafor} to calculate pooled effect sizes. However, as we
assembled our dataset, we noticed that many papers had, across
interventions, non-independent observations, typically in the form of
multiple treatments compared to a single control group. Upon discussion,
the team's statistician (MBM) suggested that the \texttt{CORR} model
from the \texttt{robumeta} package would be a better fit.

Using our original model from \texttt{metafor}, we detect a pooled
effect size of 0.024 (SE = 0.011), p = .0365. In relative terms, this is
substantially smaller, but in absolute terms, both this model and our
main model produce very small estimates. Table S2 provides an overview
of alternate estimates by our main theoretical approaches.

Fourth, we added many moderators to our dataset that we did not plan on,
such as a broad category for delivery method, whether a study was
intended to be emotionally activating, or whether a program had multiple
components. We did not end up focusing on these in our main paper but
include them in our dataset in case they are of interest.

\subsection{Supplementary Figure}\label{supplementary-figure}

This figure displays the relationship between standard error and effect
size. The colors correspond to theoretical approach and the shapes
correspond to the venue where results were published.

\includegraphics[width=1.2\linewidth,]{./figures/supplementary_figure-1}

\subsection{Supplementary Tables}\label{supplementary-tables}

Table S1 displays the category of source where we learned of papers in
our main dataset. \captionsetup[table]{labelformat=empty}

\begin{table}[!h]
\centering
\caption{\label{tab:supp_table_one}\textbf{Table S1}: Sources of papers in dataset}
\centering
\begin{tabular}[t]{lr}
\toprule
Source & Count\\
\midrule
Prior literature reviews & 15\\
Snowball search & 7\\
pre-existing knowledge & 3\\
Systematic search & 3\\
Internet search & 2\\
\addlinespace
Researcher CVs & 2\\
Rethink Priorities search & 2\\
AI search tool & 1\\
other & 1\\
\bottomrule
\end{tabular}
\end{table}

Table S2 displays the pooled effect size by theoretical approach when
using standard random effects estimation methods from the
\texttt{metafor} package (rather than the robust variance estimation
methods we ended up using from the \texttt{robumeta} package).

\begin{table}[!h]
\centering
\caption{\label{tab:supp_table_two}\textbf{Table S2}: Approach by theory with alternate estimation methods }
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Approach & N (Interventions) & N (Studies) & N (subjects) & Glass's $\Delta$ (SE)\\
\midrule
Choice Architecture & 3 & 2 & 12200 & 0.2420 (0.2300)\\
Persuasion & 76 & 25 & 21300 & 0.0150 (0.0130)\\
Persuasion + Psychology & 17 & 9 & 2100 & 0.1150 (0.0630)\\
Psychology & 18 & 11 & 53100 & 0.0360 (0.0280)\\
\bottomrule
\multicolumn{5}{l}{\rule{0pt}{1em}* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001.}\\
\end{tabular}
\end{table}

\subsection{Supplementary Discussion}\label{supplementary-discussion}

\subsubsection{Edge cases for study
inclusion}\label{edge-cases-for-study-inclusion}

Arguably the hardest decision in meta-analysis is what studies to
include or exclude. By far the most common reason for exclusion was
category of dependent variable (e.g.~measuring attitudinal or
intentional outcomes). However, many cases were harder and required some
discussion. Here are a few cases we found difficult.

Some studies limit dietary portions or switch what people are served
(e.g.~children being served more vegetables at lunchtime). We did not
include these studies because they were essentially guaranteed to have
effects that were either positive or at least bounded at zero. However,
we did include studies that provided free access to meat alternatives
\citep{acharya2004, bianchi2022} and measured outcomes after the
intervention had concluded. (There were not enough of these studies in
our main dataset to analyze this approach separately, but their effect
sizes are
\texttt{dat\ \textbar{}\textgreater{}\ filter(author\ ==\ \textquotesingle{}Acharya\textquotesingle{})\ \textbar{}\textgreater{}\ pull(d)}
and
\texttt{dat\ \textbar{}\textgreater{}\ filter(author\ ==\ \textquotesingle{}Bianchi\textquotesingle{})\ \textbar{}\textgreater{}\ pull(d)}
respectively.)

Other studies induce a form of treatment in their control groups, for
instance asking subjects to take a pledge to go vegetarian or
encouraging them not to change their diet over the course of study,
which could potentially induce changes relative to baseline consumption
patterns. Our main database only includes studies with a pure control
group or an unrelated placebo. However, we include these studies in our
supplementary robustness check.

A few studies recruit an already motivated population, e.g.~people
looking to cut back on their MAP consumption. We consider this a
separate estimand and do not include these studies in our main dataset,
but we do include them in our supplementary robustness check.

Another common design limitation we encountered was treatment assigned
at the level of alternating weeks at a cafeteria. Generally these
studies did not have enough weeks to meet our sample size requirements,
but we also note that simply alternating weeks is not random assignment,
and it is possible that consumption patterns in these studies will not
be equivalent between groups in expectation.

Last, we encountered many studies that measured fruit and or/vegetable
consumption but not MAP consumption. In some cases, it might have been
possible to add assumptions about substitution and estimate effect
sizes, but we decided to focus on studies that reported this information
directly.

\subsection{Robustness check: including X additional studies that with
near-random
assignment}\label{robustness-check-including-x-additional-studies-that-with-near-random-assignment}

\begin{itemize}
\tightlist
\item
  much larger effect size on average in these studies
\item
  still only looking at consumption outcomes
\item
  robustness studies get excluded for one of eight reasons: horse race
  design, no delay, underpowered, not randomized randomization issue,
  statistical issue, encourages substitution to fish, and portion size
  change
\item
  mention that the default studies lead the way here but we are
  concerned about net effect not effect on one meal. What happens after
  the default gets changed is not clear. If it's a great vegan meal, it
  might be habit-forming in the good direction. If it's a bad one, it
  might be habit-forming in the wrong direction. If it's perceived as
  ``not quite a full meal,'' people might be more inclined to eat meat
  at the next meal. Who knows?
\item
  do effect sizes by each exclusion category? (or at least the main
  ones)
\item
  amalgamate everything -- get bigger effect size. amalgamate the RPMC
  studies -- get even bigger effect sizes
\end{itemize}

{[}TO FILL IN{]}

\subsubsection{Defining the boundaries of nudge
interventions}\label{defining-the-boundaries-of-nudge-interventions}

Tallying how many studies pursue a given theory of change requires
drawing boundaries between those theories. This required judgment calls
about which studies embodied a nudge approach. There is some scholarly
debate about whether norms intervention qualify as nudges
\citep{bicchieri2023}. The canonical definition of nudge
\citep{thaler2009} is ``any aspect of the choice architecture that
alters people's behaviour in a predictable way, without forbidding any
options or significantly changing their economic incentives. To count as
a mere nudge, the intervention must be easy and cheap to avoid'' (p.~6),
while others \citep{hausman2010} define nudges as ``ways of influencing
choice without limiting the choice set or making alternatives
appreciably more costly in terms of time, trouble, social sanctions, and
so forth'' (p.~126).

By this definition, an injunctive norm intervention, which implies a
threat of social deviance and therefore sanction, clearly does not
qualify. Whether a descriptive norm can be a nudge is trickier. Nudges
are generally designed to address ``flaws in individual
decision-making'' \citep[126]{hausman2010}, while others identify
``unthinking conformity'' as an example of a ``human failing'' that
nudges take as their ``starting point'' \citep[4]{mols2015}.

Our view is that a social norm prompt might engender a rich array of
possible reactions, both cognitive and affective, and we do not assume
that ``unthinking conformity'' is the dominant or exclusive response.
Therefore, we do not classify the norms interventions in our database as
nudges. (A future project might investigate exactly what reactions are
occurring by asking subjects how well they recall a norms message and
what it made them think about. A high prevalence of subjects who are
unable to recall the message's specifics but nevertheless cut back on
MAP consumption would be evidence that norms are acting through
automatic rather than reflective processes.)

Likewise, providing reasoned arguments for cutting back on MAP
consumption is not a nudge because they are not aimed at flaws in
decision-making, but rather a standard model of knowledge, attitude, and
practice. This was true even if the information was deliveredin an
unobtrusive way, e.g.~a daily email \citep{banerjee2019}.

Garnett 2020 says ``A third set of interventions that target
non-conscious processes and the contexts in which behaviours
occur---so-called `nudging' or `choice architecture' approaches---hold
promise but are largely untested''. Nothing unconscious about a pledge
or receiving a daily text

\subsubsection{Some other theoretical boundary lines we
considered}\label{some-other-theoretical-boundary-lines-we-considered}

\subsubsection{A lack of follow-up data in cafeteria-based
interventions}\label{a-lack-of-follow-up-data-in-cafeteria-based-interventions}

One potential source of measurement error that we cannot easily correct
for is the possibility that a subject who is guided towards eating less
meat at one meal eats more at the next, i.e.~``regression to the meat.''
Most cafeteria-based studies we looked at were not designed to measure
this kind of spillover effect, although such designs are possible
\citep{vocski2024}. We encourage researchers in this field to collect
follow-up outcomes.

\subsubsection{Notes on prior reviews}\label{notes-on-prior-reviews}

TO FILL IN: a few sentences about the reviews that contributed studies
to our search. Then a bit about reviews that we found otherwise
noteworthy. Then, a few notes on where our conclusions do or do not
converge with prior reviews, e.g.

\begin{itemize}
\item
  A forthcoming meta-analysis of dynamic norms interventions concludes
  that their overall effects on MAP consumption are negligible
  \citep{Weikertova2024}.
\item
  These disappointing results {[}animal advocacy{]} conflict with the
  central conclusions of \citep{mathur2021effectiveness}, but accord
  with the finding in \citep{DiGennaro2024} that animal welfare appeals
  produce a null effect on average.
\item
  (\citep{bianchi2018conscious} also found effects on intentions and
  attitudes but no evidence of effects on behavior.)
\end{itemize}

\newpage

\renewcommand\refname{References}
\bibliography{./vegan-refs.bib}


\end{document}
