%Version 2.1 April 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[sn-nature,referee,pdflatex]{sn-jnl}

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published
%%%%  by Springer Nature. The guidance has been prepared in partnership with
%%%%  production teams to conform to Springer Nature technical requirements.
%%%%  Editorial and presentation requirements differ among journal portfolios and
%%%%  research disciplines. You may find sections in this template are irrelevant
%%%%  to your work and are empowered to omit any such section if allowed by the
%%%%  journal you intend to submit to. The submission guidelines and policies
%%%%  of the journal take precedence. A detailed User Manual is available in the
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

\usepackage{comment}
\usepackage{anyfontsize}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}


\raggedbottom




% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}





\begin{document}


\title[MAP-reduction-meta]{Meaningfully reducing consumption of meat and
animal products is an unsolved problem: results from a meta-analysis}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate}
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Seth
Ariel} \sur{Green} }\email{\href{mailto:setgree@stanford.edu}{\nolinkurl{setgree@stanford.edu}}}

\author[1]{\fnm{Maya B.} \sur{Mathur} }

\author[2]{\fnm{Benny} \sur{Smith} }



  \affil[1]{\orgdiv{Humane and Sustainable Food Lab}, \orgname{Stanford
University}}
  \affil[2]{\orgname{Allied Scholars for Animal Protection}}

\abstract{Which theoretical approach leads to the broadest and most
enduring reductions in consumptions of meat and animal products (MAP)?
We address these questions with a theoretical review and meta-analysis
of rigorous randomized controlled trials with consumption outcomes. We
meta-analyze 36 papers comprising 42 studies, 114 interventions, and
approximately 88,000 subjects. We find that these papers employ four
major strategies to changing behavior: choice architecture, persuasion,
psychology, and a combination of persuasion and psychology. The pooled
effect of all 114 interventions on MAP consumption is \(\Delta\) =
0.065, indicating an unsolved problem. Reducing consumption of red and
processed meat is an easier target: \(\Delta\) = 0.249, but because of
missing data on potential substitution to other MAP, we can't say
anything definitive about the consequences of these interventions on
animal welfare. We further explore effect size heterogeneity by
approach, population, and study features. We conclude that while no
theoretical approach provides a proven remedy to MAP consumption,
designs and measurement strategies have generally been improving over
time, and many promising interventions await rigorous evaluation.}

\keywords{meta-analysis, meat, plant-based, randomized controlled trial}



\maketitle

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Introduction}\label{sec1}

Consumption of meat and animal products (MAP) is increasingly recognized
as a major contributor to premature deaths
\citep{willett2019, landry2023}, public health risks
\citep{slingenbergh2004, graham2008}, ecological harms
\citep{greger2010} and climate change
\citep{scarborough2023, koneswaran2008} as well as an ethical crisis in
its own right \citep{kuruc2023, singer2023}.

Supply-side interventions, such as banning or taxing certain practices
or products, risk political backlash if they lack broad public support.
It is of vital importance, therefore, to assess which strategies and
theoretical perspectives lead to meaningful, enduring reductions in
demand for MAP, under which conditions, and for which populations.

The research on diet and its antecedents and consequences is vast. By
our count, there have been at least 130 previous published dietary
reviews in the past two decades, with at least 37 focused specifically
on MAP reduction. However, comparatively few of these are quantitative,
and most prior reviews investigated particular approaches, for example
choice architecture \citep{bianchi2018restructuring}, rather than
comparing the efficacy of different strategies. Moreover, two prior
investigations revealed three common gaps in the MAP reduction
literature: a dearth of long-term follow-ups, missing consumption
outcomes, and inattention to the gap between intentions and behavior
\citep{mathur2021meta, mathur2021effectiveness}. The lack of long-term
follow-ups is especially important in a literature where many
interventions successfully guide people to choosing vegetarian options
for a single meal \citep{hansen2021} but do not assess if the change is
habit-forming.

Our paper addresses these concerns by meta-analyzing randomized
controlled trials that

\begin{itemize}
\item
  were designed to voluntarily reduce MAP consumption, rather than
  encouraging substitution from red meat to white meat or to fish, or
  removing items from someone's plate
\item
  had least 25 subjects each in treatment and control, or, for
  cluster-randomized trials, at least 10 clusters in total;
\item
  measured MAP consumption, whether self-reported or observed directly,
  rather than (or in addition to) attitudes, intentions, beliefs or
  hypothetical choices;
\item
  featured a pure control group or placebo, rather than comparing
  multiple treatments
\item
  recorded outcomes at least a single day after the start of treatment.
\end{itemize}

Additionally, studies needed to be publicly circulated by December 2023
and published in English.

We coded 36 such papers
\citep{andersson2021, kanchanachitra2020, abrahamse2007, acharya2004, banerjee2019, bianchi2022, bochmann2017, bschaden2020, carfora2023, hennessy2016, piester2020, cooney2014, cooney2016, feltz2022, haile2021, hatami2018, jalil2023, mathur2021effectiveness, merrill2009, norris2014, peacock2017, polanco2022, sparkman2021, weingarten2022, aldoh2023, allen2002, camp2019, coker2022, griesoph2021, sparkman2017, sparkman2020, berndsen2005, bertolaso2015, fehrenbach2015, mattson2020, shreedhar2021}
comprising 42 separate studies, 114 interventions, and approximately
88000 subjects. (The N for subjects is a broad approximation because
many interventions were administered at the level of day or cafeteria
and did not record a precise number of human subjects.) The earliest
paper was published in 2002 \citep{allen2002}, and a majority (19 of 36)
have been published since 2020.

We also coded four supplementary datasets. First is a collection of 17
papers
\citep{anderson2017, carfora2017correlational, carfora2017randomised, carfora2019, carfora2019informational, delichatsios2001talking, dijkstra2022, emmons2005cancer, emmons2005project, jaacks2014, james2015, lee2018, perino2022, schatzkin2000, sorensen2005, wolstenholme2020}
that targeted and measured consumption of red and/or processed meat
(RPM), comprising 17 studies, 25 interventions, and approximately 35000
subjects.

Second is a dataset of 14 studies that we disqualified for
methodological reasons but that we include in a supplementary robustness
check
\citep{alblas2023, beresford2006, dannenberg2023, delichatsios2001eatsmart, epperson2021, frie2022, garnett2020, hansen2021, kaiser2020, lentz2020, lindstrom2015, loy2016, piazza2022, reinders2017, vlaeminck2014}.

Third, we coded a dataset of 898 papers that we excluded along with
their reasons for exclusion.

Fourth is a dataset of 134 review papers that we reviewed while
searching for papers.

All datasets are provided in our supplementary materials.

Studies in our primary database pursued three theories of change: choice
architecture, psychology, persuasion, or a combination of persuasion and
psychology.

\textbf{Choice Architecture} studies
\citep{andersson2021, kanchanachitra2020} manipulate aspects of physical
environments to reduce MAP consumtpion. Examples include placing a
vegetarian option at eye level on a cafeteria menu \citep{andersson2021}
or making it more laborious for people to serve themselves fish sauce
\citep{kanchanachitra2020}.

\begin{comment}
Do we put in something here about the line between choice architecture and nudge? I currently have it in the results section
\end{comment}

\textbf{Persuasion} studies
\citep{kanchanachitra2020, abrahamse2007, acharya2004, banerjee2019, bianchi2022, bochmann2017, bschaden2020, carfora2023, hennessy2016, piester2020, cooney2014, cooney2016, feltz2022, haile2021, hatami2018, jalil2023, mathur2021effectiveness, merrill2009, norris2014, peacock2017, polanco2022, sparkman2021, weingarten2022}
appeal directly to people to eat less MAP. These studies formed the
majority of our database. Arguments focus on health, the environment
(usually climate change), and animal welfare. Some are designed to be
emotionally activating, e.g.~presenting upsetting footage of factory
farms \citep{polanco2022}, while others present information more
factually, for instance about the relationship between diet and cancer
\citep{hatami2018}. Many persuasion studies combine arguments, such as a
lecture on the health and environmental consequences of eating meat
\citep{jalil2023}.

\textbf{Psychology} studies
\citep{aldoh2023, allen2002, camp2019, coker2022, griesoph2021, piester2020, sparkman2017, sparkman2020}
manipulate the interpersonal,cognitive, or affective factors associated
with eating meat. The most common psychological intervention is centered
on social norms. These studies seek to alter the perceived popularity of
non-MAP dishes \citep{sparkman2017}. Norms might be descriptive, stating
how many people engaged in the desired behavior \citep{aldoh2023}, or
dynamic, telling subjects that the number of people reducing their MAP
intake is increasing
\citep{aldoh2023, coker2022, sparkman2017, sparkman2020}. Another study
looked at response inhibition training, where subjects are trained to
associate meat with an inhibiting response \citep{camp2019}. The first
psychology study meeting our inclusion criteria was published in 2017.

Finally, a group of interventions combines \textbf{persuasion}
approaches with \textbf{psychological} appeals to reduce MAP consumption
\citep{berndsen2005, bertolaso2015, carfora2023, fehrenbach2015, hennessy2016, mattson2020, piester2020, shreedhar2021}.

These interventions typically combine persuasive messages with
information about changing norms. Others combine reasons to change one's
diet along with an intervention that tests the extended parallel process
model (how subjects react to fear \citep{fehrenbach2015}) or an
implementations intentions model \citep{shreedhar2021} where subjects
implement plans for changing their behavior.

\section{Results}\label{sec2}

\subsection{An overall small effect with some heterogeneity by
approach}\label{sec2.1}

Our overall meta-analytic effect size is \(\Delta\) = 0.063 (SE =
0.022), p = .0092. The aggregate effect is statistically significant,
but does not indicate a meaningful, enduring reduction.

Figure 1 displays the distribution of effect sizes, grouped by paper,
with each individual point representing an intervention. The overall
effect size is plotted at the bottom.

\includegraphics[width=1.2\linewidth,]{./figures/forest_plot-1}

Table 1 reports the number of studies, interventions, and approximate
subjects, as well as the pooled effect size, per theoretical approach.

\begin{table}[!h]
\centering
\caption{\label{tab:table_one}Choice architecture, Persuasion, Psychology, and Persuasion + Psychology approaches to MAP reduction}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Approach & N (Studies) & N (Interventions) & N (Subjects) & Glass's $\Delta$ (SE)\\
\midrule
\textbf{Overall} & 42 & 114 & 88800 & 0.0630** (0.0220)\\
Choice Architecture & 2 & 3 & 12200 & 0.2120 (0.0950)\\
Persuasion & 25 & 76 & 21300 & 0.0720* (0.0280)\\
Psychology & 11 & 18 & 53100 & 0.0890 (0.0450)\\
Persuasion + Psychology & 9 & 17 & 2100 & 0.0940 (0.0960)\\
\bottomrule
\multicolumn{5}{l}{\rule{0pt}{1em}* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001.}\\
\end{tabular}
\end{table}

Table 2 displays the numbers and findings of persuasion interventions by
topic.

\begin{table}[!h]
\centering
\caption{\label{tab:table_two}Three approaches to MAP reduction persuasion}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Persauasion Approach & N (studies) & N (interventions) & N (subjects) & Glass's $\Delta$ (SE)\\
\midrule
Health & 18 & 30 & 13900 & 0.0820 (0.0390)\\
Environment & 14 & 24 & 8400 & 0.0820 (0.0540)\\
Animal Welfare & 16 & 65 & 15700 & 0.0260 (0.0190)\\
\bottomrule
\multicolumn{5}{l}{\textsuperscript{} Note: because many studies present more than one category of message, the Ns for studies, \linebreak}\\
\multicolumn{5}{l}{interventions, and subjects will sum to more than the total numbers in the persuasion category.}\\
\end{tabular}
\end{table}

These small effects may surprise readers of previous reviews, which
typically found more positive results
\citep{mathur2021meta, meier2022, mertens2022}. We attribute this
difference to our stricter inclusion criteria. For instance, of the ten
largest effect sizes recorded in \citep{mathur2021effectiveness}, nine
were non-consumption outcomes and the tenth came from a non-randomized
design.

Per the papers' own calculations and data, 98 of 114 interventions had
null effects on net MAP consumption. However, many studies present a
wide variety of outcomes and present significant results as well.

\begin{comment}
Could put this back in: "Using our calculations of effect size and standard error 15 interventions have 95% confidence intervals that do not overlap with zero, 12 of which are positive effects, out of 114 interventions." But I think it's not necesssarys
\end{comment}

\subsection{Moderate evidence of publication bias}\label{sec2.2}

We conduct four tests for publication bias. None is conclusive.

\begin{comment} 
Could put in introductory remarks about how this puts our main results in one light or another? 
\end{comment}

First, in our dataset, effect size and standard error are positively
correlated, though not significantly.

Second, the 10 studies with pre-analysis plans have a smaller effect:
\(\Delta\) = 0.019 (SE = 0.025), p = .4747.

Third, the 13 studies with openly available data also have a smaller
effect: \(\Delta\) = 0.013 (SE = 0.028), p = .6665.

Fourth, the pooled effect size of interventions published in
peer-reviewed journals is larger than the pooled effect size from
advocacy organization publications, preprints, and student theses.

We consider these tests to be moderate evidence of publication bias in
this literature. On the other hand, the sheer quantity of null results
suggests that finding small, insignificant effects on MAP consumption is
not a major barrier to publication.

\begin{table}[!h]
\centering
\caption{\label{tab:table_three}Difference in effect size by publication status}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Publication status & N (Interventions) & N (Studies) & N (subjects) & Glass's $\Delta$ (SE)\\
\midrule
Advocacy, preprints, and theses & 56 & 11 & 6800 & 0.0110 (0.0430)\\
Journal Article & 58 & 31 & 81900 & 0.0830** (0.0270)\\
\bottomrule
\multicolumn{5}{l}{\rule{0pt}{1em}* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001.}\\
\end{tabular}
\end{table}

\subsection{Red and Processed Meat is an easier target}\label{sec2.3}

On average, interventions aimed at reducing consumption of red and
processed meat (RPM) outperform general MAP reduction interventions:
\(\Delta\) = 0.249 \text{(SE = 0.063)}, p = .0016. All but one of these
studies employs persuasion, and a majority (19 of 25) appeal to personal
health. However, these studies do not collect data on white meat and/or
fish consumption, and therefore their impact on MAP consumption overall
is unknown. (One study in our primary dataset aimed to reduce RPM
consumption but measured meat consumption overall \citep{shreedhar2021}.
That study found moderate positive effects in the short-run and no
effects in the long run.)

RPM is of special concern for its environmental and health consequences
\citep{grummon2023}, but some categories of meat considered sustainable
are arguably worse for animals on a pound-for-pound basis
\citep{mathur2022ethical}. For some plausible patterns of substitution,
these interventions are a net good for personal health and the
environment and a net bad for animal welfare.

\subsection{Psychological interventions work sometimes, but it is not
clear why or when}\label{sec2.4}

The overall effect for psychology interventions is \(\Delta\) = 0.089
(SE = 0.045), p = .0897. Of these 35 interventions, 28 are self-reported
nulls. Moreover, the spread of results within the dominant psychological
approach (norms interventions) is unusually large. For example, one
standout paper with four included studies, each featuring real-world
settings and objectively measured consumption outcomes, finds one
significant positive result, two nulls, and one significant backlash
\citep{sparkman2020}. We do not see, in this collection of studies, a
clear limiting principle for when psychological interventions achieve
their goals.

A forthcoming meta-analysis of dynamic norms interventions concludes
that their overall effects on MAP consumption are negligible
\citep{Weikertova2024}.

\begin{comment} say something about dannenberg 2024 or the 2024 meta-analysis that finds vey little?
\end{comment}

\subsection{The evidence for choice architecture on MAP consumption is
promising, but scant}\label{sec2.5}

Although choice architecture studies are common in the diet literature
writ large \citep{olafsson2024, cadario2020, szaszi2018}, only three
such studies from two papers \citep{kanchanachitra2020, andersson2021}
met our inclusion criteria. Two of those three had moderate effect sizes
on the order of a few percentage points of MAP reduction. The third had
a comparatively large effect (\(\Delta\) = 0.631); that study sought to
reduce the fish sauce consumption at a Thai university, and its most
effective intervention paired a modified spoon that made it harder for
people to serve themselves fish sauce along with a sign enjoining diners
to not add more than 2/3 teaspoons of fish sauce to their meal.

\begin{comment}
Arguably this second component  means that this study no longer qualifies as choice architecture because the message is not intended to act on unconscious processes; we include it because there is no reported enforcement mechanism and the modified spoon is a distinctly architectural change.
\end{comment}

We restrict our choice architecture analysis to studies that literally
alter the architecture of a choice, but two other studies in our dataset
describe themselves as pursuing nudges. The first encourages
participants to take a pledge to go vegetarian \citep{banerjee2019},
which implicitly corrects for time-inconsistent preferences, while the
second embeds a statement about the proportion of people who chose a
vegetarian meal in a specified time period at a university canteen
\citep{griesoph2021}, which creates what the authors call a ``social
comparison nudge.'' If we include these studies in our choice
architecture model, we get a pooled effect size of \(\Delta\) = 0.12 (SE
= 0.129), p = .4603, gleaned from 8 interventions with approximately
13500 subjects.

\begin{comment} maybe say something about Had our search extended to 2024, we would have likely included many more studies, many of which find small or null effects [cite]
\end{comment}

\subsection{Persuasion messages are more persuasive in conjunction with
psychological appeals}\label{sec2.6}

Combining persuasion messages with psychological appeals leads to a
pooled effect size that is moderately larger than either approach on its
own: \(\Delta\) = 0.094 (SE = 0.096), p = .3552. With just 9 studies
drawn from 8 papers in this sub-sample, we do not consider this a
particularly robust finding, and we note that the overall effect is
still substantively small. However, we do consider synthesizing multiple
theories into a singular framework to be a promising path forward for
researchers and encourage more such theoretical innovations.

\subsection{Health studies work better for RPM than for
MAP}\label{sec2.7}

The pooled effect size for persuasion studies with a health component on
MAP consumption is \(\Delta\) = 0.082 (SE = 0.039), p = .0634. This is
small and not significant, albeit larger than the overall pooled effect.

Health appeals are a component of 19 of 25 interventions aimed at
reducing RPM consumption, and are generally more effective there:
\(\Delta\) = 0.26 (SE = 0.065), p = .0015. This fits with a broader
context where official nutritional guidelines typically encourage
consumers to reduce RPM and consume moderate amounts of lean meat and
fish.

We also judge many health studies to be at elevated risk of
self-reporting bias. For example, one study seeks to induce a sense of
fear in subjects \citep{berndsen2005}, while others target people who
are at risk of cancer \citep{hatami2018} or cancer survivors
\citep{james2015, lee2018} with reasons they should change their diet,
and then ask subjects to self-report what they have eaten recently.

\subsection{Environmental appeals have modest positive
effects}\label{sec2.8}

The pooled effect size for persuasion studies with an environmental
component is \(\Delta\) = 0.082 (SE = 0.054), p = .1600. The strongest
evidence that these appeals produce real-world impacts is
\citep{jalil2023}, which substituted an introductory lecture in a
first-year economics class for a lecture on the environmental and health
consequences of meat, focusing mostly on the environment, and then
tracked student meal choices in dining halls for three years following.
That study found that treatment led to an overall reduction in MAP
consumption of 5.6\% (\(\Delta\) = 0.118). This study has low
statistical power due to its small number of clusters (5 each in
treatment and control, and SE = 0.572). However, due to its exceptional
commitment to long-term, oblique outcome measurement, we consider it to
be reasonably strong evidence for this intervention's efficacy among the
target population.

\subsection{Animal welfare appeals are almost always
ineffective}\label{sec2.9}

The pooled effect size for persuasion studies with an animal welfare
component is \(\Delta\) = 0.026 (SE = 0.019), p = .1954. A full 60 of 65
interventions in this category are self-described nulls. Slightly more
than half (32 of 65) lead to increases in MAP consumption, though just
one of these effects is statistically significant.

The 11 studies and 53 interventions using materials from advocacy
organizations find an overall effect of \(\Delta\) = -0.006 (SE = 0.02),
p = .7794.

\subsection{Mixed evidence of effect delay over time}\label{sec2.10}

A key quantity of interest is whether MAP reduction interventions are
habit-forming. A large effect observed immediately \citep{hansen2021}
could plausibly dissipate quickly and create no enduring changes.
Moreover, gudiing someone to have a vegetarian meal that they do not
enjoy might create a net backlash against non-MAP meals. On the other
hand, a small push in the right direction \textemdash a nudge towards a
vegan meal that someone really enjoys \textemdash might start a cascade
of positive changes.

In our dataset, we find mixed, inconclusive evidence of effect decay
over time. First, there is a tiny, positive relationship between number
of days separating treatment onset from outcome measurement and a tiny,
negative relationship between number of days separating treatment
\emph{conclusion} from measurement. We consider these results a wash.

Another way to consider effect decay is to look at studies which measure
consumption at multiple points
\citep[e.g.][]{bianchi2022, bochmann2017, bschaden2020, carfora2023, jalil2023}.
We note that for the most part, effects seem to decline over time; One
prominent counterexample is \citep{jalil2023}, where effects persist for
at least three years. However, because most of the studies we looked at
featured attrition over time, we do not place too much stock in this
result.

\begin{comment} There is probably a way to do this quantitatively and if we get asked to do it in review, I'll do it, but it's a fair bit of work and I think we've made the general point 
\end{comment}

\subsection{Heterogeneity by reporting, cluster assignment, delivery
method, and country}\label{sec2.11}

Our sample of studies is comparatively small, and many differences
between studies are confounded. For example, 23 of 24 interventions with
objectively reported outcomes are also studies of university
populations. Nevertheless we offer a few tentative explorations of
potential moderators of effect size.

Contrary to our expectations, self-reported and objectively collected
outcomes were not meaningfully different: 0.074 for objectively reported
vs 0.059 for self-reported. Likewise, the difference in effect sizes for
studies where treatment was assigned to clusters (e.g.~cafeteria or day
of treatment) vs.~individuals is small.

Table 4 displays the effect size associated with the four most common
delivery mechanisms in our dataset, which were also the groups with
enough clusters for meta-analysis to be viable.

\begin{table}[!h]
\centering
\caption{\label{tab:table_four}Difference in effect size by delivery method}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Delivery method & N (Interventions) & N (Studies) & N (subjects) & Glass's $\Delta$ (SE)\\
\midrule
Printed Materials & 57 & 13 & 10900 & 0.0140 (0.0270)\\
In-Cafeteria & 19 & 10 & 68300 & 0.0660 (0.0390)\\
Video & 16 & 10 & 5400 & 0.0120 (0.0170)\\
Online & 8 & 3 & 1800 & 0.0620 (0.0320)\\
\bottomrule
\end{tabular}
\end{table}

Table 5 displays effects associated with different regions. We see weak
evidence that these interventions are most effective in Europe.

\begin{table}[!h]
\centering
\caption{\label{tab:table_five}Difference in effect size by study region}
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Region & N (Interventions) & N (Studies) & N (Subjects) & Glass's $\Delta$ (SE)\\
\midrule
North America & 71 & 22 & 40700 & 0.0460 (0.0230)\\
Europe & 32 & 15 & 37500 & 0.1190* (0.0540)\\
Asia, Australia, and worldwide & 11 & 5 & 10500 & 0.0010 (0.0730)\\
\bottomrule
\end{tabular}
\end{table}

Interventions with adult subjects are moderately more effective
(\(\Delta\) = 0.093, SE = 0.039, p = .0325) than those with a university
population ( (\(\Delta\) = 0.056, SE = 0.036, p = .1468).

\section{Methods}\label{sec3}

\textbf{Search}: We employed a multi-pronged search strategy for
assembling our database. First, we checked the bibliographies of three
recent reviews
\citep{mathur2021meta, bianchi2018conscious, bianchi2018restructuring}
for relevant studies. Second, we checked any possibly relevant study
that either cited or was cited by studies we from our first round of
coding. Third, we checked the bibliographies of authors whose studies we
coded. Fourth, we contacted leading researchers in the field with our
in-progress database to see if we had missed any. Fifth, we repeated
steps two and three with new studies we had. Sixth, we searched Google
Scholar for terms that had come up in studies repeatedly (e.g.~``dynamic
norms + meat'', ``MAP reduction'', and ``plant-based diet +
effective'').

\begin{comment} 
does this need more description? This is not entirely reproducible I think but TBH it was not a major source of studies in our database
\end{comment}

Seventh, we checked a database emerging from a parallel project being
conducted by Rethink Priorities. Eighth, we identified a further 130+
systematic reviews and checked their bibliographies, and obtained
qualified studies from six of those reviews
\citep{ammann2023, chang2023, DiGennaro2024, harguess2020, ronto2022, wynes2018}.
Ninth, we used an AI search tool (\url{https://undermind.ai}) to check
for gray literature. All three authors contributed to the search.

\textbf{Coding:} For quantitative outcomes, we selected the latest
possible outcome that had enouugh subjects to meet our inclusion
criteria. Sample sizes were drawn from the same post-test. All effect
sizes were standardized by the standard deviation of the outcome for the
control group at baseline whenever possible (Glass's \(\Delta\)). All
effect size conversions were conducted by the first author using methods
and R code initially developed for previous papers
\citep{paluck2019, paluck2021, porat2024} using standard techniques from
\citep{cooper2019}, with the exception of a difference in proportion
estimator created for \citep{paluck2021} and explained in our appendix.

\textbf{Meta-analysis:} Our initial set of analyses was pre-registered
on the Open Science Framework in November 2023
(\url{https://osf.io/j5wbp}), although the project evolved substantially
over time. We describe four important deviations in our appendix. Our
analyses use functions and models from the \texttt{robumeta}
\citep{fisher2015}, \texttt{metafor} \citep{viechtbauer2010}, and
\texttt{tidyverse} \citep{wickham2019} packages in \texttt{R}
\citep{Rlang}. Our meta-analyses use robust variance estimation methods
\citep{hedges2010}.

\section{Discussion}\label{Sec4}

We offer three lenses through which to view our results.

First, one might focus on the small effect sizes and the evidence of
publication bias and conclude that the meager effects we detect are
likely overestimates, and therefore conclude that the true effect being
estimated in this dataset is a strict null.

Second, one might argue that our assembled database of studies \emph{is}
successfully changing consumption behavior, but in ranges too small for
most studies to detect. By this light, future studies should replicate
existing approaches with sufficient power to detect much smaller
effects.

Moreover, a change of a few percentage points might be significant in
some contexts. For example, if a college aiming to reduce its carbon
output might calculates that meat consumption accounts for 20\% of its
carbon emissions, a 5.4\% reduction in meat consumption
\citep{jalil2023} would achieve about a 1\% reduction in carbon output.
Whether this is comparatively cost-effective depends on the other
options available.

Third, one might look at the largest effect sizes in our dataset, for
instance, the five papers with an effect size of \(\Delta \geq 0.5\)
\citep{bianchi2022, carfora2023, kanchanachitra2020, merrill2009, piester2020}
and seek to replicate and/or expand their approaches.

We do not have a clear preference between these interpretations.
However, we are generally encouraged by trends in this literature.

First, as previously noted, a majority of studies that meet our
inclusion criteria have been published in the past few years, suggesting
an overall increase in attention to design and measurement validity.

Second, we applaud researchers in this field for publishing null results
when they encounter them.

Third, the tentative but positive results from studies that combine
persuasive messages with psychological appeals suggest that
theoretically synergistic approaches are a promising path forward.

Fourth, we notice that the universe of possible interventions and
settings is much broader than those we analyzed, suggesting that some
promising approaches await rigorous evaluation For example, direct
contact with animals on an animal sanctuary, price gradations,
high-intensity vegan meal planning, door-to-door canvassing, or studies
taking place in diverse settings such as retirement homes are all
promising candidates.

\backmatter

\bmhead{Supplementary information}

All code data, and documentation are available on GitHub
(\url{https://github.com/setgree/vegan-meta}) and Code Ocean {[}LINK{]}

\bmhead{Acknowledgments}

\emph{Thanks to Alex Berke, Alix Winter, Anson Berns, Hari Dandapani,
Adin Richards, Martin Gould, and Matt Lerner for comments on an early
draft. Thanks to Jacob Peacock, Andrew Jalil, Gregg Sparkman, Joshua
Tasoff, Lucius Caviola, Natalia Lawrence, and Emma Garnett for help with
assembling the database and providing guidance on their studies. We
gratefully acknowledge funding from the NIH (grant XXX) and Open
Philanthropy (YYY).}

\section*{Declarations}\label{declarations}
\addcontentsline{toc}{section}{Declarations}

\newpage

\section{Appendix}\label{Sec5}

\subsection{Supplementary Methods}\label{Sec5.1}

\subsubsection{Converting difference in proportions to standardized mean
difference}\label{Sec5.1.1}

Conventional methods of converting binary outcomes to estimates of
standardized mean differences have some notable downsides. For example,
any given odds ratio is compatible with multiple effect sizes depending
on the rate of occurrence of the dependent variable \citep{gomila2021}.
We address this by treating all binary variables as draws from a
Bernoulli distribution with variance \(p(1 - p)\), where p is the
proportion of some event's occurrence. For example, if 50\% of the
treatment group ate vegetarian meals vs 45\% for the control group, then
Glass's \(\Delta = \frac{0.05}{\sqrt{0.45 * (1-0.45)}} = 0.1\).

\subsubsection{Four deviations from pre-analysis plan}\label{Sec5.1.2}

Our pre-analysis plan registered some general principles and hypotheses
for our search process, but did not otherwise do much to constrain how
or where we searched. It also included a synthesized dataset and some
mock analyses that resemble our final analyses in general form. However,
as the project evolved over time, we made four substantive changes to
our paper that we did not anticipate at the pre-analysis stage.

First, our initial draft combined RPM and MAP studies, taking the former
as providing face value estaimtes of the latter. However, we later
decided that RPM reduction was fundamentally a separate estimand, and
that without firm data on substitution to other kinds of MAP, we could
not say anything definite about the net effect on demand for MAP.

Second, and related, we initially included studies that were not
necessarily aimed at achieving overall MAP reduction, but rather a
generally healthier diet with some amount of chicken and/or fish, for
instance the Mediterranean diet. Many of these studies had otherwise
qualifying measurement strategies and were generally highly powered and
well-designed \citep{beresford2006}. However, we ultimately concluded
that these were a separate estimand as well, and we did not want to add
noise to the estimate of studies that were aimed more specifically at
reducing MAP consumption rather than at inter-MAP substitution. Further,
we almost all of these studies featured self-reported data, and
comparatively few tracked all relevant categories of MAP.

Third, our initial analyses used the random effects model from
\texttt{metafor} to calculate pooled effect sizes. However, as we
assembled our dataset, we noticed that many papers had, across
interventions, non-independent observations, typically in the form of
multiple treatments compared to a single control group. Upon discussion,
the team's statistician (MBM) suggested that the \texttt{CORR} model
from the \texttt{robumeta} package would be a better fit.

Using our original model from \texttt{metafor}, we detect a pooled
effect size of 0.024 (SE = 0.011), p = .0365. In relative terms, this is
substantially smaller, but in absolute terms, both this model and our
main model produce very small estimates. Table S2 provides an overview
of alternate estimates by our main theoretical approaches.

Fourth, we added many moderators to our dataset that we did not plan on,
such as a broad category for delivery method, whether a study was
intended to be emotionally activating, or whether a program had multiple
components. We did not end up focusing on these in our main paper but
include them in our datasets for completeness.

\subsection{Supplementary Figure}\label{sec5.2}

This figure displays the relationship between standard error and effect
size. The colors correspond to theoretical approach and the shapes
correspond to the venue where results were published.

\includegraphics[width=1.2\linewidth,]{./figures/supplementary_figure-1}

\subsection{Supplementary Tables}\label{sec5.3}

Table S1 displays the category of source where we learned of papers in
our main dataset. \captionsetup[table]{labelformat=empty}

\begin{table}[!h]
\centering
\caption{\label{tab:supp_table_one}\textbf{Table S1}: Sources of papers in dataset}
\centering
\begin{tabular}[t]{lr}
\toprule
Source & Count\\
\midrule
Prior literature reviews & 15\\
Snowball search & 7\\
pre-existing knowledge & 3\\
Rethink Priorities search & 3\\
Systematic search & 3\\
\addlinespace
Internet search & 2\\
Researcher CVs & 2\\
AI search tool & 1\\
\bottomrule
\end{tabular}
\end{table}

Table S2 displays the pooled effect size by theoretical approach when
using random effects estimation methods from the \texttt{metafor}
package rather than the robust variance estimation methods implemented
in the \texttt{robumeta} package.

\begin{table}[!h]
\centering
\caption{\label{tab:supp_table_two}\textbf{Table S2}: Approach by theory with alternate estimation methods }
\centering
\begin{tabular}[t]{lrrrl}
\toprule
Approach & N (Interventions) & N (Studies) & N (subjects) & Glass's $\Delta$ (SE)\\
\midrule
Choice Architecture & 3 & 2 & 12200 & 0.2420 (0.2300)\\
Persuasion & 76 & 25 & 21300 & 0.0150 (0.0130)\\
Persuasion + Psychology & 17 & 9 & 2100 & 0.1150 (0.0630)\\
Psychology & 18 & 11 & 53100 & 0.0360 (0.0280)\\
\bottomrule
\multicolumn{5}{l}{\rule{0pt}{1em}* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001.}\\
\end{tabular}
\end{table}

\subsection{Supplementary Discussion}\label{sec5.4}

\subsubsection{The limits of systematic search for MAP reduction
papers}\label{sec5.4.1}

This literature has remarkable methodological, disciplinary, and
theoretical diversity. However, it also has few if any agreed upon terms
to describe itself. For instance,the term ``MAP'' is nonstandard; other
papers discuss animal-based proteins, animal products, meat, edible
animal products, plant-based foods, plant-based protein, and so on. This
diversity of language poses a particular challenge for anyone seeking to
systematically review this literature. Whether one has identified the
correct terms that each relevant study uses to describe itself is, for
all practical purposes, unknowable.

This informed our search process. Rather than starting with a list of
search terms, we began by reading prior reviews, and then reading the
studies cited by those reviews, to get a sense of the language that
studies used to describe themselves. We then pursued the multi-prongded,
iterative search process described in the main text. Ultimately, we used
systematic search techniques to fill in the the blanks when we had an
intuition that we were missing studies employing a particular approach.

The following are the Google Scholar search terms we used:

\begin{itemize}
\tightlist
\item
  ``random'' ``nudge'' ``meat''
\item
  ``meat'' ``purchases'' ``information'' ``nudge''
\item
  ``nudge'' ``theory'' ``meat'' ``purchasing''
\item
  ``meat'' ``alternatives'' ``default'' ``nudge''
\item
  ``dynamic'' ``norms'' ``meat''
\item
  ``norms'' ``animal'' ``products''
\end{itemize}

For each of these terms, we looked through ten pages of results.

\subsubsection{Edge cases for study inclusion}\label{sec5.4.2}

Arguably the hardest decision in meta-analysis is what studies to
include or exclude. By far the most common reason for exclusion was
category of dependent variable (e.g.~measuring attitudinal or
intentional outcomes). However, many cases were harder and required some
deliberation.

Some studies limit dietary portions or switch what people are served
(e.g.~children being served more vegetables at lunchtime). We did not
include these studies because they were essentially guaranteed to have
effects that were either positive or at least bounded at zero. However,
we did include studies that provided free access to meat alternatives
\citep{acharya2004, bianchi2022} and measured outcomes after the
intervention had concluded. (There were not enough of these studies in
our main dataset to analyze this approach separately, but their effect
sizes are 0.115 and 0.529 respectively.)

Other studies induce a form of treatment in their control groups, for
instance asking all subjects to take a pledge to go vegetarian. Our main
database only includes studies with a pure control group or an unrelated
placebo. However, we include a selection of studies in our supplementary
robustness check.

Another common design feature we encountered was treatment assigned at
the level of alternating weeks at a cafeteria. Generally these studies
did not have enough weeks to meet our sample size requirements. We also
note that simply alternating weeks is not equivalent to random
assignment.

Last, we encountered many studies that measured fruit and or/vegetable
consumption but not MAP consumption. In some cases, it might have been
possible to add assumptions about substitution and estimate effect
sizes, e.g.~if menus were fixed, but we exclusively meta-analyzed
studies that reported MAP consumption directly.

\subsection{Robustness check: including 15 additional studies that with
near-random assignment}\label{sec5.4.3}

While reviewing papers, we identified 14 high-quality papers comprising
17 studies, 25 interventions, and approximately 53000 subjects that did
not meet our search criteria. The most common exclusion reasons for
exclusion were: - statistically underpowered (typically too few
clusters) - not fully randomized (e.g.~treatment was altered by week but
not randomly) - lacking in a control group (meaning they compared two
MAP reduction treatments) - - without delay between treatment onset and
measurement.

One additional study encouraged participants to switch to fish. Each of
these robustness checks studies measures consumption outcomes rather
than attitudes and intentions.

This new dataset yields a pooled effect size of \(\Delta\) = 0.685 (SE =
0.317), p = .0472. Integrating these studies with our main dataset
yields an overall effect size of \(\Delta\) = 0.197 (SE = 0.057), p =
.0012. We would have considered this moderate evidence of these
interventions' efficacy at reducing MAP consumption.

A clear source of divergence between the small effect sizes in our main
dataset and the comparatively larger ones in the supplementary dataset
is that studies without delayed measurement tend to have larger effects.
For example, \citep{hansen2021} tested the effects of switching the
default meal to being vegetarian at three academic conferences, and
found remarkable effects: in one case, a rise from 2 \% of participants
choosing vegetarian meals to 87\%. However, we do not assume that this
represents an enduring reduction in MAP consumption. We are concerned
about ``regression to the meat:'' the possibility that a subject who is
guided towards eating less meat at one meal might eat more at the next.
We encourage researchers to design future default studies with this
challenge in mind, e.g.~by measuring habits both at the treated meal and
also the next one \citep{vocski2024}.

We also see that interventions with too few clusters or too few
participants to meet our criteria have much larger effects on average:
\(\Delta\) = 0.751 (SE = 0.395), p = .2166.

We draw two lessons from this robustness check. The first is that
methodological rigor is associated with smaller effect sizes. The second
is that our results are sensitive to how one defines and operationalizes
methodological rigor. A team that defined rigor differently, or that was
concerned about different sources of bias, might have found very
different results.

\subsubsection{Defining the the theoretical boundaries between studies
requires judgment calls}\label{sec5.4.4}

Tallying how many studies pursue a given theory of change requires
defining those theories and drawing boundaries between them. This proved
tricky in some cases. For instance, the words `choice architecture' and
`nudge' \citep{thaler2009} are not necessarily interchangeable in this
literature. Many studies described themselves as implementing nudges but
were not necessarily altering anything about the architecture of a
choice, and neither were they obviously seeking to operate on
`unconscious' processes \citep{garnett2020}. For instance, a text
message reminder of reasons to eat less meat is cheap and easy to
ignore, and is arguably designed to correct for time-inconsistent
preferences, a kind of cognitive bias. On the other hand, such a text
message also provides relevant information about the choice set, and if
every intervention that attempted this was a nudge, most studies in our
database would be nudges. We decided that the clearest way around this
was to separate interventions that altered the literal architecture of a
choice, and therefore were plausibly working on unconscious processes,
from interventions that tried to alter how people think or feel about
what they're eating.

Likewise with social norms messages. \citep{mols2015} identify
``unthinking conformity'' as an example of a ``human failing'' that
nudges take as their ``starting point'' (p.~4), and if social norms
activate an unthinking desire to conform, then arguably a message about
how many people are going vegetarian in one's community is a nudge. Our
view is that a social norm prompt might engender a rich array of
possible reactions, both cognitive and affective, and we do not assume
that ``unthinking conformity'' is the dominant or exclusive response.
Therefore, we do not classify the norms interventions in our database as
nudges.

A future project might investigate exactly what reactions are occurring
by asking subjects how well they recall a norms message and what it made
them think about. A high prevalence of subjects who are unable to recall
the message's specifics but nevertheless cut back on MAP consumption
would be evidence that norms are acting through automatic rather than
reflective processes.'

Reasonable people might have defined the theoretical boundary conditions
differently. For instance, rather than grouping psychology approaches
together, one might separate interpersonal processes (norms) from purely
personal processes, e.g.~pledges, implementation intentions, or response
inhibition training. For this reason, we included in our dataset both
\texttt{theory} and \texttt{secondary\_theory} columns, and in the
latter we include more specific information about papers' approaches to
behavior change. We invite readers to explore different categories and
their respective pooled effect sizes by building on the code and data we
provide.

\subsubsection{Notes on prior reviews}\label{sec5.4.5}

It was striking to us there have been more systematic reviews of MAP
reduction research than there have been studies meeting our criteria. We
encourage scholars to pursue more randomized controlled trials with
consumption outcomes.

We turning to a selective overview of prior reviews of dietary
researchthat were highly relevant to this one.

Among the reviews that found MAP reduction interventions to be
effective, several focused exclusively on choice architecture.
\citep{arno2016} found that nudges led to an average increase of healthy
dietary choices of 15.3\%, while \citep{byerly2018} found that
committing to reduce meat intake and making menus vegetarian by default
were more effective than educational interventions. However, the vast
majority of vegetarian-default studies we analyzed for this paper did
not qualify for our analysis because they lacked delayed outcomes, and
their net effect on MAP consumption is unknown.

\citep{bianchi2018restructuring} found that reducing meat portions,
making alternatives available, moving meat products to be less
conspicuous, and changing meat's sensory properties can all reduce meat
demand. \citep{pandey2023} found that changing the presentation and
availability of sustainable products was effective in increasing demand
for them, as was providing information about them.

In a meta-review, \citep{grundy2022} found environmental education to be
most promising, with substantial evidence also supporting health
information, emphasizing social norms, and decreasing meat portions.

Some reviews have focused on particular settings for MAP reduction
interventions. \citep{hartmannboyce2018} found that grocery store
interventions, such as price changes, suggested swaps, and changes to
item availability, were effective at changing purchasing choices.
However, that review covered a wide variety of health interventions,
such as reducing consumption of dietary fat and increasing fruit and
vegetable purchases. It is unclear how directly such findings translate
to MAP reduction efforts.

\citep{chang2023} focused on university meat-reduction interventions and
found more promising results than did reviews that looked at the wider
public. This suggests that students and young people may be particularly
receptive to MAP reduction interventions. \citep{harguess2020} reviewed
22 studies on meat consumption and found promising results for
educational interventions focused on the environment, health, and animal
welfare. That paper recommends using animal imagery to cause an
emotional response and utilizing choice architecture interventions. Our
review, by contrast, found no relationship between animal welfare
appeals and MAP consumption.

Taking a different angle, \citep{adleberg2018} reviewed the literature
on protests in a variety of movements and found mixed evidence of
efficacy. The authors recommend that animal advocacy protests have a
specific target (e.g.~a particular institution) and ``ask.''

Other studies provide insights on who is most easily influenced by
interventions to reduce MAP consumption. For example,
\citep{blackford2021} found that nudges focused on ``system 1'' thinking
were more effective at encouraging sustainable choices than those
focused on ``system 2,'' and that interventions had greater effects on
females than males. Our review also featured studies showing differences
between men and women.

\citep{rosenfeld2018} reports that meat avoidance is associated with
liberal political views, feminine gender, and higher openness,
agreeableness and neuroticism. That review also identifies challenges
and barriers to vegetarianism, such as recidivism and hostility from
friends and family. Future research could tailor interventions to
address these barriers, such as by focusing on commitment devices to
reduce recidivism.

Several reviews have had mixed or inconclusive results. For instance,
\citep{bianchi2018conscious} found that health and environmental appeals
appear to change dietary intentions in virtual environments, but they
did not find evidence of actual consumption changes. In the same vein,
\citep{kwasny2022} notes that most existing research focuses on
attitudes and intentions and lacks measures of actual meat consumption
over an extended period of time. \citep{taufik2019} reviewed many
studies on increasing fruit and vegetable intake, but found far fewer on
reducing animal consumption.

\citep{benningstad2020} found, in a systematic review, that dissociation
of meat from its source plays a role in meat consumption, but no extant
research that included behavioral outcomes. \citep{graca2019} developed
a theoretical framework for understanding MAP reduction, finding
variables worth investigating further in future studies, while
\citep{pitt2017} provide insights on how food environments influence
consumer choices. That paper did not draw specific conclusions about
reducing MAP consumption. A few reviews have found evidence that seems
to recommend against particular interventions. \citep{greig2017}
reviewed the literature on leafleting for vegan/animal advocacy
outreach, and observed biases towards overestimating impact. That paper
concluded that leafleting does not seem cost-effective, though with
significant uncertainty. This accords with our findings on advocacy
organizations' limited effects.

\citep{nisa2019} meta-analyzed interventions to improve household
sustainability, of which reducing MAP consumption was one of several.
Although they found small effect sizes for most interventions, they
concluded that nudges were comparatively effective. Many such nudge
studies looked at meat consumption. Similarly, \citep{rau2022} reviewed
the literature on environmentally friendly behavior changes, including
but not limited to diet change, and found small or nonexistent effects
in most cases. Only 15 interventions were described as ``very
successful,'' and none of these related to food.

\begin{comment}
Some discussion about what's meaningful? mention that ease of implementation matters in terms of what’s meaningful. The costs of fully exposing one person is the relevant denominator. The costs of recruitment are part of the cost. Maybe some people are more amenable to nudges after hearing an argument for
\end{comment}

\newpage

\renewcommand\refname{References}
\bibliography{./vegan-refs.bib}


\end{document}
