---
classoptions: 
  - sn-nature      
  # - referee       # Optional: Use double line spacing 
  # - lineno        # Optional: Add line numbers
  # - iicol         # Optional: Double column layour
title: "Durably reducing consumption of meat and animal products is an unsolved problem: results from a meta-analysis"
titlerunning: MAP-reduction-meta
authors: 
  - firstname: Seth Ariel
    lastname: Green
    email: setgree@stanford.edu
    affiliation: 1
    corresponding: TRUE
  - firstname: Maya 
    lastname: Mathur
    affiliation: 1
  - firstname: Benny
    lastname: Smith 
    affiliation: 2
affiliations:
  - number: 1
    info:
      orgdiv: Humane and Sustainable Food Lab
      orgname: Stanford University
  - number: 2
    info:
      orgname: Allied Scholars for Animal Protection 
keywords:
  - key
  - dictionary
  - word
abstract: |
  Which theoretical approach leads to the broadest and most enduring reductions in consumptions of meat and animal products (MAP)? We address these questions with a theoretical review and meta-analysis of especially rigorous Randomized Controlled Trials (RCTs). We meta-analyze 33 papers comprising 39 studies,107 interventions, and approximately 78000 subjects. We find that these papers employ either a nudge, norms, or persuasion approach to changing behavior (some papers combine norms and persuasion). Unfortunately, the pooled effect of these interventions on MAP consumption outcomes is just $\Delta$ = 0.0603, suggesting that this is effectively an unsolved problem. Reducing consumption of red and processed meat appears to be an easier target: $\Delta$ = 0.2493, but because of missing data on potential substitution to other MAP, we canâ€™t say anything definitive about the consequences of these interventions on animal welfare. We further explore heterogeneity by approach, population, and study features. We conclude that while no theoretical approach provides a proven remedy to MAP consumption, research has generally been getting more rigorous over time, and many promising approaches remain untested.
bibliography: "./manuscript/vegan-refs.bib"
output: 
  rticles::springer_article
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	fig.path = "results/figures/",
	include = FALSE,
	out.extra = ""
)
  # This forces knitr to label all figures.

source('./scripts/libraries.R')
source('./scripts/functions.R')
source('./scripts/load-data.R')
source('./scripts/red-and-processed-meat.R')
```

# Introduction {#sec1}

Consumption of meat and animal products (MAP) is increasingly recognized as a major contributor to premature deaths [@willett2019; @landry2023], public health risks [@slingenbergh2004; @graham2008], ecological harms [@greger2010] and climate change [@scarborough2023; @koneswaran2008] as well as an ethical crisis in its own right [@kuruc2023; @singer2023].

Supply-side interventions, such as banning or taxing certain practices or products, risk political backlash if they do not have broad public support.
It is of vital importance, therefore, to assess which strategies and theoretical perspectives lead to the largest and most durable reductions in demand for MAP products, under which conditions, and for which populations.
We address these questions with a meta-analysis of the most rigorous studies aimed at reducing MAP consumption.

The research on diet and its antecedents and consequences is vast.
By our count, there have been at least 118 previous published dietary reviews in the past two decades, with at least thirty-seven focused specifically on MAP reduction.
However, comparatively few of these are quantitative, and most prior reviews investigated particular approaches, for example choice architecture [@bianchi2018restructuring], appeals to animal welfare [@mathur2021effectiveness], or literacy interventions [@DiGennaro2024], rather than comparing approaches to one another.
Moreover, two prior investigations revealed three common gaps in the MAP literature: a dearth of long-term follow-ups, consumption outcomes, and inattention to the gap between intentions and behavior [@mathur2021meta; @mathur2021effectiveness].

Our paper addresses these concerns by meta-analyzing randomized controlled trials (RCTs) that

-   were designed to voluntarily reduce MAP consumption, rather than (e.g.) encouraging substitution from red to white meat or fish or removing meat from someone's plate

-   had least 25 subjects each in treatment and control, or, for cluster-randomized trials, at least 10 clusters in total;

-   measured MAP consumption, whether self-reported or observed directly, rather than (or in addition to) attitudes, intentions, beliefs or hypothetical choices;

-   recorded outcomes at least a single day after the start of treatment.

Additionally, studies needed to be publicly circulated by December 2023 and published in English.

```{r useful_constants}
num_papers <- as.numeric(max(dat$unique_paper_id))
num_studies <- as.numeric(max(dat$unique_study_id))
num_interventions <- as.numeric(nrow(dat))
n_total <-  plyr::round_any(x = sum(dat$n_c_total_pop) + sum(dat$n_t_total_pop), 1000, floor)

RPMC_papers <- as.numeric(max(RPMC$unique_paper_id))
RPMC_studies <- as.numeric(max(RPMC$unique_study_id))
RPMC_interventions <- as.numeric(nrow(RPMC))
n_meat_total <-  plyr::round_any(x = sum(RPMC$n_c_total_pop) + sum(RPMC$n_t_total_pop), 1000, floor)

decade_tab <- dat |> group_by(unique_paper_id) |>  slice(1) |>  ungroup() |> count(decade)
```

We coded `r num_papers` papers [@abrahamse2007; @alblas2023; @aldoh2023; @allen2002; @andersson2021; @acharya2004; @berndsen2005; @bertolaso2015; @bianchi2022; @bochmann2017; @bschaden2020; @carfora2023; @coker2022; @cooney2016; @fehrenbach2015; @feltz2022; @griesoph2021; @haile2021; @hatami2018; @hennessy2016; @jalil2023; @lacroix2020; @mathur2021effectiveness; @mattson2020; @merrill2009; @norris2014; @peacock2017; @piester2020; @polanco2022; @sparkman2017; @sparkman2020; @sparkman2021; @weingarten2022] comprising `r num_studies` separate studies, `r num_interventions` interventions, and approximately `r n_total` subjects.
(Some treatments were administered at the level of day or cafeteria and did not record their number of human subjects.) The earliest paper was published in 2002 [@allen2002], and a majority (`r decade_tab$n[3]` of `r num_papers`) have been published since 2020.

We also coded a supplementary dataset of `r RPMC_papers` papers aimed at reducing, and measuring, consumption of red and/or processed meat (RPM) [@carfora2017correlational; @carfora2017randomised; @carfora2019; @carfora2019informational; @delichatsios2001; @dijkstra2022; @emmons2005cancer; @emmons2005project; @jaacks2014; @james2015; @lee2018; @perino2022; @schatzkin2000; @sorensen2005], comprising `r RPMC_studies` studies, `r RPMC_interventions` interventions, and approximately `r n_meat_total` subjects.
Last, we compiled a third dataset of 782 excluded studies, along with their reason(s) for exclusion.

# Results {#sec2}

## Three theoretical categories: persuasion, choice architecture, and norms {#sec2.1}

```{r table_one, message=F}
mr <- meta_result_formatter

# Overall
model <- dat |> map_robu()

# Nudge
nudge_model <- dat |> filter(theory == 'nudge') |> map_robu()
nudge_n <- dat |> filter(theory == 'nudge') |> 
  summarise(n_total = round_any(sum(n_t_total_pop + n_c_total_pop), 100, floor))
# Norms
norms_model <- dat |> filter(theory == 'norms') |> map_robu()
norms_n <- dat |> filter(theory == 'norms') |>
    summarise(n_total = round_any(sum(n_t_total_pop + n_c_total_pop), 100, floor))

# Norms + Persuasion
norms_persuasion_model <- dat |> filter(theory == 'norms & persuasion') |> map_robu()

norms_pers_n <-  dat |> filter(theory == 'norms & persuasion')|>
  summarise(n_total = round_any(sum(n_t_total_pop + n_c_total_pop), 100, floor))

# Persuasion Overall
persuasion_model <- dat |> filter(theory == 'persuasion') |> map_robu()

persuasion_n <- dat |> filter(theory == 'persuasion') |>
  summarise(n_total = round_any(sum(n_t_total_pop + n_c_total_pop), 100, floor))

# Table One
table_one <- tibble(
  Approach = c("\\textbf{Overall}", "Norms", "Nudge",
               "Persuasion", "Norms + Persuasion"),
  "N (Studies)" = c(model$N_studies, norms_model$N_studies, 
                    nudge_model$N_studies, persuasion_model$N_studies,
                    norms_persuasion_model$N_studies),
  "N (Interventions)" = c(model$N_interventions, norms_model$N_interventions,
                          nudge_model$N_interventions, 
                          persuasion_model$N_interventions,
                          norms_persuasion_model$N_interventions),
  "N (subjects)" = c(n_total, norms_n, nudge_n, persuasion_n, norms_pers_n),
  "Glass's $\\Delta$ (SE)" = c(mr(model), mr(norms_model),
                               mr(nudge_model), mr(persuasion_model), 
                               mr(norms_persuasion_model))) |> 
  kable(format = "latex", booktabs = TRUE, escape = FALSE,
        caption = "Norm, Nudge, and persuasion approaches to MAP reduction",
        label = "tab:table_one") |>
  kable_styling(latex_options = "hold_position") |>
  footnote(general_title = "",
           general = "* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001", 
           escape = FALSE)
table_one

# Persuasion (Health)
health_model <- dat |> filter(str_detect(secondary_theory, 'health')) |> map_robu()

# Persuasion (Environment)
environment_model <- dat |> filter(str_detect(secondary_theory, 'environment')) |> map_robu()

# Persuasion (Animal Welfare)
animal_model <- dat |> filter(str_detect(secondary_theory, 'animal')) |> map_robu()

# Table Two
table_two <- tibble(
  "Persuasion Approach" = c("Health", "Environment", "Animal Welfare"),
  "N (Studies)" = c(health_model$N_studies, 
                    environment_model$N_studies,
                    animal_model$N_studies),
  "N (Interventions)" = c(health_model$N_interventions, 
                          environment_model$N_interventions,
                          animal_model$N_interventions),
  "Glass's $\\Delta$ (SE)" = c(mr(health_model), 
                               mr(environment_model), 
                               mr(animal_model))
) |> 
  kable(format = "latex", booktabs = TRUE, escape = FALSE,
        caption = "Three types of persuasion",
        label = "tab:table_two") |>
  kable_styling(latex_options = "hold_position") |>
  footnote(general_title = "",
           general = "* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001.",
           escape = FALSE)
# add note that  because many studies present more than one category of message, the number of studies and interventions will sum to more than the total number of persuasion studies and interventions.
table_two
```

Studies in our database pursued one or more of three main theories of change: norms, nudges, and persuasion, or a combination of norms and persuasion.
Table 1 reports the distribution of studies, interventions, and subjects (approximately) per approach.

**Norms** studies manipulate perceptions of the popularity of desired outcomes, e.g. plant-based dishes [@sparkman2021] or using re-usable mugs[@loschelder2019].
Norms might be descriptive ("33% of British people...successfully engaged in one or more...behaviours to eat less meat" [@aldoh2023]), injunctive (a message with a frowning face for subjects who eat more meat than the average person in their country [@alblas2023]), or dynamic, i.e. they tell subjects that the number of people engaging in desired behavior is increasing [@aldoh2023; @coker2022; @sparkman2017; @sparkman2020; @sparkman2021].
The first norms study meeting our criteria was published in 2017.

**Persuasion** studies appeal directly to people about eating less meat.
These studies formed the majority of our database.
Arguments typically focus on health [@lacroix2020], the environment [@carfora2023] \textemdash usually climate change \textemdash and animal welfare [@haile2021].
Some are designed to be emotionally activating, e.g. presenting upsetting footage of factory farms [@bertolaso2015], while others present facts more dispassionately, e.g. about the relationship between diet and cancer [@hatami2018].
Many persuasion studies combine arguments, e.g. a leaflet with information in all three categories [@hennessy2016].

Table 2 displays the distribution of persuasion studies within these categories.

Finally, a handful of studies combines **norms and persuasion** approaches [@hennessy2016; @carfora2023; @lacroix2020; @mattson2020; @piester2020].
These interventions typically suggest reasons to eat less meat side by side with information about changing consumer habits in society.

## An overall small effect {#sec2.2}

Our overall meta-analytic effect size is $\Delta$ = `r model$Delta` (SE = `r model$se`), p = `r model$pval`.
The aggregate effect is statistically significant, but does not indicate a meaningful reduction.

Figure 1 displays the distribution of effect sizes, grouped by paper, with each individual point representing an intervention.
The overall effect size is plotted at the bottom.

```{r forest_plot_nulls_and_CIs, include=F}
source('./scripts/forest-plot.R')
print(forest_plot)

effect_size_table <- dat |> sum_tab(neg_null_pos)

significant_CIs <- dat |> select(author, year, d, se_d, neg_null_pos) |>
  mutate(lower_bound = d - (1.96 * se_d),
         upper_bound = d + (1.96 * se_d)) |>
  filter(lower_bound < 0 & upper_bound < 0 |
           lower_bound > 0 & upper_bound > 0) |> 
  mutate(direction = case_when
         (lower_bound > 0 ~ 1,
           upper_bound < 0 ~ 0))

# pap analysis
pap_model <- dat |> filter(public_pre_analysis_plan != 'N') |> map_robu()

## this difference is not statistically significant
dat <- dat |> mutate(pap_yes = if_else(public_pre_analysis_plan == 'N', FALSE, TRUE))

robumeta::robu(d ~ pap_yes, dat, unique_study_id, var_d)

# open data analysis
open_data_model <- dat |> filter(open_data != 'N') |> map_robu()

dat <- dat |> mutate(open_data_yes = if_else(open_data == 'N', FALSE, TRUE))

robumeta::robu(d ~ open_data_yes, dat, unique_study_id, var_d)
```

This small effect may surprise readers of previous reviews, which typically found more positive results [@mathur2021meta; @meier2022; @chang2023].
We attribute this difference to our stricter inclusion criteria.
For instance, of the ten largest effect sizes recorded in [@mathur2021effectiveness], nine were non-consumption outcomes and the tenth came from a non-randomized design.
([@bianchi2018conscious] also found effects on intentions and attitudes but no evidence of effects on behavior.)

As told by the papers in our dataset, `r effect_size_table['0']` of `r num_interventions` interventions had null effects.
However, many studies present a wide variety of outcomes, or include MAP reduction as one of many components of a broader program of behavior change, and focus on their significant results.
Using our calculations of effect size and standard error `r (nrow(significant_CIs))` interventions have 95% confidence intervals that do not overlap with zero, `r sum(significant_CIs$direction)` of which are positive effects, out of `r nrow(dat)` interventions.

## Moderate evidence of publication bias {#sec2.3}

We conduct four tests for publication bias.

First, in our dataset, $\Delta$ and standard error are positively correlated, though not significantly.
[FIGURE?]
Second, the `r pap_model$N_studies` with a pre-analysis plan have a smaller overall effect: $\Delta$ = `r pap_model$Delta` (SE = `r pap_model$se`), p = `r pap_model$pval`.
This difference is not statistically significant.
Third, the The `r open_data_model$N_studies` with openly available data also have a smaller overall effect: $\Delta$ = `r open_data_model$Delta` (SE = `r open_data_model$se`), p = `r open_data_model$pval`.
This difference is also not statistically significant.

Fourth, the pooled effect size of interventions published in peer-reviewed journals is about 9 times larger than the equivalent effect size in student theses (see table 3).
Interventions published by advocacy organizations produce a small backlash effect on average.

```{r pbulication_bias_checks_to_verify, include=F}

# "$\Delta$ and standard error are positively correlated, though not significantly"
dat |> sum_lm(d, se_d)
# a la the contact hypothesis re-evaluated, the implication here is that an infinitely powered
# study would have an effect size of 0.0008

# within journal articles? 
dat |> filter(pub_status == 'Journal article') |> sum_lm()
# A visual exploration:
dat |>
  ggplot(aes(x = se_d, y = d)) +
  geom_point(size = 2, aes(color = theory)) + # shape = self_report, 
  stat_smooth(method = 'lm', se = FALSE, lty = 'dotted') +
  scale_color_manual(values = c("norms" = "blue",
                                "norms & persuasion" = "red",
                                "nudge" = "green",
                                "persuasion" = "purple"
                                )) +
  labs(x = "Standard Error") +
  theme_minimal() 
```

```{r table_three, include=FALSE}
table_three <- dat |> 
  split(~pub_status) |> 
  map(map_robu) |> 
  map(~ .x |> mutate("Glass's $\\Delta$ (SE)" =
                       meta_result_formatter(.x))) |> 
  bind_rows(.id = 'Publication status') |> 
  mutate(`Publication status` = case_when(
    `Publication status` == "advocacy_org" ~ "Advocacy Organization",
    TRUE ~ `Publication status`
  )) |>
  rename(
    `N (Studies)` = N_studies,
    `N (Interventions)` = N_interventions) |>
 select(-c(Delta, se, pval))  |> 
  kable(format = "latex", booktabs = TRUE, escape = FALSE,
        caption = "Difference in effect size by publication status",
        label = "tab:table_two") |> 
  kable_styling(latex_options = "hold_position") |>
  footnote(general_title = "",
           general = "* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001.",
           escape = FALSE)

table_three
```

## Red and Processed Meat is an easier target {#sec2.4}

```{r RPMC_model, echo=F}
# ok this won't be a table
rpmc_model <- RPMC |> map_robu()

# table_three <- tibble(
#   "N (Studies)" = rpmc_model$N_studies,
#   "N (Interventions)" = rpmc_model$N_interventions,
#   "Glass's $\\Delta$ (SE)" = mr(rpmc_model)) |> 
#   kable(format = "latex", booktabs = TRUE, escape = FALSE,
#         caption = "Meta-analytic results for red and processed meat",
#         label = "tab:table_three") |>
#   kable_styling(latex_options = "hold_position") |>
#   footnote(general_title = "", 
#            general = "* p $<$ 0.05, ** p $<$ 0.01, *** p $<$ 0.001", 
#            escape = FALSE)
# table_three
```

On average, interventions aimed at reducing consumption of RPM outperform general MAP reduction interventions: $\Delta$ = `r rpmc_model$Delta` \text{(SE = `r rpmc_model$se`)}, p = `r rpmc_model$pval`.
Each of these studies employs persuasion, and a majority (16/19) appeal to personal health.
However, these studies do not collect data on white meat and/or fish consumption, and therefore their impact on MAP consumption overall is unknown.

Red meat is of special concern for its environmental and health consequences [@grummon2023], but eating chicken is arguably worse for animals on a pound-for-pound basis [@mathur2022ethical].
For some plausible patterns of substitution, these interventions are net positive for health and the environment and net negative for animal welfare.

## Norms work sometimes, but it is not clear why or when {#sec2.5}

```{r include=F, echo=F}
norms_overall_model <- dat |> filter(str_detect(theory, "norms")) |> map_robu()

# look at the distribution of effect sizes

norms_studies <- dat |> filter(str_detect(theory, "norms")) |> select(author, year, theory, d, se_d, intervention_condition, neg_null_pos) |> arrange(neg_null_pos, d) |> print(n = 30)

norms_proportions  <- norms_studies |>
  sum_tab(neg_null_pos)
```

The overall effect for intervention with a norms component is $\Delta$ = `r norms_overall_model$Delta` (SE = `r norms_overall_model$se`), p = `r norms_overall_model$pval`.
`r words(norms_proportions['0'])` of these `r nrow(norms_studies)` interventions are self-reported nulls.
Moreover, the spread of norms results is unusually large, with a fair number of backlash results [@mattson2020; @griesoph2021], and one paper with four studies, each featuring real-world settings and objectively measured consumption outcomes, found four one significant positive result, two nulls, and one significant backlash [@sparkman2020].
We do not see, in this collection of studies, a clear limiting principle for when norms interventions do or do not work.

## The evidence for nudges on MAP consumption is scant {#sec2.6}

Although nudges are common in the diet literature writ large [@olafsson2024; @cadario2020; @szaszi2018], only one nudge study met our inclusion criteria [@andersson2021].
That study manipulated the salience of a plant-based dish by varying its placement on a menu in a university cafeteria in Sweden.
Placing a plant-based dish at the top of the menu encouraged a decline in sales of the meat-based option, although most people then chose fish over the vegetarian option.
When this pattern is accounted for, the remaining effect is $\Delta$ = `r nudge_model$Delta` (SE = `r nudge_model$se`).

## Health studies work better for RPM than for MAP {#sec2.7}

```{r health_studies, echo=F, include=F}
health_studies <- dat |> 
  filter(str_detect(secondary_theory, 'health')) |> 
  select(author, year, secondary_theory, d, se_d, 
         self_report, neg_null_pos) |> 
  arrange(neg_null_pos, d) |> print(n = 30)

health_proportions <- 
  health_studies |> sum_tab(neg_null_pos)

RPM_health_model <- RPMC |>  
  filter(str_detect(secondary_theory, 'health')) |> map_robu()

# health studies form the majority of RPM studies
RPM_health_numbers <- RPMC |> mutate(health_component = if_else(str_detect(secondary_theory, 'health'), T,F)) |> 
  sum_tab(health_component)
```

The pooled effect size for persuasion studies with a health component is $\Delta$ = `r health_model$Delta` (SE = `r health_model$se`), p = `r health_model$pval`.
This is small and not significant, albeit larger than the overall pooled effect.
Health appeals are a component of `r RPM_health_numbers['TRUE']` of `r nrow(RPMC)` interventions aimed at reducing RPM consumption, and are generally more effective there: $\Delta$ = `r RPM_health_model$Delta` (SE = `r RPM_health_model$se`), p = `r RPM_health_model$pval`.

Many health studies either seek to induce a sense of fear in subjects [\@ @berndsen2005] or target people who are at risk of cancer [@hatami2018] or cancer survivors [@james2005; @lee2018] with health-based reasons to reduce their MAP or RPM consumption, and then ask them to self-report their diets.
We judge self-reporting bias to be a potential concern.

## Environmental appeals have modest positive effects {#sec2.8}

```{r environment_studies, include=F}
# exploratory
# do environmental 
dat |> filter(str_detect(secondary_theory, 'environment')) |> 
  split(~population) |> map(map_robu)

dat |> filter(str_detect(secondary_theory, 'animal')) |>  
  mutate(ad_yes_no = if_else(advocacy_org == 'N', FALSE, TRUE)) |> 
  split(~ad_yes_no) |> map(map_robu)

jalil_data <- dat |> filter(author == 'Jalil')
```

The pooled effect size for persuasion studies with an environmental component is $\Delta$ = `r environment_model$Delta` (SE = `r environment_model$se`), p = `r environment_model$pval`.
The strongest evidence that these appeals produce real-world impacts is [@jalil2023], which substituted an introductory lecture in a first-year economics class for a lecture on the environment and health consequences of meat, focusing mostly on the environment, and then tracked student meal choices in dining halls for three years following.
That study found that treatment led to an overall reduction in MAP consumption of 5.6% $\Delta$ = `r round(jalil_data$d, 3` (SE = `r jalil_data$se_d`), which is neither especially large nor statistically significant.
However, due to its exceptional commitment to long-term, oblique outcome measurement, we consider this study to be reasonably robust evidence for this intervention's efficacy among students at liberal arts colleges.

## Animal welfare appeals are mostly ineffective {#sec2.9}

```{r animal_welfare_studies, include=F}
animal_proportions  <- dat |> filter(str_detect(secondary_theory, 'animal')) |>
  sum_tab(neg_null_pos)

animal_proportions['0']

neg_animal_results <- dat |> filter(str_detect(secondary_theory, 'animal')) |> filter(d<0) |> count()

advocacy_model <- dat |> filter(advocacy_org != 'N') |> map_robu()
```

he pooled effect size for persuasion studies with an animal welfare component is $\Delta$ = `r animal_model$Delta` (SE = `r animal_model$se`), p = `r animal_model$pval`.
A full `r animal_proportions['0']` of `r animal_model$N_interventions` interventions in this category are self-described nulls.
Moreover, slightly more than half â€” `r neg_animal_results` of `r animal_model$N_interventions` â€” lead to increases in MAP consumption (though just one of these effects is statistically significant).

Moreover, the `r advocacy_model$N_interventions` interventions and `r advocacy_model$N_studies` studies using materials from advocacy organizations find an overall effect of `r advocacy_model$Delta` (SE = `r advocacy_model$se`), p = `r advocacy_model$pval`.

These disappointing results conflict with the central conclusions of [@mathur2021effectiveness], but accord with the finding in [@DiGennaro2024] that animal welfare appeals produce a null effect on average.

## Heterogeneity by country, self-reporting, cluster assignment, delivery method {#sec2.10}

```{r heterogeneity_analyses, include=F}

dat |> split(~self_report) |> map(map_robu)
dat |> split(~cluster_assigned) |> map(map_robu)
table(dat$delivery_method)

```

Contrary to our expectations, reports from self-reported and objectively reported outcomes were broadly similar (X and Y)

Cluster doesn't matter

Think about how to group continent and delivery method â€“ video doesn't work, leaflets don't work, but this is confounded by other differences

Think about how to group the delivery method results

# Methods {#sec3}

-   Search
-   Coding
-   Meta-analysis

# Discussion {#sec4}

## These studies are often underpowered to detect effects they actually find {#Sec4.1}

-   X studies do power calculations, and Y of those find results smaller than they're looking for,
-   they also plan effect sizes based on recruited sample rather than follow-up
-   plan for small effects and attrition

<!-- -->

-   in this article, we
-   we are enocuraged by increasing rigor
-   we look forward to seeing

\backmatter

\bmhead{Supplementary information}

\bmhead{Acknowledgments}

# Declarations {.unnumbered}

# Appendix {#secA1}

A LOT will go here

### Nudge lit is a mess

-   Theory; behavior change is just hard <https://www.nature.com/articles/s44159-024-00305-0> & most - interventions don't work <https://www.bu.edu/bulawreview/files/2023/12/STEVENSON.pdf>

-   but nudges claim to work â€“ so what's going on?

-   well, publication bias in nudge studies <https://www.pnas.org/doi/full/10.1073/pnas.2200300119> ,

-   it's easier to change beliefs <https://www.aeaweb.org/articles?id=10.1257/jel.20211658> (Effect Sizes on Beliefs versus Behavior),

-   nudges don't scale <https://onlinelibrary.wiley.com/doi/full/10.3982/ECTA18709>

-   "our read is quite different' <https://www.pnas.org/doi/10.1073/pnas.2200732119> automatacity is not the way forward

# Bibliography

# References

```{r cleanup, echo=F}
unlink("MAP-reduction-meta_files", recursive = TRUE)
```
