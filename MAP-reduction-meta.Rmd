---
classoptions: 
  - sn-nature      
  - referee         # Optional: Use double line spacing 
  # - lineno        # Optional: Add line numbers
  # - iicol         # Optional: Double column layout
title: "Meaningfully reducing consumption of meat and animal products is an unsolved problem: results from a meta-analysis"
titlerunning: MAP-reduction-meta
authors: 
  - firstname: Seth Ariel
    lastname: Green
    email: setgree@stanford.edu
    affiliation: 1
    corresponding: TRUE
  - firstname: Maya B.
    lastname: Mathur
    affiliation: 1
  - firstname: Benny
    lastname: Smith 
    affiliation: 2
affiliations:
  - number: 1
    info:
      orgdiv: Humane and Sustainable Food Lab
      orgname: Stanford University
  - number: 2
    info:
      orgname: Allied Scholars for Animal Protection 
keywords:
  - meta-analysis
  - meat
  - plant-based
  - randomized controlled trial
  
abstract: |
  Which theoretical approach leads to the broadest and most enduring reductions in consumptions of meat and animal products (MAP)? We address these questions with a theoretical review and meta-analysis of rigorous randomized controlled trials with consumption outcomes. We meta-analyze 36 papers comprising 42 studies, 114 interventions, and approximately 88,000 subjects. We find that these papers employ four major strategies to changing behavior: choice architecture, persuasion, psychology, and a combination of persuasion and psychology. The pooled effect of all 114 interventions on MAP consumption is SMD = 0.065, indicating an unsolved problem. Reducing consumption of red and processed meat is an easier target: SMD = 0.249, but because of missing data on potential substitution to other MAP, we can’t say anything definitive about the consequences of these interventions on animal welfare. We further explore effect size heterogeneity by approach, population, and study features. We conclude that while no theoretical approach provides a proven remedy to MAP consumption, designs and measurement strategies have generally been improving over time, and many promising interventions await rigorous evaluation.
date: "`r Sys.Date()`"
output: 
  rticles::springer_article:
    keep_tex: true
    keep_md: true

bibliography: "./vegan-refs.bib"
editor_options: 
  chunk_output_type: console
header-includes:
  - \usepackage{comment}
  - \usepackage{anyfontsize}
  - \usepackage{caption}
  - \usepackage{float}      # For precise float placement
  - \usepackage{placeins}   # Provides \FloatBarrier command
---

```{r setup, include=FALSE}

# directory modifications so we can put the manuscript stuff in its own folder
library(knitr)
library(rprojroot)

# so that knitr labels figures
knitr::opts_chunk$set(fig.path = "./figures/",
                      echo = FALSE,
                      out.extra = "")
options(tinytex.clean = TRUE) # switch to FALSE to get the bbl file for overleaf

# libraries, functions and data
source('./scripts/libraries.R')
source('./scripts/functions.R')
source('./scripts/load-data.R')
```

```{r models_and_constants, include=F}
# Models
## Overall
model <- robumeta::robu(formula = d ~ 1, data = dat, studynum = unique_study_id, 
                       var.eff.size = var_d, modelweights = 'CORR', small = TRUE)


## Extract and format key results for each model
overall_results <- extract_model_results()
rpmc_results <- RPMC |> extract_model_results()

# constants
num_papers <- as.numeric(max(dat$unique_paper_id))
num_studies <- as.numeric(max(dat$unique_study_id))
num_interventions <- as.numeric(nrow(dat))

n_total <- noquote(format(round_to(x = sum(dat$n_c_total_pop) + sum(dat$n_t_total_pop), 
                                  accuracy = 1000, direction = "down"),
                         big.mark = ",", scientific = FALSE))

decade_tab <- dat |> group_by(unique_paper_id) |>  slice(1) |>  ungroup() |> count(decade)

RPMC_papers <- as.numeric(max(RPMC$unique_paper_id))
RPMC_studies <- as.numeric(max(RPMC$unique_study_id))
```

# Introduction {#sec1}

Reducing global consumption of meat and animal products (MAP) is vital to reducing chronic disease and the risk of zoonotic pandemics [@willett2019; @landry2023; @hafez2020], abating environmental degradation and climate change [@poore2018; @koneswaran2008; @greger2010], and improving animal welfare [@kuruc2023; @scherer2019].
However, eating MAP is widely regarded as normal, ethical, and necessary [@piazza2022; @milford2019].
Global MAP consumption is increasing annually [@godfray2018] and expected to continue doing so [@whitton2021].

There is a vast and diverse literature investigating potential means to reverse this trend.
Example approaches include providing free access to meat substitutes [@katare2023], changing the price [@horgen2002] or perceptions [@kunst2016] of meat, or attempting to persuade people to change their diets [@bianchi2018conscious].
A large portion of this literature seeks to alter the contexts in which MAP is selected [@bianchi2018restructuring], for instance by changing menu layouts [@bacon2018; @gravert2021] or placing vegetarian items more prominently in dining halls [@ginn2024].
Some interventions are associated with large impacts [@hansen2021; @boronowsky2022; @reinders2017], and prior reviews have concluded that some frequently studied approaches, such as using persuasive messaging that appeals to animal welfare [@mathur2021meta] or making vegetarian meals the default [@meier2022], may be consistently effective.
In particular, choice architecture (i.e., manipulating how MAP is presented to diners, for example by making MAP the default option [@andersson2021]) has been cited as a cheap, effective way of altering dietary behavior [@colgan2024].
Governments, universities, and other institutions are increasingly implementing these ideas in such settings as dining halls [@pollicino2024] and hospital cafeterias [@morgenstern2024].

However, much of this literature is beset by design and measurement limitations.
Many interventions are either not randomized [@garnett2020] or underpowered [@delichatsios2001].
Many studies record outcomes that are imperfect proxies of MAP consumption, such as attitudes, intentions, and hypothetical choices [@raghoebar2020; @vermeer2010], yet behaviors often do not track with these psychological processes [@mathur2021effectiveness; @porat2024] and hypothetical preferences [@hensher2010].
Further, many studies measure only immediate impacts [@hansen2021; @griesoph2021] rather than longer-term effects.
Last, numerous studies specifically aim to reduce consumption of red and processed meat (RPM).
Such interventions may induce people to switch from consuming RPM to consuming other forms of MAP, such as chicken or fish [@grummon2023].
While RPM is of special concern for health and greenhouse gas emissions [@abete2014; @lescinsky2022], increasing chicken or fish consumption may lead to substantially worse outcomes for animal welfare [@mathur2022ethical], and fails to reduce the risk of zoonotic outbreaks from factory farms [@hafez2020] or land and water pollution [@grvzinic2023].

In the past few years, a new wave of MAP reduction research has made commendable methodological advances in design, outcome measurement validity, and statistical power.
Historically, in some scientific fields, strong effects detected in early studies with methodological limitations were ultimately overturned by more rigorous follow-ups [@wykes2008; @paluck2019; @scheel2021].
Does this phenomenon hold in the MAP reduction literature as well?

We answer this question with a meta-analysis of rigorously designed RCTs aimed at creating lasting reductions in MAP consumption [@andersson2021; @kanchanachitra2020; @abrahamse2007; @acharya2004; @banerjee2019; @bianchi2022; @bochmann2017; @bschaden2020; @carfora2023; @cooney2014; @cooney2016; @feltz2022; @haile2021; @hatami2018; @hennessy2016; @jalil2023; @mathur2021effectiveness; @merrill2009; @norris2014; @peacock2017; @polanco2022; @sparkman2021; @weingarten2022; @piester2020; @aberman2018; @aldoh2023; @allen2002; @camp2019; @coker2022; @sparkman2020; @berndsen2005; @bertolaso2015; @fehrenbach2015; @mattson2020; @shreedhar2021].
These RCTs all measured consumption outcomes at least a single day after treatment was first administered, and all had at least 25 subjects in both treatment and control, or, in the case of cluster-assigned studies, at least ten clusters in total.
Additionally, we coded a separate dataset of `r RPMC_studies` studies that otherwise met our inclusion criteria but instead measured changes in consumption of RPM [@anderson2017; @carfora2017correlational; @carfora2017randomised; @carfora2019; @carfora2019informational; @delichatsios2001talking; @dijkstra2022; @emmons2005cancer; @emmons2005project; @jaacks2014; @james2015; @lee2018; @lindstrom2015; @perino2022; @schatzkin2000; @sorensen2005; @wolstenholme2020].

Studies in our meta-analytic database pursued one of four theoretical approaches: choice architecture, psychological appeals (typically manipulations of perceived norms around eating meat), explicit persuasion (centered around animal welfare, the environment, and/or health), or a combination of psychological and persuasion messages.
Interventions varied in delivery method, for example, documentary films [@mathur2021effectiveness], leaflets [@peacock2017], university lectures [@jalil2023], op-eds [@haile2021], and changes to menus in cafeterias [@andersson2021] and restaurants [@coker2022; @sparkman2021].

We estimated overall effect sizes as well as effect sizes associated with different theoretical approaches and delivery mechanisms.
Although we find some heterogeneity across theories and mechanisms, we find consistently smaller effects on MAP consumption than previous reviews have suggested [@bianchi2018restructuring; @byerly2018; @chang2023; @harguess2020; @kwasny2022; @mathur2021meta; @meier2022; @pandey2023], with some intriguing exceptions.
Thus, contradicting previous reviews that analyzed a wider array of designs and outcomes, we conclude that meaningfully reducing MAP consumption is an unsolved problem.
However, many promising approaches still await rigorous evaluation.

# Results {#sec2}

## Descriptive overview {#sec2.1}

Our meta-analysis included `r num_papers` papers comprising `r num_studies` studies, and `r num_interventions` separate point estimates, each corresponding to a distinct intervention.
The total sample size was `r n_total` subjects (caveat that this is a broad approximation: many interventions were administered at the level of day or cafeteria and did not record how many individuals were assigned to treatment).

```{r mean_subjects, include=F}
total_pops <- dat |> filter(cluster_assigned == 'N') |> mutate(total_pop = as.numeric(n_c_post + n_t_post)) |> pull(total_pop)

median_total_pop <- round(median(total_pops, na.rm = TRUE))
percentile_25 <- round(quantile(total_pops, 0.25, na.rm = TRUE))
percentile_75 <- round(quantile(total_pops, 0.75, na.rm = TRUE))
```

The earliest paper was published in 2002 [@allen2002], and a majority (`r  decade_tab |> filter(decade == "2020s") |> pull(n)` of `r num_papers` papers) were published since 2020.
Among studies where treatment was assigned to individuals rather than by clusters, the median analyzed sample size per study was `r median_total_pop` subjects (25th percentile: `r percentile_25`; 75th percentile: `r percentile_75`).

## Constituent Theories {#sec2.2}

**Choice Architecture** studies [@andersson2021; @kanchanachitra2020] manipulate aspects of physical environments to reduce MAP consumption, such as placing the vegetarian option at eye level on a cafeteria menu [@andersson2021].

**Persuasion** studies [@kanchanachitra2020; @aberman2018; @abrahamse2007; @acharya2004; @banerjee2019; @bianchi2022; @bochmann2017; @bschaden2020; @carfora2023; @hennessy2016; @piester2020; @cooney2014; @cooney2016; @feltz2022; @haile2021; @hatami2018; @jalil2023; @mathur2021effectiveness; @merrill2009; @norris2014; @peacock2017; @polanco2022; @sparkman2021; @weingarten2022] Such messages are often delivered through printed materials, such as leaflets [@haile2021; @polanco2022], booklets [@bianchi2022] articles and op-eds [@sparkman2021; @feltz2022], and videos [@sparkman2021; @cooney2016; @mathur2021effectiveness].
Less common delivery methods included in-person dietary consultations [@merrill2009], emails [@banerjee2019], and text messages [@carfora2023].
Arguments focus on health, the environment (usually climate change), and animal welfare.

**Psychology** studies [@aldoh2023; @allen2002; @camp2019; @coker2022; @piester2020; @sparkman2020] manipulate the interpersonal,cognitive, or affective factors associated with eating meat.
The most common psychological intervention is centered on social norms seeking to alter the perceived popularity of non-MAP dishes [@sparkman2020].
In one study, a restaurant put up signs stating that "[m]ore and more [retail store name] customers are choosing our veggie options" [@coker2022].
In another, a university cafeteria put up signs stating that "[i]n a taste test we did at the [name of cafe], 95% of people said that the veggie burger tasted good or very good! Consider giving the garden fresh veggie burger a try today!” [@piester2020]. One study told participants that people who ate meat are more likely to endorse social hierarchy and embrace human dominance over nature, making meat-eaters out to be a counter-normative outgroup [@allen2002]. Other psychological interventions include response inhibition training, where subjects are trained to avoid responding impulsively to stimuli such as unhealthy food [@camp2019].

Finally, a group of interventions combines **persuasion** approaches with **psychological** appeals to reduce MAP consumption [@aberman2018; @berndsen2005; @bertolaso2015; @carfora2023; @fehrenbach2015; @hennessy2016; @mathur2021effectiveness; @mattson2020; @piester2020; @shreedhar2021].
These studies typically combine a persuasive message with a norms-based appeal [@piester2020; @mattson2020] or an opportunity to pledge to reduce one's meat consumption [@mathur2021effectiveness; @shreedhar2021].

## Meta-analytic results {#sec2.3}

```{r needed_vars, include=F}
low_prop_test <- prop_stronger( q = 0.1, M = overall_results$Delta,
                                t2 = overall_results$tau^2,
                                se.M = overall_results$SE, tail = "above",
                                estimate.method = "calibrated",
                                ci.method = "calibrated", dat = dat,
                                yi.name = "d", vi.name = "var_d",
                              bootstrap = "ifneeded", R = 200) |> 
   mutate(across(1:6, \(x) round(x, 3)))
low_prop_test
high_prop_test <- prop_stronger( q = 0.2,  M = overall_results$Delta,
                                t2 = overall_results$tau^2,
                                se.M = overall_results$SE, tail = "above",
                                estimate.method = "calibrated",
                                ci.method = "calibrated", dat = dat,
                                yi.name = "d", vi.name = "var_d",
                              bootstrap = "ifneeded", R = 200) |> 
     mutate(across(1:6, \(x) round(x, 3)))
high_prop_test
```

In our dataset, the pooled effect of all interventions is SMD = `r overall_results$Delta` (95% CI: `r overall_results$CI`), p = `r overall_results$p_val`, $\tau$ (standard deviation of population effects) = `r overall_results$tau`.
We estimate that `r round(low_prop_test$est * 100, 2)`% of true effects are above SMD = 0.1, and just `r round(high_prop_test$est * 100,2)`% are above SMD = 0.2.

Table 1 compares the overall meta-analytic estimate to the subgroup estimates associated with the four major theoretical approaches, as well as the three categories of persuasion.

\begin{center}
[Table 2 about here]
\end{center}
\begin{center}
[Figure 1 about here]
\end{center}

```{r rpmc_prop, include=F}

red_high_prop_test <- prop_stronger( q = 0.2, M = rpmc_results$Delta,
                                     t2 = rpmc_results$tau^2,
                                se.M = rpmc_results$SE, tail = "above",
                                estimate.method = "calibrated",
                                ci.method = "calibrated", dat = RPMC,
                                yi.name = "d", vi.name = "var_d",
                              bootstrap = "ifneeded", R = 200) |> 
     mutate(across(1:6, \(x) round(x, 3)))
```

By contrast, the 17 studies that only attempted to reduce consumption of RPM, comprising 25 point estimates, yielded a pooled effect of SMD = `r rpmc_results$Delta` (95% CI: `r rpmc_results$CI`), p = `r rpmc_results$p_val`, $\tau$ = `r rpmc_results$tau`.
We estimate that `r round(red_high_prop_test$est * 100, 2)`% of true RPM effects are above SMD = 0.2.

## Meta-regression on study characteristics analysis {#sec2.4}

Table 2 displays average differences in effect size by study population, region, era of publication, and delivery method.

\begin{center}
[Table 2 about here]
\end{center}

## Sensitivity Analyses {#sec2.5}

Table 3 presents average differences by publication status, data collection strategy, and open science practices.

\begin{center}
[Table 3 about here]
\end{center}

```{r publication_bias, include=F, message=F}
rma_model <- metafor::rma.uni(yi = d, vi = var_d, data = dat)
hedges_model <- selmodel(x = rma_model, type = 'stepfun', 
                         alternative = 'greater', steps = c(0.025, 1))

pub_bias_corrected_estimate <- PublicationBias::pubbias_meta(yi = dat$d, vi = dat$var_d, cluster = dat$unique_study_id, model_type = 'robust', favor_positive = TRUE, alpha_select = .05, small = TRUE, selection_ratio = 1) 

pub_bias_estimate <- round(pub_bias_corrected_estimate$stats$estimate, 3)
pub_ci_lower <- round(pub_bias_corrected_estimate$stats$ci_lower, 2)
pub_ci_upper <- round(pub_bias_corrected_estimate$stats$ci_upper, 2)
pub_ci_p_val <- round(pub_bias_corrected_estimate$stats$p_value, 3)

nulls <- dat |> filter(neg_null_pos == 0| neg_null_pos == -1)
worst_case <- extract_model_results(data = nulls)

```

The meta-analytic mean corrected for publication bias [@hedges1992] was `r round(hedges_model$b, 3)` (95% CI: [`r paste0(round(hedges_model$ci.lb, 3), ",", " ", round(hedges_model$ci.ub, 3))`]), p = `r round(hedges_model$pval, 3)`.
A conservative estimate that accounts for the possibility of worst-case publication bias [@mathur2024] yields an estimate of SMD = `r worst_case$Delta` (95% CI: `r worst_case$CI`), p = `r worst_case$p_val`.

Figure 2 is a significance funnel plot [@mathur2020] that relates studies’ point estimates to their standard errors and compares the pooled estimate within all studies (black diamond) to the worst-case estimate (gray diamond).

\begin{center}
[Fig 2 about here]
\end{center}

# Methods {#sec3}

```{r methods_nums, include=F}
reviews_count <- nrow(read.csv('./data/review-of-reviews.csv'))
excluded_count <- nrow(read.csv('./data/excluded-studies.csv'))
```

## Study selection {#sec3.1}

Our meta-analytic sample comprises randomized controlled trial evaluations of interventions intended to reduce MAP consumption that had at least 25 subjects in treatment and control (or at least 10 clusters for studies that were cluster-assigned) and that measured MAP consumption at least a single day after treatment begins.
We required that studies have a pure control group receiving no treatment.
We further restricted our search to studies that were publicly circulated in English by December 2023.

We also made two consequential post-hoc decisions regarding study inclusion: to count reductions in red and processed meat as a separate estimand and to analyze them separately, and to exclude studies that sought to induce substitution from one kind of MAP to another, e.g. swapping red meat with fish.

Given our interdisciplinary research question and previous work indicating a large grey literature [@mathur2021meta], we designed and carried out a customized search process.
We 1) reviewed `r reviews_count` prior reviews, nine of which yielded included articles [@mathur2021meta; @bianchi2018conscious; @bianchi2018restructuring; @ammann2023; @chang2023; @DiGennaro2024; @harguess2020; @ronto2022; @wynes2018]; 2) conducted backwards and forward citation search; 3) reviewed published articles by authors with papers in the meta-analysis; 4) crowdsourced potentially missing papers from leading researchers in the field 5) searched Google Scholar for terms that had come up in studies repeatedly; 6) used an AI search tool to search for gray literature (\url{https://undermind.ai/}); and 7) checked two databases emerging from ongoing nonprofit projects that both seek to identify all papers on meat-reducing interventions (see supplement for details).

All three authors contributed to the search.
Inclusion/exclusion decisions were primarily made by the first author, with all authors contributing to discussions about borderline cases.

Figure 3 is a PRISMA diagram depicting the sources of included and excluded studies (see supplement).

\begin{center}
[Fig 3 about here]
\end{center}

## Data extraction {#sec3.3}

The first author extracted all data.
We extracted an effect size for one outcome per intervention: the latest possible measure of net MAP or RPM consumption.
Sample sizes corresponded to the same time point.
Additional variables coded included information about publication, details of the interventions, length of delay, intervention theories, and additional details about interventions' methods, contexts, and open science practices (see accompanying code and data repository for full documentation).

When in doubt about calculating effect sizes, we consulted available datasets and/or contacted authors.

To assess risk of bias, we collected data on whether outcomes were self-reported or objectively measured, publication status, and presence of a pre-analysis plan and/or open data (see table 3).

All effect size conversions were conducted by the first author using methods and R code initially developed for previous papers [@paluck2019; @paluck2021; @porat2024] using standard techniques from [@cooper2019], with the exception of a difference in proportion estimator that treats discrete events as draws from a Bernoulli distribution (see appendix to [@paluck2021] for details).
We used Glass's $\Delta$ whenever possible as our measure of standardized mean difference: $\Delta = \frac{\mu_T - \mu_C}{\sigma_C}$.
We standardized on the SD of the control group at pre-treatment.
If group SDs were not available, we standardized on the pooled SD.
When means and SDs were not available, we converted effect sizes from: regression coefficients, eta squared, or z scores.
When there was insufficient information to calculate a specific SMD, but the text reports the result as a null, we recorded the outcome as an "unspecified null" and set it to 0.01.
If results were significant and we could not calculate an SMD, we excluded the study.

## Statistical analysis methods {#sec3.4}

Results were synthesized using robust variance estimation (RVE) methods [@hedges2010] as implemented by the `robumeta` package [@fisher2015] in `R`[@Rlang].
Many studies in our sample featured multiple treatment groups compared to a single control group.
Therefore, we used the RVE method to allow for the resulting dependence between observations, as well as a standard small-sample correction.

Data analyses were largely conducted with custom functions building on tidyverse [@wickham2019] We assessed publication bias using selection model methods [@hedges1992; @vevea1995], sensitivity analysis methods [@mathur2024], and the significance funnel plot [@mathur2020].
These methods assume that the publication process favors “statistically significant” (i.e., p \< 0.05) and positive results over “nonsignificant” or negative results.
Our sensitivity check meta-analyzes only non-affirmative results, which creates an estimate under a hypothetical “worst-case” publication bias scenario where affirmative studies are almost infinitely more likely to be published than non-affirmative studies.
We conducted these analyses using functions in `metafor` [@viechtbauer2010] and `PublicationBias` [@mathur2020; @mathur2024].

We used `Rmarkdown` [@xie2018] and a containerized [@moreau2023] online platform [@clyburne2019] to ensure computational reproducibility [@polanin2020].

# Discussion

Our overall effect of SMD = `r overall_results$Delta`, as well as our upper confidence bound of SMD = `r round(model$reg_table$CI.U, 2)`, lead us to conclude that reducing MAP consumption is an unsolved problem.
Effects were also consistently small across an array of locations, study designs, and intervention categories.
Some individual studies found comparatively larger effects (SMD \> 0.5: [@carfora2023; @merrill2009; @kanchanachitra2020; @bianchi2022; @piester2020]).
However, each builds on a fairly unique theory of change and employs idiosyncratic methods; these interventions are intriguing candidates for subsequent research and replication.
Therefore, we conclude that no theoretical approach, delivery mechanism, or intended persuasive message should be considered a well-validated method of reducing MAP consumption.

Though this may surprise readers of previous reviews [@mathur2021meta; @meier2022; @mertens2022], our divergent results likely reflect our stricter methodological inclusion criteria..
For instance, of the ten largest effect sizes recorded in [@mathur2021effectiveness], nine measured attitudes and/or intentions, and the tenth came from a non-randomized design.
Prior research has found that intentions often do not predict behavior [@mathur2021effectiveness], and reviews in other fields have found systematic differences in impacts between randomized and non-randomized evaluations [@porat2024; @stevenson2023].
Our results raise the possibility that previous reviews’ positive findings might be largely attributable to bias, though this will require further empirical evaluation.

Another potentially surprising result is that very few (two) choice architecture papers met our methodological inclusion criteria.
Most potentially eligible papers either measured hypothetical outcomes or measured outcomes immediately after the intervention.
Moreover, prior reviews that found choice architecture approaches to be consistently effective at modifying diet typically focused on foods that may have weaker cultural and social attachments than MAP, such as sugary drinks and snacks [@venema2020; @adriaanse2009].
We speculate that people are more likely to notice, and care, when their burger is missing from the choice set than when their soft drink has been made smaller.

Likewise, as our analyses show, studies aimed at reducing RPM consumption are associated with an effect about four times larger (SMD = 0.25) than those aimed at reducing all MAP consumption.
Sharply curtailing RPM consumption is a core component of current leading dietary guidelines, such as the heart-healthy diet [@diab2023], but many of these same diets actively encourage moderate intake of poultry and fish.
Further, reducing RPM consumption is frequently mentioned as something consumers can and should do to personally fight climate change [@auclair2024].
By contrast, vegetarianism is still a minority diet worldwide [@tilman2014] that consumers consider to be difficult, unsatisfying, and expensive [@bryant2019].
We speculate that cutting back on RPM is perceived as easier and more likely to be socially rewarded than is cutting back on MAP generally, and that this explains the observed difference in effect sizes.

```{r confounding_check, include=F}
confound_table <- dat |> filter(self_report == 'N') |> group_by(str_detect(population, 'university')) |> summarise(count = n()) |> as_tibble()

```

We caution that our analyses are limited by our small sample size.
Our moderation analysis, for instance, tests differences between studies that are highly confounded — `r confound_table$count[[2]]` of `r confound_table$count[[2]] + confound_table$count[[1]]` interventions with objectively reported outcomes are also studies of university populations, limiting our ability to detect the independent association of these variables with effect size.
Further, our meta-analytic database is a non-random sample of the literature writ large, and our estimates of publication bias should not be taken as estimates for the entire literature.
Most importantly, our results are sensitive to choices about included dependent variables, which arguably means they lack robustness.
However, this critique is a double-edged sword.
Our paper suggests that prior reviews' findings are also more sensitive to inclusion rules than was previously known.

Overall, we are encouraged by positive trends in the literature.
First, as noted, a majority of studies in our meta-analysis have been published since 2020, indicating the field's growing dedication to questions of credible design and measurement.
Second, we observe many fruitful collaborations between researchers and advocacy organizations, as shown by the plethora of nonprofit white papers in our sample.
Third, many promising designs and interventions yet await rigorous evaluation.
For instance, no study that met our criteria evaluated extended contact with farm animals [@cerrato2022], manipulations to the price of meat [@wilde2016], activating moral and/or physical disgust [@palomo2018], watching popular media such as the Simpsons episode *Lisa the Vegetarian* [@byrd2010] or the movie *Babe [@novatna2019]* , and many categories of choice architecture intervention [@olafsson2024].
Moreover, we are encouraged by contemporary research designs that offer creative solutions to longstanding measurement challenges, for example by implementing a default intervention at lunch and then measuring outcomes at dinner as well to assess potential compensatory effects [@vocski2024].

In sum, though we view meaningfully reducing MAP consumption as an unsolved problem, there is no reason to think it is unsolvable.

\bmhead{Acknowledgments}

*Thanks to Alex Berke, Alix Winter, Anson Berns, Hari Dandapani, Adin Richards, Martin Gould, and Matt Lerner for comments on an early draft. Thanks to Jacob Peacock, Andrew Jalil, Gregg Sparkman, Joshua Tasoff, Lucius Caviola, Natalia Lawrence, and Emma Garnett for help with assembling the database and providing guidance on their studies. Thanks to Estefania Vera Verduzco for research assistance. We gratefully acknowledge funding from the NIH (grant XXX), Open Philanthropy (YYY), and the Food Systems Research Fund (Grant FSR 2023-11-07).*

# Declarations {.unnumbered}

\newpage

## Tables

```{r meta_table, echo=FALSE, message=FALSE, results='asis'}
source('./scripts/table-one-meta.R')
meta_table
```

```{r moderator_table, echo=F, message=F}
source('./scripts/table-two-moderator.R')
moderator_table
```

```{r sensitivity_table,echo=F, message=F}
source('./scripts/table-three-sensitivity.R')
sensitivity_table
```

\FloatBarrier

## Figures

```{r forest_plot, fig.cap="Forest plot for MAP reduction studies. Each point corresponds to a fixed effects meta-analysis for each paper. Papers employing multiple theoretical approaches are represented once per theory. Dot size is inversely proportional to variance. Points are sorted within theory by SMD. A random effects meta-analysis for the entire dataset is plotted at the bottom. The black line demarcates an effect size of zero, and the dotted line is the observed overall effect.", echo=FALSE, message=F, fig.align='center', fig.pos='H', fig.height=9, fig.width=6}
source('./scripts/forest-plot.R')
forest_plot 
```

```{r funnel_plot, echo=FALSE, message=F, fig.align='center', fig.pos='H', fig.height=9, fig.width=6}
funnel_plot <- significance_funnel(yi = dat$d, vi = dat$var_d, favor_positive = TRUE, , alpha_select = 0.05, plot_pooled = TRUE)
funnel_plot
```

```{r prisma_diagram, echo=FALSE, message=FALSE, fig.align='center', fig.pos='H', fig.height=8, fig.width=6, out.width='100%'}
knitr::include_graphics('./figures/prisma-diagram.png')

```

\newpage

# Supplement {#Sec5}

## Robustness checks {#Sec5.1}

### Robustness to less stringent inclusion criteria {#Sec5.1.1}

```{r robustness_check, include=F}
source('./scripts/robustness-checks.R')

robust_only_results <- robust_dat |> extract_model_results()

# overall result with robust_dat merged
merged_dat <- full_join(dat, robust_dat) |> 
  select(c(-unique_study_id, unique_paper_id)) |>
  group_by(title) |>
  mutate(unique_paper_id = cur_group_id())  |>
  ungroup() |>
  group_by(unique_paper_id, study_num_within_paper) |>
  mutate(unique_study_id = cur_group_id()) |>
  ungroup() |>
  select(author, year, title, unique_paper_id, unique_study_id, everything())

merged_results <- merged_dat |> extract_model_results()

## look at biggest results
merged_dat |> arrange(desc(d)) |> select(author,year,  ,se_d, inclusion_exclusion) |> head(10)
```

Here we integrate and meta-analyze a supplementary dataset of `r robust_only_results$N_studies` studies comprising `r robust_only_results$N_estimates` with noteworthy results and many strong design features that nevertheless did not meet our inclusion criteria.
These studies were excluded for one of five reasons: 1) issues with random assignment or the control group (for instance, where the control group receives some aspect of treatment [@piazza2022], or where treatment was alternated weekly but not randomly [@garnett2020]); 2) underpowered (too few clusters [@reinders2017] or subjects [@lentz2019]); 3) immediate outcome measurement [@dannenberg2023; @sparkman2017; @griesoph2021; @hansen2021]; 4) actively encouraging substitution within categories of MAP, e.g. from red meat to fish [@celis2017; @johansen2009]; or 5) uncertainty in calculating an effect size arising from missing information about the behavior of diners who opt out of treatment to avoid a vegetarian meal [@betterfoodfoundation2023].

Taken together, our integrated dataset including both our main sample and this supplementary one yields a pooled effect of SMD = `r merged_results$Delta` (95% CI: `r merged_results$CI`), p = `r merged_results$p_val`.
Particularly large results were found in studies that measured outcomes immediately [@hansen2021] or that were underpowered [@lentz2020].

A reader with different beliefs about sources of bias in this literature than ours might conclude from this analysis that it is indeed possible, in some contexts, to meaningfully reduce MAP consumption.
Likewise for readers who take stated reductions in RPM consumption as unbiased estimates of overall MAP reduction.

### Robustness to alternative estimation strategies {#Sec5.1.2}

Our pre-analysis plan (\url{https://osf.io/3sth2}) used a cluster-robust random effects model from `metafor` to analyze a synthetic dataset.
However, as we assembled the real dataset, we noticed that many papers had, across interventions, non-independent observations, typically in the form of multiple treatments compared to a single control group.
Upon discussion, the team's statistician (MBM) suggested that the `CORR` model from the `robumeta` package would be a better fit.

```{r alt_models, include=F}
alt_model <- robust(metafor::rma.uni(yi = d, vi = var_d, data = dat), 
                    cluster = dat$unique_study_id)

hier_model <- robumeta::robu(formula =d ~ 1, data = dat,
                             studynum = author,
                             var.eff.size = var_d, modelweights = 'HIER', 
                             small = TRUE) 
```

Using our original cluster-robust estimation strategy from `metafor`, we detect a pooled effect size of `r alt_model$beta` (95% CI: [`r paste0(round(alt_model$ci.lb, 2), ", ", round(alt_model$ci.ub, 2))`]), p = `r alt_model$pval`.
(Although `metafor` also provides an RVE estimator, it applies the correction to the standard errors and not to the overall estimate, and we preferred a model that incorporates clustering information at the level of effect estimation.)

### Robustness to a stricter definition of delay {#Sec5.1.3}

```{r strict_delay_model}
strict_delay_model <- dat |> filter(delay_post_endline > 0) |> extract_model_results()
```

Our delay-related inclusion criterion aimed to capture enduring, not incidental, effects, particularly to consider cases where someone encouraged to have a single vegetarian meal might later counterbalance by consuming a larger quantity of meat or animal products (MAP).
Upon reviewing studies, however, we encountered an issue: numerous high-quality studies modifying eating environments over multiple days did not incorporate a delay following the final day of treatment before measuring outcomes.
For example, [@andersson2021] included 50 combined days of treatment and control, but, implemented in a dining hall, the interval between treatment and any individual outcome measurement was zero days.
By one light, such studies lack delayed outcome measures.
In another, the multi-day setup in a repeated environment allows for some theoretical delay, as participants acclimate and undergo control measurements on subsequent days.

We thus included multi-day studies where delayed outcomes were at least theoretically possible through repeat visits to the intervention site.
Our delay variable reflects the days elapsed from treatment initiation to measurement.
Additionally, we documented a secondary delay variable, recording time from treatment conclusion to measurement.
Restricting our analysis to the `r strict_delay_model$N_studies` studies and `r strict_delay_model$N_estimates` point estimates where this secondary delay exceeds zero, we observe an effect of SMD = `r strict_delay_model$Delta` (95% CI: `r strict_delay_model$CI`), p = `r strict_delay_model$p_val`.

## Notes on custom search strategy {#Sec5.2}

This literature has remarkable methodological, disciplinary, and theoretical diversity.
However, it also has few if any agreed upon terms to describe itself.
For instance,the term "MAP" is nonstandard; other papers discuss animal-based proteins, animal products, meat, edible animal products, plant-based foods, plant-based protein, animal meat and products, and so on.
This diversity of language poses a particular challenge for anyone seeking to systematically review this literature.
Whether one has identified the correct terms that each relevant study uses to describe itself is, for all practical purposes, unknowable.

This informed our search process.
Rather than starting with a list of search terms, we began by reading prior reviews, and then reading the studies cited by those reviews, to get a sense of the language that studies used to describe themselves.
We then pursued the multi-pronged, iterative search process described in the main text.
Ultimately, we used systematic search techniques to fill in gaps where we had an intuition that we may have missed studies employing a particular approach.

[RP SEARCH PROCESS]

We used the following Google Scholar search terms:

-   "random" "nudge" "meat"
-   "meat" "reduction" "randomized"
-   "meat" "consumption" "reducing" "random"
-   "meat" "purchases" "information" "nudge"
-   "nudge" "theory" "meat" "purchasing"
-   "meat" "alternatives" "default" "nudge"
-   "dynamic" "norms" "meat"
-   "dynamic" "norms" "meat" "consumption"
-   "norms" "animal" "products"
-   "university" "meat" "default" "reduction"
-   "sustainable" "meat" "nudge"
-   "sustainable" "meat" "nudge" "random"
-   "randomized controlled trial" "meat" consumption" "reduce"
-   "nudges" "norms" "meat"
-   "meat" "sustainable" "random"
-   "nudge" "meat" "default"
-   "nudge" "sustainable" "consumption" "meat"
-   "nudge" "reduce" "meat" "consumption"
-   "field" "experiment" "plant-based"

For each of these, we reviewed ten pages of results.

Additionally, we searched the American Economic Association's RCT registry for the following terms;

-   term

-   term

Last, we searched a few journal home pages for a few related terms:

PHAIR:\
\* reduction meat random

-   reduction meat

## Supplementary Discussion

### Defining choice architecture: do norms interventions count? {#sec5.4.4}

What exactly choice architecture is, and what sorts of interventions qualify, is a subject of scholarly debate.
[@thaler2009] define a nudge as “any aspect of the choice architecture that alters people’s behaviour in a predictable way, without forbidding any options or significantly changing their economic incentives.
To count as a mere nudge, the intervention must be easy and cheap to avoid” (p. 6).
However, which incentives count as “economic” is not self-evident, and [@selinger2012] note that many of the examples cited by [@thaler2009] actually do alter incentives.
[@hausman2010] offer a revised definition of nudges as “ways of influencing choice without limiting the choice set or making alternatives appreciably more costly in terms of time, trouble, social sanctions, and so forth” (p. 126).
By this definition, an injunctive norm intervention, which implies a threat of social deviance and therefore sanction, would not qualify.
The question of whether a descriptive norm intervention is a nudge is trickier.
As [@hausman2010] note, nudges are designed to address “flaws in individual decision-making” (p. 126).
Is a tendency to conform a flaw or behavioral bias [@kantorowicz2021]?
[@mols2015] ] address this defining “unthinking conformity” as one of the “human failings” which nudges are intended to address.
They contrast this approach with “persuasion,” which “appeals to an individual’s ability to reason, digest new information and engage in systematic information processing” (p. 4).

Our own view is that a tendency to conform might be irrational or unthinking, but it could just as easily be the product of reflection on one’s social identity, especially when a socially beneficial behavior is being proposed.
If you walk into a campus cafe and see a sign saying that its veggie burgers are “on the rise” [@sparkman2020], perhaps that triggers a “herd mentality” [@mols2015], but perhaps the patron thinks of their vegetarian friends, the environment, or animal welfare and makes a socially conscious choice.
We do not know and do not assume that people react unthinkingly.
Therefore, we do not classify the norms interventions in our database as nudges.

A future project might investigate exactly what reactions are occurring by asking subjects how well they recall a norms message and what it made them think about.
A high prevalence of subjects who are unable to recall the message's specifics but nevertheless cut back on MAP consumption would be evidence that norms are acting through automatic rather than reflective processes.

### Discussion of prior reviews {#sec5.4.5}

It was striking to us there have been more systematic reviews of MAP reduction research than there have been studies meeting our criteria.
We encourage scholars to pursue more randomized controlled trials with consumption outcomes.

We turn now to a selective overview of prior reviews of dietary research that were highly relevant to this one.

Among the reviews that found MAP reduction interventions to be effective, several focused exclusively on choice architecture.
[@arno2016] found that nudges led to an average increase of healthy dietary choices of 15.3%, while [@byerly2018] found that committing to reduce meat intake and making menus vegetarian by default were more effective than educational interventions.
However, the vast majority of vegetarian-default studies we analyzed for this paper did not qualify for our analysis because they lacked delayed outcomes, and their net effect on MAP consumption is unknown.

[@bianchi2018restructuring] found that reducing meat portions, making alternatives available, moving meat products to be less conspicuous, and changing meat's sensory properties can all reduce meat demand.
[@pandey2023] found that changing the presentation and availability of sustainable products was effective in increasing demand for them, as was providing information about them.

In a meta-review, [@grundy2022] found environmental education to be most promising, with substantial evidence also supporting health information, emphasizing social norms, and decreasing meat portions.

Some reviews have focused on particular settings for MAP reduction interventions.
[@hartmannboyce2018] found that grocery store interventions, such as price changes, suggested swaps, and changes to item availability, were effective at changing purchasing choices.
However, that review covered a wide variety of health interventions, such as reducing consumption of dietary fat and increasing fruit and vegetable purchases.
It is unclear how directly such findings translate to MAP reduction efforts.

[@chang2023] focused on university meat-reduction interventions and found more promising results than did reviews that looked at the wider public.
This suggests that students and young people may be particularly receptive to MAP reduction interventions.
[@harguess2020] reviewed 22 studies on meat consumption and found promising results for educational interventions focused on the environment, health, and animal welfare.
That paper recommends using animal imagery to cause an emotional response and utilizing choice architecture interventions.
Our review, by contrast, found no relationship between animal welfare appeals and MAP consumption.

Taking a different angle, [@adleberg2018] reviewed the literature on protests in a variety of movements and found mixed evidence of efficacy.
The authors recommend that animal advocacy protests have a specific target (e.g. a particular institution) and "ask."

Other studies provide insights on who is most easily influenced by interventions to reduce MAP consumption.
For example, [@blackford2021] found that nudges focused on "system 1" thinking were more effective at encouraging sustainable choices than those focused on "system 2," and that interventions had greater effects on females than males.
Our review also featured studies showing differences between men and women.

[@rosenfeld2018] reports that meat avoidance is associated with liberal political views, feminine gender, and higher openness, agreeableness and neuroticism.
That review also identifies challenges and barriers to vegetarianism, such as recidivism and hostility from friends and family.
Future research could tailor interventions to address these barriers.

Several reviews have had mixed or inconclusive results.
For instance, [@bianchi2018conscious] found that health and environmental appeals appear to change dietary intentions in virtual environments, but did not find evidence of actual consumption changes.
In the same vein, [@kwasny2022] notes that most existing research focuses on attitudes and intentions and lacks measures of actual meat consumption over an extended period of time.
[@taufik2019] reviewed many studies aimed at increasing fruit and vegetable intake, but found far fewer that looked at reducing MAP consumption.
[@benningstad2020] found that dissociation of meat from its source plays a role in meat consumption, but no extant research that included behavioral outcomes.

A few reviews have found evidence that seems to recommend against particular interventions.
[@greig2017] reviewed the literature on leafleting for vegan/animal advocacy outreach, and observed biases towards overestimating impact.
That paper concluded that leafleting does not seem cost-effective, though with significant uncertainty.
This accords with our findings on advocacy organization materials' limited impacts.

[@nisa2019] meta-analyzed interventions to improve household sustainability, of which reducing MAP consumption was one of several.
Although they found small effect sizes for most interventions, they concluded that nudges were comparatively effective.
Many such nudge studies looked at meat consumption.
Similarly, [@rau2022] reviewed the literature on environmentally friendly behavior changes, including but not limited to diet change, and found small or nonexistent effects in most cases.
Only fifteen interventions in that paper were described as “very successful,” and none of these related to food.

We draw two lessons from these papers.
The first is that the marginal value of a new rigorous evaluation is much higher than that of a new systematic review.
The second is that the category of dependent variable matters for estimating impact.
We encourage researchers who care about reducing MAP consumption to measure it directly whenever possible.

\begin{comment}
First I feel a little strange saying that the marginal value of a review is low (then whay are we writing this paper?) Second, maybe there's a space for discussion about what counts as  meaningful? mention that ease of implementation matters in terms of what’s meaningful. The costs of fully exposing one person is the relevant denominator. The costs of recruitment are part of the cost. Maybe some people are more amenable to nudges after hearing an argument for
\end{comment}

\newpage

# References
